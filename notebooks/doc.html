<!DOCTYPE html>
<html lang="en" class="h-100">
  <head>
    <title>Learnfromdata Doc</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Bootstrap CSS, Icon and favicon -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.3.0/font/bootstrap-icons.css">
    <link rel="icon" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15/svgs/solid/code.svg">
    
    <!-- Custom styling -->
    <style>
        .nav-pills .nav-link.active, .nav-pills .show .nav-link {color: #ffe; background-color: #c90000}
        .nav-link, .nav-link:hover {color:rgb(59, 59, 59); text-align: left}
        .sub {margin-left: 30px; padding-top: 5px; font-size: 14px;}
        .python{background-color: #fff !important;}
        .signature{color:#555555; font-size:18px}
        .function{color:#C90000; font-size:22px}
        .attributes{color:#7e7e7e; font-style: italic}
        .argument{color:#555555}
        .datatype{color:#777777}
        h3 {color:#555555}
        p {font-family: 'Times New Roman', Times, serif;}
        .uml {line-height: 1.1; letter-spacing: -0.2px; font-size: small; color: #555555;}
        .accordion-button, .accordion-button:not(.collapsed)
            {color:#555; background-color: #fff;}
    </style>
    
    <!-- Python code syntax highlighting -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </head>

  <body class="d-flex flex-column h-100">
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js" integrity="sha384-oBqDVmMz9ATKxIep9tiCxS/Z9fNfEXiDAYTujMAeBAsjFuCZSmKbSSUnQlmh/jp3" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.min.js" integrity="sha384-cuYeSxntonz0PPNlHhBs68uyIAVpIIOZZ5JqeqvYYIcEL727kskC66kF92t6Xl2V" crossorigin="anonymous"></script>
        <div class="col-lg-11 mx-auto p-4 py-md-5">
        <div>
<h1>Learnfromdata <span class="small attributes">v1.0.0</span>
</h1>
<br>
</div>
<span id="intro"></span>
        <div class="row">
            <div class="col-xl-1 col-3">
                <ul class="nav nav-pills nav-fill mb-3 flex-column" id="v-pills-tab" role="tablist" aria-orientation="vertical">
                    <li class="nav-item" role="presentation"><button class="nav-link active" data-bs-toggle="pill" data-bs-target="#Abouttab" role="tab" type="button" aria-controls="Abouttab" aria-selected="true">About</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Pipelinetab" role="tab" type="button" aria-controls="Pipelinetab" aria-selected="false">Pipeline</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Bootstraptab" role="tab" type="button" aria-controls="Bootstraptab" aria-selected="false">Bootstrap</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Datatab" role="tab" type="button" aria-controls="Datatab" aria-selected="false">Data</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Transformertab" role="tab" type="button" aria-controls="Transformertab" aria-selected="false">Transformer</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#UniSelectortab" role="tab" type="button" aria-controls="UniSelectortab" aria-selected="false">UniSelector</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Binnertab" role="tab" type="button" aria-controls="Binnertab" aria-selected="false">Binner</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Imputertab" role="tab" type="button" aria-controls="Imputertab" aria-selected="false">Imputer</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Encodertab" role="tab" type="button" aria-controls="Encodertab" aria-selected="false">Encoder</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#BiSelectortab" role="tab" type="button" aria-controls="BiSelectortab" aria-selected="false">BiSelector</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Expandertab" role="tab" type="button" aria-controls="Expandertab" aria-selected="false">Expander</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Standardizertab" role="tab" type="button" aria-controls="Standardizertab" aria-selected="false">Standardizer</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Modeltab" role="tab" type="button" aria-controls="Modeltab" aria-selected="false">Model</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Regressiontab" role="tab" type="button" aria-controls="Regressiontab" aria-selected="false">Regression</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Xgboosttab" role="tab" type="button" aria-controls="Xgboosttab" aria-selected="false">Xgboost</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#NeuralNettab" role="tab" type="button" aria-controls="NeuralNettab" aria-selected="false">NeuralNet</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#DecisionTreetab" role="tab" type="button" aria-controls="DecisionTreetab" aria-selected="false">DecisionTree</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#Isotonictab" role="tab" type="button" aria-controls="Isotonictab" aria-selected="false">Isotonic</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#GaussianMixturetab" role="tab" type="button" aria-controls="GaussianMixturetab" aria-selected="false">GaussianMixture</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#Plottertab" role="tab" type="button" aria-controls="Plottertab" aria-selected="false">Plotter</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#PlotterModeltab" role="tab" type="button" aria-controls="PlotterModeltab" aria-selected="false">PlotterModel</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#PlotterVisualtab" role="tab" type="button" aria-controls="PlotterVisualtab" aria-selected="false">PlotterVisual</button></li>
<li class="nav-item" role="presentation"><button class="nav-link sub" data-bs-toggle="pill" data-bs-target="#PlotterGraphtab" role="tab" type="button" aria-controls="PlotterGraphtab" aria-selected="false">PlotterGraph</button></li>
<li class="nav-item" role="presentation"><button class="nav-link" data-bs-toggle="pill" data-bs-target="#configtab" role="tab" type="button" aria-controls="configtab" aria-selected="false">config</button></li>
<span id="sidebar"></span>
                  <!-- <a class="nav-link sub" data-toggle="pill" href="#xgboosttab" role="tab" aria-controls="xgboosttab" aria-selected="false">Xgboost</a> -->
                </ul>
            </div>
            <div class="col-xl-9 offset-xl-1 col-9">
                <main class="tab-content" id="v-pills-tabContent">       
                    <div class="tab-pane show active" id="Abouttab" role="tabpanel" aria-labelledby="Abouttab" tabindex="0"><div>
    <div class="row">
        <div class="col-xl-8 col-10">
            <h3>Summary</h3>
            <p>This package contains tools to build modelling pipelines.</p>

            <p>These pipelines are composed of a number of data transformers and one or more 
            (un)supervised models. They can be configured, evaluated, explained, visualized, saved,
            and iterated with various parameters. Any use of the package is reproducible.</p>

            <p>The package can be seen as a thin, object oriented layer on top of the Numpy stack (including packages as 
            Numpy, Pandas and Sklearn). It follows the fit-transform paradigm of Sklearn meaning that pipelines 
            (and thus its transformers and models) are always first learned and later on applied.</p>
        </div>
    </div>

    <br><h3>Get Started</h3>
    <p>These are little code sippets to get started. For more details on atributes, methods, inputs and outputs, refer to the respective class documentation.</p>
    <div class="row">
        <div class="col-6">
            <div class="accordion accordion-flush" id="accordionFlushExample">
                <div class="accordion-item">
                  <h2 class="accordion-header" id="flush-headingOne">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseOne" aria-expanded="false" aria-controls="flush-collapseOne">
                      Learn a pipeline
                    </button>
                  </h2>
                  <div id="flush-collapseOne" class="accordion-collapse collapse" aria-labelledby="flush-headingOne" data-bs-parent="#accordionFlushExample">
                    <div class="accordion-body">
                        <pre><code class="python">import lfd
data = lfd.Data('path/to/data.csv')
params = lfd.get_params(target='target_variable', mode='binaryclass')
pipe = lfd.Pipeline()
pipe.learn(params, data)
pipe.save('path/to/experiment', as_pickle=True)</code></pre>    
                    </div>
                  </div>
                </div>
                <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingOne1">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseOne1" aria-expanded="false" aria-controls="flush-collapseOne1">
                        Apply a pipeline
                        </button>
                    </h2>
                    <div id="flush-collapseOne1" class="accordion-collapse collapse" aria-labelledby="flush-headingOne1" data-bs-parent="#accordionFlushExample">
                        <div class="accordion-body">
                            <pre><code class="python">import lfd
data = lfd.Data('path/to/new_data.csv')
pipe = lfd.Pipeline()
pipe.load('path/to/experiment.pkl')
pipe.apply(data)</code></pre>    
                        </div>
                    </div>
                </div>
                <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingOne2">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseOne2" aria-expanded="false" aria-controls="flush-collapseOne2">
                        Visualize a pipeline
                        </button>
                    </h2>
                    <div id="flush-collapseOne2" class="accordion-collapse collapse" aria-labelledby="flush-headingOne2" data-bs-parent="#accordionFlushExample">
                        <div class="accordion-body">
                            <pre><code class="python">import lfd
pipe = ... # Load or learn pipeline
plotter = lfd.ModelPlotter(theme='dark', colors='belfius')

# Run visualization dashboard
plotter.run_app('path/to/experiments', host='10.226.128.91', port=9065)

# Plot visualizations in a notebook
model = pipe.models['Xgboost']
plotter.confusion_heatmaps(model.confusion)
plotter.plot_bar_chart(model.feature_imp.head(20))
plotter.lift_curve(model.predictions.df, bins=20)</code></pre>    
                        </div>
                    </div>
                </div>
                <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingOne3">
                        <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseOne3" aria-expanded="false" aria-controls="flush-collapseOne3">
                        Bootstrap a pipeline
                        </button>
                    </h2>
                    <div id="flush-collapseOne3" class="accordion-collapse collapse" aria-labelledby="flush-headingOne3" data-bs-parent="#accordionFlushExample">
                        <div class="accordion-body">
                            <pre><code class="python">import lfd
boot = lfd.Bootstrap('path/to/experiments')
boot.learn_pipelines(data, all_params, data_iters=20, model_iters=20)
meta = boot.get_meta(model='Xgboost', dataset='Test', metrics='accuracy')</code></pre>    
                        </div>
                    </div>
                </div>
                <div class="accordion-item">
                  <h2 class="accordion-header" id="flush-headingTwo">
                    <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwo" aria-expanded="false" aria-controls="flush-collapseTwo">
                      Configure a pipeline
                    </button>
                  </h2>
                  <div id="flush-collapseTwo" class="accordion-collapse collapse" aria-labelledby="flush-headingTwo" data-bs-parent="#accordionFlushExample">
                    <div class="accordion-body">
                        <pre><code class="python">params = dict(
    set_aside = ['variables', 'to', 'exclude'],
    data = dict(
        add_noise = dict(seed=0),
        test_split = dict(test_size=0.2, stratify_col=None, seed=0),
    ),
    transform = dict(
        uniselector = dict(min_occ=0.01, max_occ=0.99),
        imputer = dict(default_cat='MISSING', default_cont='median'),
        encoder = dict(min_occ=0.01, method='onehot'),
        biselector = dict(threshold=0.8, target='target_variable'),
    ),
    model = dict(
        target='target_variable', mode='binaryclass', seed_train=0,
        base0 = dict(algorithm='xgboost', name='Xgboost', hyper_params=dict(
            n_estimators=100, max_depth=6
        )),
        calibrate = dict(algorithm='regression', hyper_params=dict()),
    )
)</code></pre>                            
                    </div>
                  </div>
                </div>
              </div>
            
        </div>
        <div class="col-6">
        </div>
    </div>
    <br><br><h3>UML Class Diagram</h3>
    <br>
    <pre class="uml">
    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;           &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;       &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9474; Pipeline    &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508; Bootstrap       &#9474;           &#9474; Plotter       &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508; ModelPlotter &#9474;
    &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;           &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;           &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;       &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;
    &#9474; learn       &#9474;           &#9474; learn_pipelines &#9474;           &#9474; line_chart    &#9474;       &#9474; run_app      &#9474;
    &#9474; apply       &#9474;           &#9474; get_meta        &#9474;           &#9474; boxplots      &#9474;       &#9474; liftcurve    &#9474;
    &#9474; save        &#9474;           &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;           &#9474; histogram     &#9474;       &#9474; confusion    &#9474;
    &#9474; load        &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;                                   &#9474; ...           &#9474;       &#9474; ...          &#9474;
    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;     &#9474;                                   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
          &#9474;             &#9474;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
          &#9474;             &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508; Transformer &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;     &#9474;     &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;          &#9474;               &#9474;            &#9474;             &#9474;               &#9474;              &#9474;                 &#9474;
    &#9474; Data        &#9474;     &#9474;     &#9474; learn       &#9474;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;     &#9474;     &#9474; apply       &#9474;   &#9474; UniSelector &#9474;   &#9474; Binner &#9474;   &#9474; Imputer &#9474;   &#9474; Encoder &#9474;   &#9474; Biselector &#9474;   &#9474; Expander &#9474;   &#9474; Standardizer &#9474;
    &#9474; merge       &#9474;     &#9474;     &#9474; save        &#9474;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;
    &#9474; split       &#9474;     &#9474;     &#9474; load        &#9474;   &#9474; learn       &#9474;   &#9474; learn  &#9474;   &#9474; learn   &#9474;   &#9474; learn   &#9474;   &#9474; learn      &#9474;   &#9474; learn    &#9474;   &#9474; learn        &#9474;
    &#9474; balance     &#9474;     &#9474;     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9474; apply       &#9474;   &#9474; apply  &#9474;   &#9474; apply   &#9474;   &#9474; apply   &#9474;   &#9474; apply      &#9474;   &#9474; apply    &#9474;   &#9474; apply        &#9474;
    &#9474; filter      &#9474;     &#9474;                       &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
    &#9474; select      &#9474;     &#9474;     &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9474; sample      &#9474;     &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508; Model       &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9516;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9474; concat      &#9474;           &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;          &#9474;              &#9474;              &#9474;                 &#9474;                &#9474;               &#9474;
    &#9474; generate    &#9474;           &#9474; learn       &#9474;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9488;   &#9484;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9524;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9488;
    &#9474; add_noise   &#9474;           &#9474; apply       &#9474;   &#9474; Regression &#9474;   &#9474; Xgboost &#9474;   &#9474; NeuralNet &#9474;   &#9474; DecisionTree &#9474;   &#9474; Isotonic &#9474;   &#9474; UniSelector &#9474;
    &#9474; save        &#9474;           &#9474; evaluate    &#9474;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;   &#9500;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9508;
    &#9474; load        &#9474;           &#9474; explain     &#9474;   &#9474; learn      &#9474;   &#9474; learn   &#9474;   &#9474; learn     &#9474;   &#9474; learn        &#9474;   &#9474; learn    &#9474;   &#9474; learn       &#9474;
    &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;           &#9474; save        &#9474;   &#9474; apply      &#9474;   &#9474; apply   &#9474;   &#9474; apply     &#9474;   &#9474; apply        &#9474;   &#9474; apply    &#9474;   &#9474; apply       &#9474;
                              &#9474; load        &#9474;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;   &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
                              &#9492;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9472;&#9496;
    </pre>
</div></div>
<div class="tab-pane" id="Pipelinetab" role="tabpanel" aria-labelledby="Pipelinetab" tabindex="0">
<p><h3>
<span class="function">Pipeline</span><span class="signature">(logparams=None, name=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Pipelinemod"></i></span>
</h3><p>This class collects methods for learning applying, saving and loading a pipeline, which
is composed a number of transformers (imputer, encoder...) and (un)supervised model(s).
Configuration on how to learn happens with a dictionary as provided by config.get_params().
This configuration can be adapted, and makes learning and applying of a pipeline reproducible.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>logparams</b></span>: <span class="datatype"><i>Dict, optional</i></span> Dictionary of parameters that are given to the get_params function when learning a pipeline. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Arbitrary name for the pipeline object. If not given, it will be the current timestamp in format 'yymmdd_hhmmss_ms'. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Pipeline.name</b></span>: <span class="datatype"><i>String</i></span> Name of the pipeline. <br>
<span class="argument"><b>Pipeline.data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to use in a pipeline. Used to split, predict, evaluate, explain, etc. <br>
<span class="argument"><b>Pipeline.train</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to train on. Either given or split from self.data when learning. <br>
<span class="argument"><b>Pipeline.transformers</b></span>: <span class="datatype"><i>Dict[String: lfd.Transformer]</i></span> Dictionary of transformer objects. <br>
<span class="argument"><b>Pipeline.models</b></span>: <span class="datatype"><i>Dict[String: lfd.Model]</i></span> Dictionary of model objects. <br>
<span class="argument"><b>Pipeline.cal_models</b></span>: <span class="datatype"><i>Dict[String: lfd.Model]</i></span> Dictionary of model objects, that calibrate the models in self.models. <br>
<span class="argument"><b>Pipeline.stack_model</b></span>: <span class="datatype"><i>lfd.Model</i></span> Model object that is built on top of the models in self.models. <br>
<span class="argument"><b>Pipeline.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary as given or provided by config.get_params(). <br>
<span class="argument"><b>Pipeline.set_aside</b></span>: <span class="datatype"><i>List</i></span> List of variables that is not transformed or used as features in modelling. <br>
<span class="argument"><b>Pipeline.log_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters that set logging, and is given to config.set_params(). </p>


    <div class="modal fade bd-example-modal-lg" id="Pipelinemod" tabindex="-1" role="dialog" aria-labelledby="PipelineLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Pipeline</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Pipeline:
    
    def __init__(self, logparams=None, name=None):
        set_logging(**dict() if logparams is None else logparams)
        # Data objects
        self.data = None
        self.train = None
        
        # Transform &amp; model objects
        self.transformers = {}
        self.models = {}
        self.cal_models = {}
        self.stack_model = None
        
        # Settings attributes
        self.params = {}
        self.set_aside = None
        self.logparams = logparams

        self.name = name if name else datetime.strftime(datetime.now(), '%y%m%d_%H%M%S_%f')
        
    def _set_data(self, params, data=None, train=None):
        
        self.params['data'] = params
        self.data = data
        self.train = train

        if train is not None: self.train = train

        # Split in training, test and validation, add noise
        if params.get('test_split'): 
            self.data.split(subset='All', names=('Train', 'Test'), **params['test_split'])
        if params.get('valid_split'):
            self.data.split(subset='Train', names=('Train', 'Valid'), **params['valid_split'])
        if params.get('add_noise'): 
            self.data.add_noise(**params['add_noise'])
        if params.get('test_split') is None and params.get('valid_split') is None and 'dataset' not in self.data.df.index.names:
            self.data.add_index('dataset', 'Train')

        # Create samples for learning and evaluation
        if self.train is None:
            self.train = self.data.select(['Train'], drop=False, name='Train')
        if params.get('sample'):
            self.train = self.train.sample(params['sample'])
        if params.get('train_balance'):
            self.train = self.train.balance(**params['train_balance'], name='Balanced')
        if params.get('actual_balance'):
            self.data = self.data.balance(**params['actual_balance'], name='All')

    def _learn_transform(self, params):
            
        # Create transformers and learn on train
        self.params['transform'] = params
        self.transformers = {}
        for name, parameters in params.items():
            if parameters is None: continue
            self.transformers[name] = TransformEnum[name].value()
            self.train = self.transformers[name].learn(
                self.train, set_aside=self.set_aside, **parameters).apply(self.train)

        # Apply the transform objects on validation and testing
        self.data = self._apply_transform(self.data)
        self.params['transform'] = params
      
    def _apply_transform(self, data):
        
        for name in self.transformers:
            self.transformers[name].apply(data, inplace=True)
        return data

    def _learn_model(self, params, cutoff_params=None, evaluate=True, explain=False):
            
        self.params['model'] = params
        seed = params.get('seed_train', 0)
        target = params.get('target')
        mode = params['mode']
        self.models, self.cal_models, self.stack_model = {}, {}, None
                
        # Train models
        base_params = [v for k, v in params.items() if k.startswith('base') and v is not None]
        for param_set in base_params:
            if param_set is None: continue
            # Make an object of a class according to 'algorithm' params, with 'name' attribute
            model = ModelEnum[param_set['algorithm']].value(param_set['name'])
            model.learn(self.train, target, mode, set_aside=self.set_aside, seed=seed, 
                        hyper_params=param_set['hyper_params'])
            if explain: model.explain(self.data)
            self.models[param_set['name']] = model

        # Train calibration models
        if params.get('calibrate') is not None:
            for model in self.models.values():
                train_unbalanced = self.data.select(['Train'], drop=False, name='Train')
                scores = model.apply(train_unbalanced, include_preds=False)
                cal_model = ModelEnum[params['calibrate']['algorithm']].value(name='C_'+model.name)
                cal_model.learn(scores, 'target', mode, set_aside=['target'], seed=seed,
                                hyper_params=params['calibrate'].get('hyper_params'))
                self.cal_models[model.name] = cal_model

        # Train stack model
        if params.get('stack'):
            scores = pd.DataFrame({name:model.predict_scores(self.train.df) for name, model in self.models.items()})            
            scores[target] = self.train.df[target].values
            self.stack_model = ModelEnum[params['stack']['algorithm']].value(name='Stack')
            self.stack_model.learn(
                Data(scores, name='scores'), target, mode, set_aside=self.set_aside,
                hyper_params=params['stack'].get('hyper_params'), seed=seed)

        # Evaluate all models
        self._apply_model(self.data, cutoff_params, evaluate=evaluate)
                 
    def _apply_model(self, data, cutoff_params=None, evaluate=True, explain=False):
        
        for model in self.models.values(): # apply the model to get the predictions
            model.apply(data, store=True, cutoff_params=cutoff_params)
            if evaluate: model.evaluate(model.predictions)
            if explain: model.explain(data)
        
        # Apply platt-calibration to the predictions of the model to get calibrated scores
        for modelname, cal_model in self.cal_models.items(): 
            cal_model.apply(self.models[modelname].predictions, store=True, cutoff_params=cutoff_params)
            if evaluate: cal_model.evaluate(cal_model.predictions)

        if self.stack_model:
            scores = pd.DataFrame({name: model.predictions.df.scores for name, model in self.models.items()})
            scores[self.stack_model.target] = data.df[self.stack_model.target].values
            self.stack_model.apply(Data(scores, name='scores'), store=True, cutoff_params=cutoff_params)
            if evaluate: self.stack_model.evaluate(self.stack_model.predictions)

    @profile
    def learn(self, params, data=None, train=None, cutoff_params=None, evaluate=True, explain=True):
        
        logging.info('Learning pipeline')
        self.set_aside = params['set_aside']
        self._set_data(params['data'], data, train)
        self._learn_transform(params['transform'])
        self._learn_model(params['model'], cutoff_params, evaluate, explain)
        return self
    
    def apply(self, data=None, cutoff_params=None, evaluate=False, explain=False):
        
        logging.info('Applying pipeline')
        self.data = Data(data, 'Data')
        self.data = self._apply_transform(self.data)
        self._apply_model(self.data, cutoff_params, evaluate, explain)         
        return self

    def save(self, directory=None, name=None, slim=False, as_pickle=False):
        
        logging.info('Saving pipeline')
        # Set name and check presence
        self.name = name if name else self.name
        if directory is None or self.name is None:
            logging.warning('Pipeline not saved. No directory or name was provided.')
            return
        
        # Save as pickle
        if as_pickle:
            with open(os.path.join(directory, f'{self.name}.pkl'), 'wb') as f:
                pickle.dump(self, f)
            return

        # Reset path
        path = os.path.join(directory, self.name)
        if os.path.isdir(path): shutil.rmtree(path)
        os.mkdir(path)

        # Save parameters
        if self.params: 
            with open(os.path.join(path, 'params.json'), 'w') as f:
                json.dump(self.params, f, indent=4)

        # Save transformers
        transform_path = os.path.join(path, 'transform')
        if not os.path.isdir(transform_path): os.mkdir(transform_path)
        for name in self.transformers:
            self.transformers[name].save(transform_path)
            
        # Save models
        kwargs = dict(directory=path, slim=slim, as_pickle=False)
        for model in self.models.values(): 
            model.save(**kwargs)
            if model.name in self.cal_models.keys():
                self.cal_models[model.name].save(**kwargs)
        if self.stack_model: 
            self.stack_model.save(**kwargs)
            
        if not slim and self.data is not None:
            self.data.save(os.path.join(path, 'data.parquet'))
            
    def load(self, path=None, slim=False):
        
        logging.info('Loading pipeline')
        paths = path.split('/')
        storage = '/'.join(paths[:-1])

        # Load pickle file
        if paths[-1].endswith('.pkl'):
            name = paths[-1][:-4]
            with open(os.path.join(storage, f'{name}.pkl'), 'rb') as f:
                self = pickle.load(f)
            self.name = paths[-1][:-4]
            return self

        # Load files
        self.name = paths[-1]
        path = os.path.join(storage, self.name)

        with open(os.path.join(path, 'params.json'), 'r') as f:
            self.params = dict_map(json.load(f))

        # Load transformers
        self.transformers = {}
        transform_path = os.path.join(path, 'transform')
        for name in self.params['transform']:
            self.transformers[name] = TransformEnum[name].value()
            self.transformers[name].load(transform_path)

        # Load models
        self.models, self.cal_models = {}, {}
        model_dirs = [f for f in os.listdir(path) if os.path.isdir(f'{path}/{f}') and f != 'transform']
        for model_dir in model_dirs:
            with open(os.path.join(path, model_dir, 'model.json'), 'r') as f:
                algorithm = json.load(f)['algorithm']
            model = ModelEnum[algorithm].value(model_dir).load(os.path.join(path, model_dir), slim=slim)
            if model_dir=='stack': self.stack_model = model
            elif model_dir.startswith('C_'): self.cal_models[model.name[2:]] = model
            else: self.models[model.name] = model
        if not slim and 'data.parquet' in os.listdir(path):
            self.data = Data(os.path.join(path, 'data.parquet'), 'Data')
        return self

    def _summary(self):
        
        datas = [d for d in [self.data, self.train] if d is not None]
        data = [data._summary() for data in datas]
        data = pd.concat(data, axis=1).T if len(data)&amp;gt;0 else pd.DataFrame()
        models = [model._summary()._append(pd.Series(dict(Role='Base'))) for model in self.models.values()]
        models += [model._summary()._append(pd.Series(dict(Role='Calibration'))) for model in self.cal_models.values()]
        models = pd.concat(models, axis=1).T if len(models)&amp;gt;0 else pd.DataFrame()
        transformers = [transformer._summary() for transformer in self.transformers.values()]
        transformers = pd.concat(transformers, axis=1).T if len(transformers)&amp;gt;0 else pd.DataFrame()
        return data, transformers, models, self.metrics, self.confusion

    def __repr__(self):
        string = 'This is a PIPELINE object.'
        data, transformers, models, metrics, confusion = self._summary()
        string += f"\n\nDATA\n"
        string += tabulate(data, tablefmt='simple_outline', showindex=False, headers='keys')
        string += f"\n\nTRANSFORMERS\n"
        string += tabulate(transformers, tablefmt='simple_outline', showindex=False, headers='keys')
        string += f"\n\nMODELS\n"
        string += tabulate(models, tablefmt='simple_outline', showindex=False, headers='keys')
        string += '\n\nAttributes: data, train, transformers, models, cal_models, stack_model, metrics, confusion, params, storage.\n'
        string += 'Methods: learn, apply, save, load.'
        return string

    # def __getstate__(self):
    #     state = self.__dict__.copy()
    #     state['data'] = None
    #     state['train'] = None
    #     return state

    # def __setstate__(self, state):
    #     self.__dict__.update(state)
    #     if self.slim:
    #         for a in ['data', 'train']:
    #             self.__dict__[a] = None

    @property
    def metrics(self):
        metrics = [model.metrics for model in self.models.values() if model.metrics is not None]
        return pd.concat(metrics, keys=self.models.keys()).round(3) if metrics else None

    @property
    def confusion(self):
        confusion = [model.confusion for model in self.models.values() if model.confusion is not None]
        return pd.concat(confusion, keys=self.models.keys()).round(3) if confusion else None
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Pipeline.learn</span><span class="signature">(self, params, data=None, train=None, cutoff_params=None, evaluate=True, explain=True) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Pipelinelearnmod"></i></span>
</h3>
<p>Learns a modelling pipeline. From data setting, to learning transformers, to learning and 
evaluating models.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>params</b></span>: <span class="datatype"><i>Dict[]</i></span> Parameters in dictionary used in underlying data, transform and modelling functions. See Config.get_params() on how to format. <br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data, optional</i></span> Data object used as input for splitting, adding noise, sampling and balancing. If not given, self.data attribute is used. <br>
<span class="argument"><b>train</b></span>: <span class="datatype"><i>lfd.Data, optional</i></span> Data object used for training. Typically not given, but can be to overrule splitting data. If not given, self.train attribute is used. If this is None, self.data will be split. <br>
<span class="argument"><b>cutoff_params</b></span>: <span class="datatype"><i>Dict[String: List[Float]]</i></span> Dictionary of cutoff parameters for binary classification. See Model.apply. A list for fixed recalls, precisions, flags and betas can be given. <br>
<span class="argument"><b>evaluate</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether the pipeline should also be evaluated by means of metrics and confusion matrices. <br>
<span class="argument"><b>explain</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether the pipeline should also be explained by means of SHAP values. </p>


    <div class="modal fade bd-example-modal-lg" id="Pipelinelearnmod" tabindex="-1" role="dialog" aria-labelledby="PipelinelearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Pipelinelearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    @profile
    def learn(self, params, data=None, train=None, cutoff_params=None, evaluate=True, explain=True):
        
        logging.info('Learning pipeline')
        self.set_aside = params['set_aside']
        self._set_data(params['data'], data, train)
        self._learn_transform(params['transform'])
        self._learn_model(params['model'], cutoff_params, evaluate, explain)
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Pipeline.apply</span><span class="signature">(self, data=None, cutoff_params=None, evaluate=False, explain=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Pipelineapplymod"></i></span>
</h3>
<p>Applies a modelling pipeline on any data object. From applying transformers, to applying and 
evaluating models.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data, pandas.DataFrame, String, optional</i></span> Data object to apply the pipeline on. Can be lfd.Data, pandas.DataFrame or a pathfile to Parquet or csv. Pipeline must first be learned (on same or other data object). <br>
<span class="argument"><b>cutoff_params</b></span>: <span class="datatype"><i>Dict[String: List[Float]]</i></span> Dictionary of cutoff parameters for binary classification. See Model.apply. A list for fixed recalls, predictions, flags and betas can be given. <br>
<span class="argument"><b>evaluate</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether the pipeline should also be evaluated by means of metrics and confusion matrices. <br>
<span class="argument"><b>explain</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether the pipeline should also be explained by means of SHAP values. </p>


    <div class="modal fade bd-example-modal-lg" id="Pipelineapplymod" tabindex="-1" role="dialog" aria-labelledby="PipelineapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Pipelineapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, data=None, cutoff_params=None, evaluate=False, explain=False):
        
        logging.info('Applying pipeline')
        self.data = Data(data, 'Data')
        self.data = self._apply_transform(self.data)
        self._apply_model(self.data, cutoff_params, evaluate, explain)         
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Pipeline.save</span><span class="signature">(self, directory=None, name=None, slim=False, as_pickle=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Pipelinesavemod"></i></span>
</h3>
<p>Save pipeline.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>directory</b></span>: <span class="datatype"><i>String, optional</i></span> Directory where the pipeline should be saved. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Name the folder or file will have in the directory. If not given, name attribute will be used. If given, name attribute will be overwritten. <br>
<span class="argument"><b>slim</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to store also predictions, data and shapvalues. Generally not needed for prediction, but useful for inspection. <br>
<span class="argument"><b>as_pickle</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to save to a pickle file. </p>


    <div class="modal fade bd-example-modal-lg" id="Pipelinesavemod" tabindex="-1" role="dialog" aria-labelledby="PipelinesaveLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Pipelinesave</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def save(self, directory=None, name=None, slim=False, as_pickle=False):
        
        logging.info('Saving pipeline')
        # Set name and check presence
        self.name = name if name else self.name
        if directory is None or self.name is None:
            logging.warning('Pipeline not saved. No directory or name was provided.')
            return
        
        # Save as pickle
        if as_pickle:
            with open(os.path.join(directory, f'{self.name}.pkl'), 'wb') as f:
                pickle.dump(self, f)
            return

        # Reset path
        path = os.path.join(directory, self.name)
        if os.path.isdir(path): shutil.rmtree(path)
        os.mkdir(path)

        # Save parameters
        if self.params: 
            with open(os.path.join(path, 'params.json'), 'w') as f:
                json.dump(self.params, f, indent=4)

        # Save transformers
        transform_path = os.path.join(path, 'transform')
        if not os.path.isdir(transform_path): os.mkdir(transform_path)
        for name in self.transformers:
            self.transformers[name].save(transform_path)
            
        # Save models
        kwargs = dict(directory=path, slim=slim, as_pickle=False)
        for model in self.models.values(): 
            model.save(**kwargs)
            if model.name in self.cal_models.keys():
                self.cal_models[model.name].save(**kwargs)
        if self.stack_model: 
            self.stack_model.save(**kwargs)
            
        if not slim and self.data is not None:
            self.data.save(os.path.join(path, 'data.parquet'))
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Pipeline.load</span><span class="signature">(self, path=None, slim=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Pipelineloadmod"></i></span>
</h3>
<p>Load pipeline.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>path</b></span>: <span class="datatype"><i>String, optional</i></span> Path where the pipeline should be loaded from. Can be a path to a pipeline directory or pipeline pickle file. <br>
<span class="argument"><b>slim</b></span>: <span class="datatype"><i>Bool, default False</i></span> If True, will not load predictions, data and shapvalues. Generally not needed for prediction, but useful for inspection or visualization. </p>


    <div class="modal fade bd-example-modal-lg" id="Pipelineloadmod" tabindex="-1" role="dialog" aria-labelledby="PipelineloadLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Pipelineload</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def load(self, path=None, slim=False):
        
        logging.info('Loading pipeline')
        paths = path.split('/')
        storage = '/'.join(paths[:-1])

        # Load pickle file
        if paths[-1].endswith('.pkl'):
            name = paths[-1][:-4]
            with open(os.path.join(storage, f'{name}.pkl'), 'rb') as f:
                self = pickle.load(f)
            self.name = paths[-1][:-4]
            return self

        # Load files
        self.name = paths[-1]
        path = os.path.join(storage, self.name)

        with open(os.path.join(path, 'params.json'), 'r') as f:
            self.params = dict_map(json.load(f))

        # Load transformers
        self.transformers = {}
        transform_path = os.path.join(path, 'transform')
        for name in self.params['transform']:
            self.transformers[name] = TransformEnum[name].value()
            self.transformers[name].load(transform_path)

        # Load models
        self.models, self.cal_models = {}, {}
        model_dirs = [f for f in os.listdir(path) if os.path.isdir(f'{path}/{f}') and f != 'transform']
        for model_dir in model_dirs:
            with open(os.path.join(path, model_dir, 'model.json'), 'r') as f:
                algorithm = json.load(f)['algorithm']
            model = ModelEnum[algorithm].value(model_dir).load(os.path.join(path, model_dir), slim=slim)
            if model_dir=='stack': self.stack_model = model
            elif model_dir.startswith('C_'): self.cal_models[model.name[2:]] = model
            else: self.models[model.name] = model
        if not slim and 'data.parquet' in os.listdir(path):
            self.data = Data(os.path.join(path, 'data.parquet'), 'Data')
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Bootstraptab" role="tabpanel" aria-labelledby="Bootstraptab" tabindex="0">
<p><h3>
<span class="function">Bootstrap</span><span class="signature">(storage=None, logparams=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Bootstrapmod"></i></span>
</h3><p>This class collects methods for bootstrapping pipelines.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>storage</b></span>: <span class="datatype"><i>String, optional</i></span> Path to where the bootstrap should be saved to or loaded from. <br>
<span class="argument"><b>logparams</b></span>: <span class="datatype"><i>Dict, optional</i></span> Dictionary of parameters that are given to the set_logging function when learning a pipeline. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Bootstrap.pipe</b></span>: <span class="datatype"><i>lfd.Pipeline</i></span> Pipeline object which is used multiple times over to iterate. <br>
<span class="argument"><b>Bootstrap.storage</b></span>: <span class="datatype"><i>String</i></span> Path to directory where the bootstrap can be saved or loaded from. <br>
<span class="argument"><b>Bootstrap.log_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters that set logging, and is given to config.set_params(). </p>


    <div class="modal fade bd-example-modal-lg" id="Bootstrapmod" tabindex="-1" role="dialog" aria-labelledby="BootstrapLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Bootstrap</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Bootstrap:
    
    def __init__(self, storage=None, logparams=None):
        self.pipe = None
        self.storage = storage
        if not os.path.exists(storage): os.mkdir(storage)
        self._experiments = [c for c in os.listdir(self.storage) if not '.' in c]
        self.logparams = logparams if logparams else dict(stdout=False, log_dir=None)
        set_logging(**self.logparams)

    def learn_pipelines(self, data, params, data_iters=1, model_iters=1, 
                         cutoff_params=None, method=None):
        
        for _ in tqdm(np.arange(data_iters), 'Data Iterations'):
            self.pipe = Pipeline(logparams=self.logparams)
            self.pipe.set_aside = params['set_aside']
            
            self.pipe._set_data(dict_sample(params['data']), data=data.copy())
            self.pipe._learn_transform(dict_sample(params['transform']))
            
            for __ in tqdm(np.arange(model_iters), 'Model Iterations'):
                experiment = datetime.strftime(datetime.now(), '%y%m%d_%H%M%S_%f')
                self._experiments.append(experiment)
                self.pipe._learn_model(dict_sample(params['model']), cutoff_params)
                self.pipe.save(self.storage, name=experiment, as_pickle=False, slim=True)
                if method: self.pipe = method(self.pipe)
                np.random.seed(int(experiment[-6:]))  # Reset seed after every experiment

        return self

    def _get_features(self, aggregate=False, model='Xgboost'):
        
        features_df = pd.DataFrame()
        for i, experiment in enumerate(self._experiments):
            path_e = os.path.join(self.storage, f'{experiment}')
            features = pd.read_csv(os.path.join(path_e, model, 'features.csv'), index_col=0, squeeze=True)
            features_df = features_df.append(features.rename(experiment))
        if aggregate: features_df = features_df.mean().abs().sort_values(ascending=False)
        return features_df

    def _get_metrics(self):
        
        metrics_df = []
        for i, experiment in enumerate(self._experiments):
            path_e = os.path.join(self.storage, f'{experiment}')
            models = [m for m in os.listdir(path_e) if \
                      os.path.isdir(os.path.join(path_e, m)) and not re.match(r'^(\.)', m) and m != 'transform']
            metrics = pd.concat(([pd.read_csv(os.path.join(path_e, m, 'metrics.csv'), index_col=0, header=[0, 1]
                                             ) for m in models]), keys=models, names=['model'])
            metrics_df.append(metrics)
            if (i+1)%1000==0: logging.info(f'{i+1} metric experiments read.')
        logging.info(f'All {i+1} metric experiments read.')
        metrics_df = pd.concat((metrics_df), keys=self._experiments, names=['experiment'])
        return metrics_df

    def _get_params(self):
        
        params_df = pd.DataFrame()
        for i, experiment in enumerate(self._experiments):
            with open(os.path.join(self.storage, experiment, 'params.json'), 'r') as f:
                params = pd.Series(dict_flatten(dict_map(json.load(f))), name=experiment)
            params_df = params_df._append(params)
            if (i+1)%1000==0: logging.info(f'{i+1} parameter experiments read.')
        logging.info(f'All {i+1} parameter experiments read.')
        return params_df

    def get_meta(self, model, metrics=None, dataset='Test', predictions=None, include_seeds=False):
                
        # Gather params and metrics
        params = self._get_params()
        metrics_df = self._get_metrics().xs((model, dataset), level=['model', 'dataset'])
        
        # Collect predictions and metrics if not given
        predictions = metrics_df.columns.levels[0][0] if predictions is None else predictions
        metrics = metrics_df.columns.levels[1] if metrics is None else metrics
        
        # Join two datasets, 1 line per experiment
        meta = metrics_df[predictions][metrics].join(params)
        if not include_seeds: meta = meta.iloc[:, ~meta.columns.str.contains('seed|SEED')]
        meta = Data(meta, name='Meta')
        #meta.df = meta.df.sort_values(metrics_df.columns, ascending=False)
        meta = UniSelector().learn(meta, min_occ=0.01, max_occ=0.99, include_missings=False).apply(meta)
        return meta
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Bootstrap.learn_pipelines</span><span class="signature">(self, data, params, data_iters=1, model_iters=1, cutoff_params=None, method=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Bootstraplearn_pipelinesmod"></i></span>
</h3>
<p>Learns a number of pipelines with the goal of finding an optimum in parameter space.
Reasons to learn multiple pipelines: Get insight in 1. number of rows to train on, 
2. number of features to train on, 3. what hyper parameters to use for the modelling 
algorithm and 4. to have a robust evaluation with random cross-validation.
Total number of pipeline iterations is data_iters * model_iters.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object used for each of the pipeline iterations. <br>
<span class="argument"><b>params</b></span>: <span class="datatype"><i>Dict[]</i></span> Parameters in dictionary used in underlying data, transform and modelling functions. See Config.get_params() on how to format. At least one of the parameters should be a numpy array to make bootstrap useful. <br>
<span class="argument"><b>data_iters</b></span>: <span class="datatype"><i>Int, default 1</i></span> Number of times the data is split, sampled, balanced an transformed. <br>
<span class="argument"><b>model_iters</b></span>: <span class="datatype"><i>Int, default 1</i></span> Number of times - per data iteration - that the models are trained. <br>
<span class="argument"><b>cutoff_params</b></span>: <span class="datatype"><i>Dict[String: List[Float]]</i></span> Dictionary of cutoff parameters for binary classification. See Model.apply. A list for fixed recalls, precisions, flags and betas can be given. <br>
<span class="argument"><b>method</b></span>: <span class="datatype"><i>Function, optional</i></span> Arbitrary function that is applied to each lfd.Pipe object before saving. </p>


    <div class="modal fade bd-example-modal-lg" id="Bootstraplearn_pipelinesmod" tabindex="-1" role="dialog" aria-labelledby="Bootstraplearn_pipelinesLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Bootstraplearn_pipelines</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn_pipelines(self, data, params, data_iters=1, model_iters=1, 
                         cutoff_params=None, method=None):
        
        for _ in tqdm(np.arange(data_iters), 'Data Iterations'):
            self.pipe = Pipeline(logparams=self.logparams)
            self.pipe.set_aside = params['set_aside']
            
            self.pipe._set_data(dict_sample(params['data']), data=data.copy())
            self.pipe._learn_transform(dict_sample(params['transform']))
            
            for __ in tqdm(np.arange(model_iters), 'Model Iterations'):
                experiment = datetime.strftime(datetime.now(), '%y%m%d_%H%M%S_%f')
                self._experiments.append(experiment)
                self.pipe._learn_model(dict_sample(params['model']), cutoff_params)
                self.pipe.save(self.storage, name=experiment, as_pickle=False, slim=True)
                if method: self.pipe = method(self.pipe)
                np.random.seed(int(experiment[-6:]))  # Reset seed after every experiment

        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Bootstrap.get_meta</span><span class="signature">(self, model, metrics=None, dataset='Test', predictions=None, include_seeds=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Bootstrapget_metamod"></i></span>
</h3>
<p>This function assumes a iterate_pipeline has run (or is still running).
It combines all parameters and resulting metrics of those stored pipelines into 
a single pandas DataFrame. This could be used for hyperparameter selection.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>model</b></span>: <span class="datatype"><i>String</i></span> Which model for which the metrics and params should be read. <br>
<span class="argument"><b>metrics</b></span>: <span class="datatype"><i>String, optional</i></span> Which metrics should be used, e.g. 'accuracy'. If not given, all metrics available will be part of the output table. <br>
<span class="argument"><b>dataset</b></span>: <span class="datatype"><i>String, default 'Test'</i></span> For which dataset, e.g. 'Test' or 'Train' the table should be made. <br>
<span class="argument"><b>predictions</b></span>: <span class="datatype"><i>String, optional</i></span> For which predictions the table should be made, e.g. 'predictions_rec0.16' If not given, the first available prediction set is used. <br>
<span class="argument"><b>include_seeds</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to include varying seeds over the experiments in the output table. Can be usefull to assess cross validation or reproducibility. </p>


    <div class="modal fade bd-example-modal-lg" id="Bootstrapget_metamod" tabindex="-1" role="dialog" aria-labelledby="Bootstrapget_metaLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Bootstrapget_meta</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def get_meta(self, model, metrics=None, dataset='Test', predictions=None, include_seeds=False):
                
        # Gather params and metrics
        params = self._get_params()
        metrics_df = self._get_metrics().xs((model, dataset), level=['model', 'dataset'])
        
        # Collect predictions and metrics if not given
        predictions = metrics_df.columns.levels[0][0] if predictions is None else predictions
        metrics = metrics_df.columns.levels[1] if metrics is None else metrics
        
        # Join two datasets, 1 line per experiment
        meta = metrics_df[predictions][metrics].join(params)
        if not include_seeds: meta = meta.iloc[:, ~meta.columns.str.contains('seed|SEED')]
        meta = Data(meta, name='Meta')
        #meta.df = meta.df.sort_values(metrics_df.columns, ascending=False)
        meta = UniSelector().learn(meta, min_occ=0.01, max_occ=0.99, include_missings=False).apply(meta)
        return meta
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Datatab" role="tabpanel" aria-labelledby="Datatab" tabindex="0">
<p><h3>
<span class="function">Data</span><span class="signature">(df=None, name='Data', type='tabular') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datamod"></i></span>
</h3><p>This class collects methods for data operations. It is provides extra functionality 
on top of pandas DataFrames, and has its data stored in the self.df attribute.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>df</b></span>: <span class="datatype"><i>pandas.DataFrame, lfd.Data, or String, optional</i></span> Source for the data, type will be inferred. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Data'</i></span> Arbitrary name for the data object that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Data.df</b></span>: <span class="datatype"><i>pandas.DataFrame</i></span> Stores the data. <br>
<span class="argument"><b>Data.name</b></span>: <span class="datatype"><i>String, default 'Data'</i></span> Name of the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Data.shape</b></span>: <span class="datatype"><i>Tuble[Int, Int]</i></span> Dimensions of the data, rows and columns. <br>
<span class="argument"><b>Data.type</b></span>: <span class="datatype"><i>String, default 'tabular'</i></span> Type of dataset, can be tabular, visual or graph <br>
<span class="argument"><b>Data.index</b></span>: <span class="datatype"><i>pandas.Index</i></span> Index of the data. <br>
<span class="argument"><b>Data.columns</b></span>: <span class="datatype"><i>pandas.Index</i></span> Columns of the data. </p>


    <div class="modal fade bd-example-modal-lg" id="Datamod" tabindex="-1" role="dialog" aria-labelledby="DataLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Data</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Data:
    
    def __init__(self, df=None, name='Data', type='tabular'):
        self.df = None
        self.name = None
        self.type = type
        self.load(df, name)

    @property
    def shape(self): return self.df.shape

    @property
    def index(self): return self.df.index

    @property
    def columns(self): return self.df.columns

    @property
    def cont_columns(self): return [c for c in self.df.columns if self.df[c].dtype.kind in 'iufc']

    @property
    def cat_columns(self): return [c for c in self.df.columns if self.df[c].dtype.kind not in 'iufc']

    @classmethod
    def merge(cls, data_objects, merge_types, prefixes=None, name='Merged'):
        
        prefixes = ['' for _ in data_objects] if prefixes is None else prefixes
        df = data_objects.pop(0).df.add_prefix(prefixes.pop(0))
        logging.info(f'Starting from shape {df.shape}')
        for i, new_df in enumerate(data_objects):
            df = pd.merge(
                df, new_df.df.add_prefix(prefixes[i]), how=merge_types[i],
                left_index=True, right_index=True, validate='one_to_one')
            logging.info(f'Data for {prefixes[i]} is {merge_types[i]} merged, shape is {df.shape}')

        # Remove categories that might be lost because of lost rows due to merging
        for var in df.select_dtypes('category').columns:
            df[var] = df[var].cat.remove_unused_categories()
            df[var].cat.set_categories(df[var].cat.categories.astype(str))
        return Data(df, name, self.type)

    def split(self, subset='Train', mask=None, test_size=None, stratify_col=None, 
              names=('Train', 'Test'), seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - splitting into {names[0]} and {names[1]}')
        from sklearn.model_selection import train_test_split

        # If data has no dataset index yet, add one
        if not isinstance(self.df.index, pd.MultiIndex): 
            self.add_index('dataset', subset)
        
        if mask is not None:
            mask = eval(mask) if type(mask)==str else mask
        elif test_size is not None:
            all_indices = np.arange(len(self.df.loc[subset]))
            indices = train_test_split(all_indices,
                test_size=test_size, random_state=seed,
                stratify=self.df.loc[subset, stratify_col] if stratify_col else None)[0]
            mask = pd.Series(all_indices).isin(indices)
            
        # Take initial dataset index and overwrite with new dataset values
        self.df['dataset'] = self.df.index.get_level_values('dataset').astype(str)
        self.df.loc[subset, 'dataset'] = mask.replace(
            {True: names[0], False: names[1]}).values
        self.df['dataset'] = self.df['dataset'].astype('category')
        
        # Remove initial dataset index and replace with new one
        self.df.index = self.df.index.droplevel('dataset')
        self.df.set_index('dataset', append=True, inplace=True)
        self.df.index = self.df.index.swaplevel()
        
        # Print info on splits
        if stratify_col:
            logging.debug('\n'+tabulate(
                self.df.groupby([self.df.index.get_level_values('dataset'),
                                 self.df[stratify_col]]).size().unstack(),
                headers='keys', tablefmt='psql'))
        logging.debug('\n'+tabulate(
            self.df.index.get_level_values('dataset').value_counts().to_frame(),
            headers='keys', tablefmt='psql'))
        return self
            
    def balance(self, target, counts, stratified=None, name='Balanced', seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - balancing data: {counts}')
        assert target != stratified, "Stratified column cannot be the target"
        data = self.copy()

        samples = []
        if stratified:
            stratified_values = self.df[stratified].unique()
            n_values = len(stratified_values)
            for strat in stratified_values:
                temp = self.df[self.df[stratified]==strat]
                for value, count in counts.items():
                    newtemp = temp[temp[target]==value]
                    count /= n_values
                    sample = newtemp.sample(random_state=seed, n=int(count), replace=(count &amp;gt; len(newtemp)))
                    samples.append(sample)
        else:
            for value, count in counts.items():
                temp = self.df[self.df[target]==value]
                count = len(temp)*count if isinstance(count, float) else count
                if count&amp;lt;0.5: logging.warning(f'Trying to sample 0 rows for value {value}')
                sample = temp.sample(random_state=seed, n=int(count), replace=(count &amp;gt; len(temp)))
                samples.append(sample)
        data.df = pd.concat(samples, axis=0)
        if stratified: 
            logging.debug('\n' + tabulate(pd.crosstab(balanced[target], balanced[stratified]),
                                          headers='keys', tablefmt='psql'))
        return data
     
    def filter(self, mask, inplace=False):
        
        logging.info(f'{self.df.shape} - {self.name} - filtering data')

        assert len(mask)==len(self.df), 'Mask hasn\'t same length as data'
        logging.info(f'Keeping {mask.sum()} of {len(mask)} lines after filtering.')
        if inplace: self.df = self.df[mask]
        else: return Data(self.df[mask].copy(), self.name, self.type)
        
    def select(self, subset=None, axis=0, name=None, drop=False):
        
        data = self.copy()
        if axis==0: data.df = data.df.loc[subset]
        elif axis==1: data.df = data.df.loc[:, subset]
        if drop: self.df.drop(subset, axis=axis, inplace=True)
        return data

    def sample(self, n, replace=True, seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - sampling data')
        n, frac = (int(n), None) if n &amp;gt; 1 else (None, float(n))
        data = Data(self.df.sample(random_state=seed, n=n, frac=frac,replace=replace), self.name, self.type)
        return data

    @classmethod
    def concat(cls, data_objects, axis=1, keys=None, name='Concatenated'):
        
        data = Data(pd.concat([d.df for d in data_objects], axis=axis, keys=keys), name=name, type=self.type)
        return data

    def generate(self, n, name='Generated'):
        
        generated = pd.DataFrame()
        for var in self.df:
            generated[var] = np.random.choice(self.df[var].unique(), size=n)
        return Data(generated, name=name, type=self.type)
    
    def add_noise(self, seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - adding random noise')
        np.random.seed(seed)
        n = self.df.shape[0]
        self.df['RANDOM1'] = np.random.choice([0, 1], p=[0.5, 0.5], size=n)
        self.df['RANDOM2'] = np.random.choice([0, 1], p=[0.1, 0.9], size=n)
        self.df['RANDOM3'] = np.random.choice([0, 1], p=[0.95, 0.05], size=n)
        self.df['RANDOM4'] = np.random.normal(loc=1000, scale=500, size=n)
        self.df['RANDOM5'] = np.random.normal(loc=-500, scale=100, size=n)
        self.df['RANDOM6'] = np.random.normal(loc=0, scale=1, size=n)

    def apply_functions(self, functions):
        
        for function in functions:
            self.df = function(self.df)

    def save(self, file_name: str):
        
        logging.info('Saving data')
        if os.path.isdir(file_name):
            with open(os.path.join(file_name, f'meta.json'), 'w') as f:
                json.dump({
                    'name': self.name,
                    'type': self.type,
                    'shape': list(self.df.shape),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'memory': get_memory(self)
                }, f, indent=4)
            self.df.to_parquet(os.path.join(file_name, f'data.parquet'))

        extension = file_name.split('.')[-1]
        if extension == 'parquet':
            self.df.to_parquet(file_name)
        elif extension == 'csv':
            self.df.to_csv(file_name)
        else:
            logging.error('Did not recognize extensions. Write to .csv or .parquet.')
        self.df.to_parquet(file_name)

    
    def load(self, data, name='Data', nrows=None):
        
        if isinstance(data, pd.DataFrame):
            self.df = data
            self.name = name
        elif isinstance(data, Data):
            self.df = data.df
            self.name = name
        elif isinstance(data, str):
            if os.path.isdir(data):
                if 'meta.json' in os.listdir(data):
                    with open(os.path.join(data, 'meta.json'), 'r') as f:
                        json_data = json.load(f)
                        self.name = json_data['name']
                else:
                    self.name = name
                data = os.path.join(data, 'data.parquet') if 'data.parquet' in os.listdir(data) else os.path.join(data, 'data.csv')
            extension = data.split('.')[-1]
            if extension == 'parquet':
                logging.info(f'Reading parquet file: {data}')
                self.df = pd.read_parquet(data)
            elif extension == 'csv':
                logging.info(f'Reading csv file: {data}')
                self.df = pd.read_csv(data, index_col=0, nrows=nrows)
            else:
                logging.error('Only parquet and csv are implemented for now. Did not read any data.')
        else:
            self.df = pd.DataFrame()
            self.name = name
        return self

    def analyse(self, broken_by=None, bins=5, to_excel=True, path='analysis.xlsx'):
        
        logging.info(f'Generating analysis for {broken_by}')
        analysis = analyse(self.df, broken_by, bins)
        if to_excel:
            with pd.ExcelWriter(path, engine='xlsxwriter') as writer:
                analysis.to_excel(writer, sheet_name='Analysis')
                writer.save()
            logging.info(f'Analysis written to {path}')
        else: return analysis

    def copy(self):
        
        return deepcopy(self)

    def add_index(self, index, value):
        
        self.df[index] = value
        self.df.set_index(index, append=True, inplace=True)
        self.df.index = self.df.index.swaplevel()

    def set_dtypes(self):
        
        self.df = set_dtypes(self.df)

    def get_memory(self):
        
        return get_memory(self.df)

    def _summary(self):
        
        return pd.Series(dict(Name = self.name, Shape = self.df.shape, Type = self.type))
        
    def __repr__(self):
        print(f'This is a DATA object. Shape is {self.df.shape}.\n')
        display(pd.concat((self.df.head(3), self.df.tail(3))))
        return ''
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Data.merge</span><span class="signature">(data_objects, merge_types, prefixes=None, name='Merged') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datamergemod"></i></span>
</h3>
<p>Class method. Merging data objects together.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data_objects</b></span>: <span class="datatype"><i>List[lfd.Data]</i></span> List of data objects to merge. <br>
<span class="argument"><b>merge_types</b></span>: <span class="datatype"><i>List[String]</i></span> Elements should be in in ('left', 'inner', 'outer'). List of length same as data_objects minus 1, defining how to merge each table. <br>
<span class="argument"><b>prefixes</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of length same as data_objects, defining a prefix for column names per table. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Merged'</i></span> Name for the merged dataframe </p>


    <div class="modal fade bd-example-modal-lg" id="Datamergemod" tabindex="-1" role="dialog" aria-labelledby="DatamergeLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datamerge</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    @classmethod
    def merge(cls, data_objects, merge_types, prefixes=None, name='Merged'):
        
        prefixes = ['' for _ in data_objects] if prefixes is None else prefixes
        df = data_objects.pop(0).df.add_prefix(prefixes.pop(0))
        logging.info(f'Starting from shape {df.shape}')
        for i, new_df in enumerate(data_objects):
            df = pd.merge(
                df, new_df.df.add_prefix(prefixes[i]), how=merge_types[i],
                left_index=True, right_index=True, validate='one_to_one')
            logging.info(f'Data for {prefixes[i]} is {merge_types[i]} merged, shape is {df.shape}')

        # Remove categories that might be lost because of lost rows due to merging
        for var in df.select_dtypes('category').columns:
            df[var] = df[var].cat.remove_unused_categories()
            df[var].cat.set_categories(df[var].cat.categories.astype(str))
        return Data(df, name, self.type)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.split</span><span class="signature">(self, subset='Train', mask=None, test_size=None, stratify_col=None, names=('Train', 'Test'), seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datasplitmod"></i></span>
</h3>
<p>Split data object into 2 subsets, by creating or adding a dataset index. Additional 
memory usage is very limited this way.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>subset</b></span>: <span class="datatype"><i>String, default 'Train'</i></span> Which index to split in case a dataset index is present. If not present, it will use the whole dataset. <br>
<span class="argument"><b>mask</b></span>: <span class="datatype"><i>String or pandas.Series[Bool], optional</i></span> Identifying how the subset/dataset should be split. Can be a string too which will be evaluated, e.g. "self.df.year &amp;gt; 2021". If given, test_size is ignored. <br>
<span class="argument"><b>test_size</b></span>: <span class="datatype"><i>Float, optional</i></span> Only used if mask is None. Share of subset/dataset that is split randomly. <br>
<span class="argument"><b>stratify_col</b></span>: <span class="datatype"><i>String, optional</i></span> Variable that is optionally used to stratify the split, meaning the distribution of this variable will remain the same in each split. Often used for a model target. <br>
<span class="argument"><b>names</b></span>: <span class="datatype"><i>Tuple[String, String], default ('Train', 'Test')</i></span> Two strings that define the names in the dataset index of both splits. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when making the random split. Only used when splitting with test_size. </p>


    <div class="modal fade bd-example-modal-lg" id="Datasplitmod" tabindex="-1" role="dialog" aria-labelledby="DatasplitLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datasplit</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def split(self, subset='Train', mask=None, test_size=None, stratify_col=None, 
              names=('Train', 'Test'), seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - splitting into {names[0]} and {names[1]}')
        from sklearn.model_selection import train_test_split

        # If data has no dataset index yet, add one
        if not isinstance(self.df.index, pd.MultiIndex): 
            self.add_index('dataset', subset)
        
        if mask is not None:
            mask = eval(mask) if type(mask)==str else mask
        elif test_size is not None:
            all_indices = np.arange(len(self.df.loc[subset]))
            indices = train_test_split(all_indices,
                test_size=test_size, random_state=seed,
                stratify=self.df.loc[subset, stratify_col] if stratify_col else None)[0]
            mask = pd.Series(all_indices).isin(indices)
            
        # Take initial dataset index and overwrite with new dataset values
        self.df['dataset'] = self.df.index.get_level_values('dataset').astype(str)
        self.df.loc[subset, 'dataset'] = mask.replace(
            {True: names[0], False: names[1]}).values
        self.df['dataset'] = self.df['dataset'].astype('category')
        
        # Remove initial dataset index and replace with new one
        self.df.index = self.df.index.droplevel('dataset')
        self.df.set_index('dataset', append=True, inplace=True)
        self.df.index = self.df.index.swaplevel()
        
        # Print info on splits
        if stratify_col:
            logging.debug('\n'+tabulate(
                self.df.groupby([self.df.index.get_level_values('dataset'),
                                 self.df[stratify_col]]).size().unstack(),
                headers='keys', tablefmt='psql'))
        logging.debug('\n'+tabulate(
            self.df.index.get_level_values('dataset').value_counts().to_frame(),
            headers='keys', tablefmt='psql'))
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.balance</span><span class="signature">(self, target, counts, stratified=None, name='Balanced', seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Databalancemod"></i></span>
</h3>
<p>Balance data by combining over- and undersampling according to a target variable. Often
used to oversample low occurring target values and undersamply high occurring target values.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Column to use for balancing the data. <br>
<span class="argument"><b>count</b></span>: <span class="datatype"><i>Dict[Any: Integer or Float]</i></span> Defining the desired number or share of each value of the target column in the resulting data. <br>
<span class="argument"><b>stratified</b></span>: <span class="datatype"><i>String, optional</i></span> Define another column for which you want to retain its distribution. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Balanced'</i></span> Arbitrary name for the resulting balanced data object. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when over- &amp; undersampling. </p>


    <div class="modal fade bd-example-modal-lg" id="Databalancemod" tabindex="-1" role="dialog" aria-labelledby="DatabalanceLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Databalance</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def balance(self, target, counts, stratified=None, name='Balanced', seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - balancing data: {counts}')
        assert target != stratified, "Stratified column cannot be the target"
        data = self.copy()

        samples = []
        if stratified:
            stratified_values = self.df[stratified].unique()
            n_values = len(stratified_values)
            for strat in stratified_values:
                temp = self.df[self.df[stratified]==strat]
                for value, count in counts.items():
                    newtemp = temp[temp[target]==value]
                    count /= n_values
                    sample = newtemp.sample(random_state=seed, n=int(count), replace=(count &amp;gt; len(newtemp)))
                    samples.append(sample)
        else:
            for value, count in counts.items():
                temp = self.df[self.df[target]==value]
                count = len(temp)*count if isinstance(count, float) else count
                if count&amp;lt;0.5: logging.warning(f'Trying to sample 0 rows for value {value}')
                sample = temp.sample(random_state=seed, n=int(count), replace=(count &amp;gt; len(temp)))
                samples.append(sample)
        data.df = pd.concat(samples, axis=0)
        if stratified: 
            logging.debug('\n' + tabulate(pd.crosstab(balanced[target], balanced[stratified]),
                                          headers='keys', tablefmt='psql'))
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.filter</span><span class="signature">(self, mask, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datafiltermod"></i></span>
</h3>
<p>Filter rows of data object according to a boolean mask. 
Either returns a filtered data object or filters in place.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>mask</b></span>: <span class="datatype"><i>pandas.Series[Bool]</i></span> Identifying which rows to filter. <br>
<span class="argument"><b>inplace</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to apply the filtering in place. </p>


    <div class="modal fade bd-example-modal-lg" id="Datafiltermod" tabindex="-1" role="dialog" aria-labelledby="DatafilterLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datafilter</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def filter(self, mask, inplace=False):
        
        logging.info(f'{self.df.shape} - {self.name} - filtering data')

        assert len(mask)==len(self.df), 'Mask hasn\'t same length as data'
        logging.info(f'Keeping {mask.sum()} of {len(mask)} lines after filtering.')
        if inplace: self.df = self.df[mask]
        else: return Data(self.df[mask].copy(), self.name, self.type)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.select</span><span class="signature">(self, subset=None, axis=0, name=None, drop=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataselectmod"></i></span>
</h3>
<p>Selects from data object on index or columns.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>subset</b></span>: <span class="datatype"><i>Any, whatever the index dtype is.</i></span> Loc identifier for selecting from data object <br>
<span class="argument"><b>axis</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Which axis to select from. Rows with 0, columns with 1. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Arbitrary and optional new name for the resulting selected data object. <br>
<span class="argument"><b>drop</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether the index of the selected subset should be retained. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataselectmod" tabindex="-1" role="dialog" aria-labelledby="DataselectLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataselect</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def select(self, subset=None, axis=0, name=None, drop=False):
        
        data = self.copy()
        if axis==0: data.df = data.df.loc[subset]
        elif axis==1: data.df = data.df.loc[:, subset]
        if drop: self.df.drop(subset, axis=axis, inplace=True)
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.sample</span><span class="signature">(self, n, replace=True, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datasamplemod"></i></span>
</h3>
<p>Sample random rows from data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>n</b></span>: <span class="datatype"><i>Integer or Float</i></span> How many rows (in case of integer) or what share of the dataset (in case of float) to sample. <br>
<span class="argument"><b>replace</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether rows are replaced and thus could be sampled more than once. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when sampling. </p>


    <div class="modal fade bd-example-modal-lg" id="Datasamplemod" tabindex="-1" role="dialog" aria-labelledby="DatasampleLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datasample</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def sample(self, n, replace=True, seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - sampling data')
        n, frac = (int(n), None) if n &amp;gt; 1 else (None, float(n))
        data = Data(self.df.sample(random_state=seed, n=n, frac=frac,replace=replace), self.name, self.type)
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.concat</span><span class="signature">(data_objects, axis=1, keys=None, name='Concatenated') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataconcatmod"></i></span>
</h3>
<p>Class method. Concatenate data objects.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data_objects</b></span>: <span class="datatype"><i>List[lfd.Data]</i></span> List of data objects to concatenate. <br>
<span class="argument"><b>axis</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Which axis to concatenate in. Rows with 0, columns with 1. keys: List[String] Names to add as multiindex level after concatenation <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Arbitrary and optional new name for the resulting concatenated data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataconcatmod" tabindex="-1" role="dialog" aria-labelledby="DataconcatLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataconcat</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    @classmethod
    def concat(cls, data_objects, axis=1, keys=None, name='Concatenated'):
        
        data = Data(pd.concat([d.df for d in data_objects], axis=axis, keys=keys), name=name, type=self.type)
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.generate</span><span class="signature">(self, n, name='Generated') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datageneratemod"></i></span>
</h3>
<p>Generate a random data object based on an existing one by sampling randomly from its values.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>n</b></span>: <span class="datatype"><i>Integer</i></span> How many rows the new data object should contain. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Arbitrary and optional new name for the generated data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Datageneratemod" tabindex="-1" role="dialog" aria-labelledby="DatagenerateLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datagenerate</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def generate(self, n, name='Generated'):
        
        generated = pd.DataFrame()
        for var in self.df:
            generated[var] = np.random.choice(self.df[var].unique(), size=n)
        return Data(generated, name=name, type=self.type)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.add_noise</span><span class="signature">(self, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataadd_noisemod"></i></span>
</h3>
<p>Add 6 random variables to a data object, 3 categorical and 3 continuous ones.
Often used to assess where random variables show up in a model's feature importance.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when sampling. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataadd_noisemod" tabindex="-1" role="dialog" aria-labelledby="Dataadd_noiseLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataadd_noise</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def add_noise(self, seed=0):
        
        logging.info(f'{self.df.shape} - {self.name} - adding random noise')
        np.random.seed(seed)
        n = self.df.shape[0]
        self.df['RANDOM1'] = np.random.choice([0, 1], p=[0.5, 0.5], size=n)
        self.df['RANDOM2'] = np.random.choice([0, 1], p=[0.1, 0.9], size=n)
        self.df['RANDOM3'] = np.random.choice([0, 1], p=[0.95, 0.05], size=n)
        self.df['RANDOM4'] = np.random.normal(loc=1000, scale=500, size=n)
        self.df['RANDOM5'] = np.random.normal(loc=-500, scale=100, size=n)
        self.df['RANDOM6'] = np.random.normal(loc=0, scale=1, size=n)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.apply_functions</span><span class="signature">(self, functions) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataapply_functionsmod"></i></span>
</h3>
<p>Apply multiple functions on a data object, useful for custom logic.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>functions</b></span>: <span class="datatype"><i>List[Function]</i></span> List of functions to apply on a data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataapply_functionsmod" tabindex="-1" role="dialog" aria-labelledby="Dataapply_functionsLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataapply_functions</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply_functions(self, functions):
        
        for function in functions:
            self.df = function(self.df)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.save</span><span class="signature">(self, file_name: str) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datasavemod"></i></span>
</h3>
<p>Saves a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>file_name</b></span>: <span class="datatype"><i>String</i></span> Path where the data should be written. Depending on the given extension, it saves a CSV or Parquet file. </p>


    <div class="modal fade bd-example-modal-lg" id="Datasavemod" tabindex="-1" role="dialog" aria-labelledby="DatasaveLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datasave</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def save(self, file_name: str):
        
        logging.info('Saving data')
        if os.path.isdir(file_name):
            with open(os.path.join(file_name, f'meta.json'), 'w') as f:
                json.dump({
                    'name': self.name,
                    'type': self.type,
                    'shape': list(self.df.shape),
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'memory': get_memory(self)
                }, f, indent=4)
            self.df.to_parquet(os.path.join(file_name, f'data.parquet'))

        extension = file_name.split('.')[-1]
        if extension == 'parquet':
            self.df.to_parquet(file_name)
        elif extension == 'csv':
            self.df.to_csv(file_name)
        else:
            logging.error('Did not recognize extensions. Write to .csv or .parquet.')
        self.df.to_parquet(file_name)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.load</span><span class="signature">(self, data, name='Data', nrows=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataloadmod"></i></span>
</h3>
<p>Loads a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>pandas.DataFrame, lfd.Data, or String</i></span> Source for the data, type will be inferred. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Data'</i></span> Arbitrary name for the data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataloadmod" tabindex="-1" role="dialog" aria-labelledby="DataloadLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataload</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def load(self, data, name='Data', nrows=None):
        
        if isinstance(data, pd.DataFrame):
            self.df = data
            self.name = name
        elif isinstance(data, Data):
            self.df = data.df
            self.name = name
        elif isinstance(data, str):
            if os.path.isdir(data):
                if 'meta.json' in os.listdir(data):
                    with open(os.path.join(data, 'meta.json'), 'r') as f:
                        json_data = json.load(f)
                        self.name = json_data['name']
                else:
                    self.name = name
                data = os.path.join(data, 'data.parquet') if 'data.parquet' in os.listdir(data) else os.path.join(data, 'data.csv')
            extension = data.split('.')[-1]
            if extension == 'parquet':
                logging.info(f'Reading parquet file: {data}')
                self.df = pd.read_parquet(data)
            elif extension == 'csv':
                logging.info(f'Reading csv file: {data}')
                self.df = pd.read_csv(data, index_col=0, nrows=nrows)
            else:
                logging.error('Only parquet and csv are implemented for now. Did not read any data.')
        else:
            self.df = pd.DataFrame()
            self.name = name
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.analyse</span><span class="signature">(self, broken_by=None, bins=5, to_excel=True, path='analysis.xlsx') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataanalysemod"></i></span>
</h3>
<p>Analyse variables with respect to a given variable.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>broken_by</b></span>: <span class="datatype"><i>String, optional</i></span> Variable by which all other variables should be broken. Should not be a continuous variable. <br>
<span class="argument"><b>bins</b></span>: <span class="datatype"><i>Integer, default 5</i></span> Number of bins to bin continuous variables into. <br>
<span class="argument"><b>to_excel</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to store the analysis in an excel file. If False, the dataframe will be returned. <br>
<span class="argument"><b>path</b></span>: <span class="datatype"><i>String, default 'analysis.xlsx'</i></span> Path to excel file to store the analysis. Only used if to_excel=True. </p>


    <div class="modal fade bd-example-modal-lg" id="Dataanalysemod" tabindex="-1" role="dialog" aria-labelledby="DataanalyseLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataanalyse</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def analyse(self, broken_by=None, bins=5, to_excel=True, path='analysis.xlsx'):
        
        logging.info(f'Generating analysis for {broken_by}')
        analysis = analyse(self.df, broken_by, bins)
        if to_excel:
            with pd.ExcelWriter(path, engine='xlsxwriter') as writer:
                analysis.to_excel(writer, sheet_name='Analysis')
                writer.save()
            logging.info(f'Analysis written to {path}')
        else: return analysis
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.copy</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Datacopymod"></i></span>
</h3>
<p>Create a hard copy of a data object.</p>
<p><span class="attributes">Arguments</span></p>


    <div class="modal fade bd-example-modal-lg" id="Datacopymod" tabindex="-1" role="dialog" aria-labelledby="DatacopyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Datacopy</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def copy(self):
        
        return deepcopy(self)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.add_index</span><span class="signature">(self, index, value) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataadd_indexmod"></i></span>
</h3>
<p></p>

    <div class="modal fade bd-example-modal-lg" id="Dataadd_indexmod" tabindex="-1" role="dialog" aria-labelledby="Dataadd_indexLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataadd_index</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def add_index(self, index, value):
        
        self.df[index] = value
        self.df.set_index(index, append=True, inplace=True)
        self.df.index = self.df.index.swaplevel()
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.set_dtypes</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataset_dtypesmod"></i></span>
</h3>
<p>Sets the categorical dtype for categorical variables, and downsize numeric variables.</p>
<p><span class="attributes">Arguments</span></p>


    <div class="modal fade bd-example-modal-lg" id="Dataset_dtypesmod" tabindex="-1" role="dialog" aria-labelledby="Dataset_dtypesLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataset_dtypes</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def set_dtypes(self):
        
        self.df = set_dtypes(self.df)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Data.get_memory</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Dataget_memorymod"></i></span>
</h3>
<p>Return a string with information on the size of the object.</p>
<p><span class="attributes">Arguments</span></p>


    <div class="modal fade bd-example-modal-lg" id="Dataget_memorymod" tabindex="-1" role="dialog" aria-labelledby="Dataget_memoryLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Dataget_memory</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def get_memory(self):
        
        return get_memory(self.df)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Transformertab" role="tabpanel" aria-labelledby="Transformertab" tabindex="0">
<p><h3>
<span class="function">Transformer</span><span class="signature">(name='Transformer') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Transformermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Transformermod" tabindex="-1" role="dialog" aria-labelledby="TransformerLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Transformer</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Transformer:
        
    def __init__(self, name='Transformer'):
        self.params = {}
        self.name = name

    def learn(self, X):
        
        logging.info(f'{X.df.shape} - {X.name} - learning {self.name}')

    def apply(self, X):
        
        logging.info(f'{X.df.shape} - {X.name} - applying {self.name}')
    
    def save(self, storage):
        
        with open(os.path.join(storage, f'{self.name}.json'), 'w') as f:
            json.dump(self.__dict__, f, indent=4)
    
    def load(self, storage):
        
        with open(os.path.join(storage, f'{self.name}.json'), 'r') as f:
            self.__dict__.update(json.load(f))
        return self

    def _summary(self):
        
        return pd.Series(dict(
            Name = self.name,
            Attributes = ", ".join([a for a in self.__dict__.keys() if a not in ('name', 'params')]),
            Parameters = ", ".join([f'{k}: {v}' for k, v in self.params.items()]),
        ))

    def __repr__(self):
        string = 'This is a TRANSFORM object.\n'
        string += tabulate(self._summary().to_frame(), tablefmt='simple_outline')
        return string
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Transformer.learn</span><span class="signature">(self, X) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Transformerlearnmod"></i></span>
</h3>
<p>Learn a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used to learn the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Transformerlearnmod" tabindex="-1" role="dialog" aria-labelledby="TransformerlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Transformerlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X):
        
        logging.info(f'{X.df.shape} - {X.name} - learning {self.name}')
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Transformer.apply</span><span class="signature">(self, X) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Transformerapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Transformerapplymod" tabindex="-1" role="dialog" aria-labelledby="TransformerapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Transformerapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X):
        
        logging.info(f'{X.df.shape} - {X.name} - applying {self.name}')
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Transformer.save</span><span class="signature">(self, storage) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Transformersavemod"></i></span>
</h3>
<p>Save transformer.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>storage</b></span>: <span class="datatype"><i>String</i></span> Directory where the transformer should be saved. </p>


    <div class="modal fade bd-example-modal-lg" id="Transformersavemod" tabindex="-1" role="dialog" aria-labelledby="TransformersaveLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Transformersave</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def save(self, storage):
        
        with open(os.path.join(storage, f'{self.name}.json'), 'w') as f:
            json.dump(self.__dict__, f, indent=4)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Transformer.load</span><span class="signature">(self, storage) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Transformerloadmod"></i></span>
</h3>
<p>Load transformer.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>storage</b></span>: <span class="datatype"><i>String</i></span> Directory where the transformer should be loaded from. </p>


    <div class="modal fade bd-example-modal-lg" id="Transformerloadmod" tabindex="-1" role="dialog" aria-labelledby="TransformerloadLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Transformerload</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def load(self, storage):
        
        with open(os.path.join(storage, f'{self.name}.json'), 'r') as f:
            self.__dict__.update(json.load(f))
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="UniSelectortab" role="tabpanel" aria-labelledby="UniSelectortab" tabindex="0">
<p><h3>
<span class="function">UniSelector</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#UniSelectormod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="UniSelectormod" tabindex="-1" role="dialog" aria-labelledby="UniSelectorLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">UniSelector</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class UniSelector(Transformer):

    def __init__(self):
        super().__init__('uniselector')
        self.columns = []

    def learn(self, X, min_occ=0.01, max_occ=0.99, include_missings=True, variable_select=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(min_occ=min_occ, max_occ=max_occ, include_missings=include_missings, variable_select=variable_select)
        self.columns = []
        
        # Hard select variables if given.
        if variable_select:
            assert type(variable_select)==list, 'variable_select is not a list'
            self.columns = list(variable_select)
            if set_aside: self.columns += set_aside
            return self
        
        # If hard select is not given, perform data-wase uni selection
        constant_vars = []
        low_variation_vars = []
        high_variation_vars = []
        
        # Loop through variables and decide whether to keep
        for var in X.df.columns:
            if type(set_aside)==list and var in set_aside:
                self.columns.append(var)
                continue
            shares = X.df[var].value_counts(normalize=True, dropna=not include_missings)
            if len(shares)&amp;lt;=1:  # Variables is constant
                constant_vars.append(var)
            elif shares.iloc[0] &amp;gt; max_occ:  # Var has low variation
                low_variation_vars.append(var)
            elif X.df[var].dtype.name in ('object', 'category') and shares.iloc[0] &amp;lt; min_occ: # Var has high variation
                high_variation_vars.append(var)
            else: self.columns.append(var)
            
        logging.debug(f'Constant variables: {len(constant_vars)}, {constant_vars}')
        logging.debug(f'Low variation variables {len(low_variation_vars)}, {low_variation_vars}')
        logging.debug(f'High variation variables: {len(high_variation_vars)}, {high_variation_vars}')
        return self

    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        data.df = data.df[[c for c in self.columns if c in X.df]]
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">UniSelector.learn</span><span class="signature">(self, X, min_occ=0.01, max_occ=0.99, include_missings=True, variable_select=None, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#UniSelectorlearnmod"></i></span>
</h3>
<p>This function learns which variables should be selected.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on <br>
<span class="argument"><b>min_occ</b></span>: <span class="datatype"><i>Float, default 0.01</i></span> Minimum occurrence that the highest occurring value must have. If it doesn't reach this, the variable is considered too variable and thrown out. <br>
<span class="argument"><b>max_occ</b></span>: <span class="datatype"><i>Float, default 0.99</i></span> Maximum occurrence that the highest occurring value can have. If it exceeds this, the variable is considered too constant and thrown out. <br>
<span class="argument"><b>include_missings</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to include missing values as a value to consider in the variation calculation. <br>
<span class="argument"><b>variable_select</b></span>: <span class="datatype"><i>List[Strings], optional</i></span> This is a way to hard-select variables. If given, the other parameters are ignored. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="UniSelectorlearnmod" tabindex="-1" role="dialog" aria-labelledby="UniSelectorlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">UniSelectorlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, min_occ=0.01, max_occ=0.99, include_missings=True, variable_select=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(min_occ=min_occ, max_occ=max_occ, include_missings=include_missings, variable_select=variable_select)
        self.columns = []
        
        # Hard select variables if given.
        if variable_select:
            assert type(variable_select)==list, 'variable_select is not a list'
            self.columns = list(variable_select)
            if set_aside: self.columns += set_aside
            return self
        
        # If hard select is not given, perform data-wase uni selection
        constant_vars = []
        low_variation_vars = []
        high_variation_vars = []
        
        # Loop through variables and decide whether to keep
        for var in X.df.columns:
            if type(set_aside)==list and var in set_aside:
                self.columns.append(var)
                continue
            shares = X.df[var].value_counts(normalize=True, dropna=not include_missings)
            if len(shares)&amp;lt;=1:  # Variables is constant
                constant_vars.append(var)
            elif shares.iloc[0] &amp;gt; max_occ:  # Var has low variation
                low_variation_vars.append(var)
            elif X.df[var].dtype.name in ('object', 'category') and shares.iloc[0] &amp;lt; min_occ: # Var has high variation
                high_variation_vars.append(var)
            else: self.columns.append(var)
            
        logging.debug(f'Constant variables: {len(constant_vars)}, {constant_vars}')
        logging.debug(f'Low variation variables {len(low_variation_vars)}, {low_variation_vars}')
        logging.debug(f'High variation variables: {len(high_variation_vars)}, {high_variation_vars}')
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">UniSelector.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#UniSelectorapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="UniSelectorapplymod" tabindex="-1" role="dialog" aria-labelledby="UniSelectorapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">UniSelectorapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        data.df = data.df[[c for c in self.columns if c in X.df]]
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Binnertab" role="tabpanel" aria-labelledby="Binnertab" tabindex="0">
<p><h3>
<span class="function">Binner</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Binnermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Binnermod" tabindex="-1" role="dialog" aria-labelledby="BinnerLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Binner</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Binner(Transformer):
    
    def __init__(self):
        super().__init__('binner')
        self.bin_intervals = {}
        self.bin_values = {}
        self.transform = False
        
    def learn(self, X, n_bins=10, min_prop=0.05, transform=True, predef_cuts=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(n_bins=n_bins, min_prop=min_prop, transform=transform, predef_cuts=predef_cuts)

        # Reset bins
        self.bin_intervals = {}
        if type(predef_cuts)==dict: self.bin_intervals.update(predef_cuts)
        self.bin_values = {}
        self.transform = transform
        if n_bins is None: return self
        n_bins = int(n_bins)
                        
        # Retrieve numerical variables to bin
        vars_bin = X.df.select_dtypes(['number']).columns
        if type(set_aside)==list: vars_bin = [c for c in vars_bin if c not in set_aside]
        if type(predef_cuts)==dict: vars_bin = [c for c in vars_bin if c not in predef_cuts.keys()]
        logging.debug(f'Attempting to bin following variables: {vars_bin}')
        
        # Learn intervals or values per variable
        for binvar in vars_bin:
            # Case with fewer unique values than bins
            if X.df[binvar].nunique() &amp;lt;= n_bins:
                logging.debug(f'Variable {binvar} has fewer unique values than {n_bins} desired bins! \
                    Creating a bin per value.')
                self.bin_values[binvar] = X.df[binvar].dropna().unique().tolist()
            else: # Case with more unique values than bins
                tot_len = X.df[binvar].notna().sum()
                for new_bins in np.arange(n_bins, 0, step=-1):
                    bins_series, cut_points = pd.qcut(
                        X.df[binvar], q=new_bins, retbins=True, duplicates='drop')
                    min_occ = bins_series.value_counts().min()
                    if(min_occ/tot_len &amp;gt;= min_prop):  # At new_bins=1, this condition will always be True
                        logging.debug(f'Variable {binvar} is binned into {new_bins} out of {n_bins} desired')
                        self.bin_intervals[binvar] = cut_points.tolist()
                        break
                if new_bins==1:
                    logging.debug(f'Could not bin {binvar}. There is only one category for {binvar}')
        return self
        
    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()

        for var, intervals in self.bin_intervals.items():
            labels = [f'b{i}' for i, _ in enumerate(intervals[:-1])]
            # _l{np.round(intervals[i], 2)}_r{np.round(intervals[i+1], 2)}
            data.df[var+'__binned'] = pd.cut(data.df[var], intervals, labels=labels, include_lowest=True)
            if self.transform: data.df.drop(var, inplace=True, axis=1)
            data.df[var+'__binned'].cat.set_categories(data.df[var+'__binned'].cat.categories.astype(str))
        for var, values in self.bin_values.items():
            data.df[var+'__binned'] = data.df[var].astype('category').cat.set_categories(values)
            if self.transform: data.df.drop(var, inplace=True, axis=1)
            data.df[var+'__binned'].cat.set_categories(data.df[var+'__binned'].cat.categories.astype(str))
        if not inplace: return data    
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Binner.learn</span><span class="signature">(self, X, n_bins=10, min_prop=0.05, transform=True, predef_cuts=None, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Binnerlearnmod"></i></span>
</h3>
<p>This function learns which variables to binn and which splitting points to use.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on. <br>
<span class="argument"><b>n_bins</b></span>: <span class="datatype"><i>Integer, default 10</i></span> Number of equal-sized bins to bin the variables into. This is the same for all continuous variables. <br>
<span class="argument"><b>min_prop</b></span>: <span class="datatype"><i>Float, default 0.05</i></span> Minimum the proportion each bin must have in order to preserve the bin. If not successful for n_bins, n_bins-1 will be attempted and so on. <br>
<span class="argument"><b>transform</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to add or transform the initial non-binned variables. <br>
<span class="argument"><b>predef_cuts</b></span>: <span class="datatype"><i>Dict[String: List[Float]], optional</i></span> Overwrite the determined cutting points according the selected method by predefined values. These must be provided in a dictionary; the key is the variable name, the value is a list with pre-defined cutting points. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="Binnerlearnmod" tabindex="-1" role="dialog" aria-labelledby="BinnerlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Binnerlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, n_bins=10, min_prop=0.05, transform=True, predef_cuts=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(n_bins=n_bins, min_prop=min_prop, transform=transform, predef_cuts=predef_cuts)

        # Reset bins
        self.bin_intervals = {}
        if type(predef_cuts)==dict: self.bin_intervals.update(predef_cuts)
        self.bin_values = {}
        self.transform = transform
        if n_bins is None: return self
        n_bins = int(n_bins)
                        
        # Retrieve numerical variables to bin
        vars_bin = X.df.select_dtypes(['number']).columns
        if type(set_aside)==list: vars_bin = [c for c in vars_bin if c not in set_aside]
        if type(predef_cuts)==dict: vars_bin = [c for c in vars_bin if c not in predef_cuts.keys()]
        logging.debug(f'Attempting to bin following variables: {vars_bin}')
        
        # Learn intervals or values per variable
        for binvar in vars_bin:
            # Case with fewer unique values than bins
            if X.df[binvar].nunique() &amp;lt;= n_bins:
                logging.debug(f'Variable {binvar} has fewer unique values than {n_bins} desired bins! \
                    Creating a bin per value.')
                self.bin_values[binvar] = X.df[binvar].dropna().unique().tolist()
            else: # Case with more unique values than bins
                tot_len = X.df[binvar].notna().sum()
                for new_bins in np.arange(n_bins, 0, step=-1):
                    bins_series, cut_points = pd.qcut(
                        X.df[binvar], q=new_bins, retbins=True, duplicates='drop')
                    min_occ = bins_series.value_counts().min()
                    if(min_occ/tot_len &amp;gt;= min_prop):  # At new_bins=1, this condition will always be True
                        logging.debug(f'Variable {binvar} is binned into {new_bins} out of {n_bins} desired')
                        self.bin_intervals[binvar] = cut_points.tolist()
                        break
                if new_bins==1:
                    logging.debug(f'Could not bin {binvar}. There is only one category for {binvar}')
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Binner.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Binnerapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Binnerapplymod" tabindex="-1" role="dialog" aria-labelledby="BinnerapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Binnerapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()

        for var, intervals in self.bin_intervals.items():
            labels = [f'b{i}' for i, _ in enumerate(intervals[:-1])]
            # _l{np.round(intervals[i], 2)}_r{np.round(intervals[i+1], 2)}
            data.df[var+'__binned'] = pd.cut(data.df[var], intervals, labels=labels, include_lowest=True)
            if self.transform: data.df.drop(var, inplace=True, axis=1)
            data.df[var+'__binned'].cat.set_categories(data.df[var+'__binned'].cat.categories.astype(str))
        for var, values in self.bin_values.items():
            data.df[var+'__binned'] = data.df[var].astype('category').cat.set_categories(values)
            if self.transform: data.df.drop(var, inplace=True, axis=1)
            data.df[var+'__binned'].cat.set_categories(data.df[var+'__binned'].cat.categories.astype(str))
        if not inplace: return data    
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Imputertab" role="tabpanel" aria-labelledby="Imputertab" tabindex="0">
<p><h3>
<span class="function">Imputer</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Imputermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Imputermod" tabindex="-1" role="dialog" aria-labelledby="ImputerLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Imputer</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Imputer(Transformer):
 
    def __init__(self):
        super().__init__('imputer')
        self.impute_values = {}
    
    def learn(self, X, default_cat='MISSING', default_cont='median', override=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(default_cat=default_cat, default_cont=default_cont, override=override)

        self.impute_values = {}
        set_aside = set_aside if set_aside else []

        # Retrieve categorical and numerical variables, asserting there are no others
        cat_vars = [c for c in X.df.select_dtypes(['object', 'category']).columns if c not in set_aside]
        cont_vars = [c for c in X.df.select_dtypes(['number']).columns if c not in set_aside]
        logging.debug(f'Storing imputation for {len(cat_vars)} categorical and {len(cont_vars)} continuous variables.')        
        
        # Update impute_values attribute with appropriate values
        for var in cat_vars:
            if X.df[var].isnull().sum()&amp;gt;0: self.impute_values.update({var: default_cat})
        if default_cont is not None:
            self.impute_values.update({v: float(X.df[v].mean()) if default_cont=='mean' \
                                       else float(X.df[v].median()) if default_cont=='median' \
                                       else float(default_cont) for v in cont_vars})
        
        # Override any given imputation values
        if type(override)==dict: self.impute_values.update(override)
        return self
    
    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()

        # Add missing value to categories if not present
        for var in data.df.select_dtypes('category').columns:
            if var in self.impute_values.keys() and self.impute_values[var] not in data.df[var].cat.categories:
                data.df[var] = data.df[var].cat.add_categories(self.impute_values[var])
        
        # Actual missing value imputation
        data.df.fillna(self.impute_values, inplace=True)
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Imputer.learn</span><span class="signature">(self, X, default_cat='MISSING', default_cont='median', override=None, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Imputerlearnmod"></i></span>
</h3>
<p>This function learns how to impute data for each given variable, 
and stores this information into an impute_values attribute.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on <br>
<span class="argument"><b>default_cat</b></span>: <span class="datatype"><i>String</i></span> Imputation value for all categorical variables. <br>
<span class="argument"><b>default_cont</b></span>: <span class="datatype"><i>String</i></span> Integer or Float or 'mean' or 'median'. Imputation value for all continuous variables. If 'mean' or 'median', these will be calculated. <br>
<span class="argument"><b>override</b></span>: <span class="datatype"><i>Dictionary.</i></span> Set a particular imputation value per feature. If this is filled in for a feature, this will override the default parameters. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="Imputerlearnmod" tabindex="-1" role="dialog" aria-labelledby="ImputerlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Imputerlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, default_cat='MISSING', default_cont='median', override=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(default_cat=default_cat, default_cont=default_cont, override=override)

        self.impute_values = {}
        set_aside = set_aside if set_aside else []

        # Retrieve categorical and numerical variables, asserting there are no others
        cat_vars = [c for c in X.df.select_dtypes(['object', 'category']).columns if c not in set_aside]
        cont_vars = [c for c in X.df.select_dtypes(['number']).columns if c not in set_aside]
        logging.debug(f'Storing imputation for {len(cat_vars)} categorical and {len(cont_vars)} continuous variables.')        
        
        # Update impute_values attribute with appropriate values
        for var in cat_vars:
            if X.df[var].isnull().sum()&amp;gt;0: self.impute_values.update({var: default_cat})
        if default_cont is not None:
            self.impute_values.update({v: float(X.df[v].mean()) if default_cont=='mean' \
                                       else float(X.df[v].median()) if default_cont=='median' \
                                       else float(default_cont) for v in cont_vars})
        
        # Override any given imputation values
        if type(override)==dict: self.impute_values.update(override)
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Imputer.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Imputerapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Imputerapplymod" tabindex="-1" role="dialog" aria-labelledby="ImputerapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Imputerapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()

        # Add missing value to categories if not present
        for var in data.df.select_dtypes('category').columns:
            if var in self.impute_values.keys() and self.impute_values[var] not in data.df[var].cat.categories:
                data.df[var] = data.df[var].cat.add_categories(self.impute_values[var])
        
        # Actual missing value imputation
        data.df.fillna(self.impute_values, inplace=True)
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Encodertab" role="tabpanel" aria-labelledby="Encodertab" tabindex="0">
<p><h3>
<span class="function">Encoder</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Encodermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Encodermod" tabindex="-1" role="dialog" aria-labelledby="EncoderLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Encoder</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Encoder(Transformer):

    def __init__(self):
        super().__init__('encoder')
        self.encode_values = {}

    def learn(self, X, min_occ=0.01, override=None, include_others=True, method='onehot', target=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(min_occ=min_occ, override=override, include_others=include_others, method=method, target=target)
        
        # Assert that sep string does not occur in columns of dataset
        cols = pd.Series(X.df.columns)
        assert cols.str.contains('__').sum()==0, 'Seperator string "__" already occurs in column names!'
        assert method in ('onehot', 'target'), "Method should be in ('onehot' or 'target')"
        if method =='target': assert target is not None, "Target should be given if method is 'target'"
        
        self.encode_values = {}
        if min_occ is None: return self
        
        # Per variable we will be storing the values that occur more than min_occ
        for var in X.df.select_dtypes(['category', 'object', 'bool']):
            if set_aside is not None and var in set_aside: continue
            shares = X.df[var].value_counts(normalize=True)
            
            # In case of 2 values, choose one to one-hot-encode based on value
            if method == 'onehot' and X.df[var].nunique() == 2:
                if '1' in shares.index: shares = shares.loc[['1']]
                elif True in shares.index: shares = shares[shares.index]
                elif 1 in shares.index: shares = shares.loc[[1]]
                else: shares = shares.iloc[[1]]  # Less occuring value is 'trigger'
                
            # Override when needed, and remove low occuring values
            min_occ_to_use = override[var] if override and var in override.keys() else min_occ 
            encode_values = list(shares.index[shares&amp;gt;min_occ_to_use])
            
            # Add other category if requested and other values are present
            if include_others and len(shares) &amp;gt; len(encode_values):
                encode_values.append('OTHER')

            if method=='target':
                x = set_categories(X.df[var].copy(), encode_values)
                encode_values = X.df[target].groupby(x).mean().to_dict()
            self.encode_values[var] = encode_values

        return self

    def apply(self, X, inplace=False):
        super().apply(X)
        # Create new data object which will contain all dummies
        data = X if inplace else X.copy()
            
        # Loop through each variable to dummy
        for i, (var, values) in enumerate(self.encode_values.items()):
            
            # Set categories. Values not part of categories become missing
            data.df[var] = set_categories(data.df[var], values)

            # One hot encoding
            if isinstance(values, list):
                # Retrieve dummy variables, make them categorical and set level type as string
                dummies = pd.get_dummies(data.df[[var]], prefix_sep='__')
                dummies = dummies.astype('category') if dummies.shape[1] &amp;gt; 0 else dummies
                for d in dummies.columns: 
                    dummies[d].cat.set_categories(dummies[d].cat.categories.astype(str))
                    
                # Remove brackets and commas from column names (libraries like xgboost don't like them)
                dummies.columns = [c.replace('(', '').replace(')', '').replace(']', '').replace(
                    ' ', '').replace('&amp;lt;', '_st_').replace('&amp;gt;', '_gt_') for c in dummies.columns]

                # Append dummies and drop original variable
                data.df.drop(var, axis=1, inplace=True)
                data.df = pd.concat([data.df, dummies], axis=1)
                logging.debug(f'{i}: {var} encoded into {dummies.shape[1]} dummies.')

            # Target encoding
            elif isinstance(values, dict):
                data.df[var] = pd.to_numeric(data.df[var].replace(values), downcast='float')
            
        if not inplace: return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Encoder.learn</span><span class="signature">(self, X, min_occ=0.01, override=None, include_others=True, method='onehot', target=None, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Encoderlearnmod"></i></span>
</h3>
<p>This function learns which variables should be encoded to which dummies.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on. <br>
<span class="argument"><b>min_occ</b></span>: <span class="datatype"><i>Float, default 0.01</i></span> Should be between 0 and 1. Minimum occurrence or share each value must have to receive it's own indicator. <br>
<span class="argument"><b>override</b></span>: <span class="datatype"><i>Dictionary[String: Float]</i></span> Set a particular min_occ per variable. If this is filled in for a feature, this will override the default min_occ. <br>
<span class="argument"><b>include_others</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to group all values occurring less than min_occ in a single indicator. <br>
<span class="argument"><b>method</b></span>: <span class="datatype"><i>String, default 'onehot'</i></span> Should be in in ('onehot', 'target'). Whether to group all values occurring less than min_occ in a single indicator. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String, optional</i></span> In case of target encoding, identify which column is used as target. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="Encoderlearnmod" tabindex="-1" role="dialog" aria-labelledby="EncoderlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Encoderlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, min_occ=0.01, override=None, include_others=True, method='onehot', target=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(min_occ=min_occ, override=override, include_others=include_others, method=method, target=target)
        
        # Assert that sep string does not occur in columns of dataset
        cols = pd.Series(X.df.columns)
        assert cols.str.contains('__').sum()==0, 'Seperator string "__" already occurs in column names!'
        assert method in ('onehot', 'target'), "Method should be in ('onehot' or 'target')"
        if method =='target': assert target is not None, "Target should be given if method is 'target'"
        
        self.encode_values = {}
        if min_occ is None: return self
        
        # Per variable we will be storing the values that occur more than min_occ
        for var in X.df.select_dtypes(['category', 'object', 'bool']):
            if set_aside is not None and var in set_aside: continue
            shares = X.df[var].value_counts(normalize=True)
            
            # In case of 2 values, choose one to one-hot-encode based on value
            if method == 'onehot' and X.df[var].nunique() == 2:
                if '1' in shares.index: shares = shares.loc[['1']]
                elif True in shares.index: shares = shares[shares.index]
                elif 1 in shares.index: shares = shares.loc[[1]]
                else: shares = shares.iloc[[1]]  # Less occuring value is 'trigger'
                
            # Override when needed, and remove low occuring values
            min_occ_to_use = override[var] if override and var in override.keys() else min_occ 
            encode_values = list(shares.index[shares&amp;gt;min_occ_to_use])
            
            # Add other category if requested and other values are present
            if include_others and len(shares) &amp;gt; len(encode_values):
                encode_values.append('OTHER')

            if method=='target':
                x = set_categories(X.df[var].copy(), encode_values)
                encode_values = X.df[target].groupby(x).mean().to_dict()
            self.encode_values[var] = encode_values

        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Encoder.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Encoderapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Encoderapplymod" tabindex="-1" role="dialog" aria-labelledby="EncoderapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Encoderapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        # Create new data object which will contain all dummies
        data = X if inplace else X.copy()
            
        # Loop through each variable to dummy
        for i, (var, values) in enumerate(self.encode_values.items()):
            
            # Set categories. Values not part of categories become missing
            data.df[var] = set_categories(data.df[var], values)

            # One hot encoding
            if isinstance(values, list):
                # Retrieve dummy variables, make them categorical and set level type as string
                dummies = pd.get_dummies(data.df[[var]], prefix_sep='__')
                dummies = dummies.astype('category') if dummies.shape[1] &amp;gt; 0 else dummies
                for d in dummies.columns: 
                    dummies[d].cat.set_categories(dummies[d].cat.categories.astype(str))
                    
                # Remove brackets and commas from column names (libraries like xgboost don't like them)
                dummies.columns = [c.replace('(', '').replace(')', '').replace(']', '').replace(
                    ' ', '').replace('&amp;lt;', '_st_').replace('&amp;gt;', '_gt_') for c in dummies.columns]

                # Append dummies and drop original variable
                data.df.drop(var, axis=1, inplace=True)
                data.df = pd.concat([data.df, dummies], axis=1)
                logging.debug(f'{i}: {var} encoded into {dummies.shape[1]} dummies.')

            # Target encoding
            elif isinstance(values, dict):
                data.df[var] = pd.to_numeric(data.df[var].replace(values), downcast='float')
            
        if not inplace: return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="BiSelectortab" role="tabpanel" aria-labelledby="BiSelectortab" tabindex="0">
<p><h3>
<span class="function">BiSelector</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#BiSelectormod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="BiSelectormod" tabindex="-1" role="dialog" aria-labelledby="BiSelectorLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">BiSelector</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class BiSelector(Transformer):

    def __init__(self):
        super().__init__('biselector')
        self.columns = []
        
    def learn(self, X, threshold=0.8, target=None, feature_select=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(threshold=threshold, target=target, feature_select=feature_select)

        # Hard select variables if given.
        if feature_select is not None:
            assert type(feature_select)==list, 'feature_select is not a list'
            for v in feature_select:
                if v in X.df: self.columns.append(v)
                else: logging.debug(f'{v} not present in data')
            if set_aside: self.columns += set_aside
            return self

        # Shortcut of threshold is 1: all features are selected
        if threshold==1:
            self.columns = list(X.df.columns)
            return self
        self.columns = []
        set_aside = [] if set_aside is None else set_aside

        # Take sample and calculate pairwise and target correlations
        variables = [x for x in X.df if x not in set_aside or x == target]
        sample = X.df.sample(min([len(X.df), 10000]), random_state=0, replace=True)[variables]
        sample = pd.concat((
            sample.select_dtypes(('category', 'object')),
            sample.select_dtypes('number').apply(
                lambda x: pd.qcut(x, q=10, duplicates='drop') if x.nunique() &amp;gt; 10 else x)
        ), axis=1).apply(lambda column: np.unique(column.astype(str).fillna('&amp;lt;m&amp;gt;'), return_inverse=True)[1])
        logging.debug('Sample created for correlation matrix')
        
        # Calculate cramers V in between features and features vs target
        corr_matrix = sample.corr(method=calculate_cramersv)
        if target is not None:
            corr_matrix.drop(target, inplace=True)
            corr_target = corr_matrix.pop(target)
            features_sorted = corr_target.sort_values(ascending=False).index
        else: features_sorted = sample.columns
        
        # Loop through candidates and potentialy append or replace list of kept vars
        kept_vars = []
        for candidate in features_sorted:
            to_keep = True
            for i, kept_var in enumerate(kept_vars):
                if corr_matrix.loc[candidate, kept_var] &amp;gt; threshold:
                    logging.debug(f'Candidate {candidate} correlates too much with kept var {kept_var}.')
                    if target is not None and corr_target[candidate] &amp;gt; corr_target[kept_var]:
                        if not kept_var.startswith('in_'):
                            logging.debug(f'Candidate {candidate} correlates more with target, so replacing {kept_var}.')
                            kept_vars[i] = candidate
                    to_keep = False
                    break
            if to_keep: 
                logging.debug(f'Candidate {candidate} added to kept variables.')
                kept_vars.append(candidate)
        self.columns = kept_vars + set_aside
        return self

    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        data.df = data.df[[c for c in self.columns if c in X.df]]
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">BiSelector.learn</span><span class="signature">(self, X, threshold=0.8, target=None, feature_select=None, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#BiSelectorlearnmod"></i></span>
</h3>
<p>This function learns which variables should be selected.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on. <br>
<span class="argument"><b>threshold</b></span>: <span class="datatype"><i>Float, default 0.8</i></span> Maximum allowed correlation (Cramer's V) between 2 variables. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String, optional</i></span> Target variable. If 2 variables correlate too much according to threshold, the one with the highest target correlation is preserved. If not given, the first one in X is retained. <br>
<span class="argument"><b>feature_select</b></span>: <span class="datatype"><i>List[Strings], optional</i></span> Similarly to variable_select in the uniselector, this is a way to hard-select features, albeit in this stage - after potential binning, imputing and encoding. If given, the other parameters are ignored. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="BiSelectorlearnmod" tabindex="-1" role="dialog" aria-labelledby="BiSelectorlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">BiSelectorlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, threshold=0.8, target=None, feature_select=None, set_aside=None):
        
        super().learn(X)
        self.params = dict(threshold=threshold, target=target, feature_select=feature_select)

        # Hard select variables if given.
        if feature_select is not None:
            assert type(feature_select)==list, 'feature_select is not a list'
            for v in feature_select:
                if v in X.df: self.columns.append(v)
                else: logging.debug(f'{v} not present in data')
            if set_aside: self.columns += set_aside
            return self

        # Shortcut of threshold is 1: all features are selected
        if threshold==1:
            self.columns = list(X.df.columns)
            return self
        self.columns = []
        set_aside = [] if set_aside is None else set_aside

        # Take sample and calculate pairwise and target correlations
        variables = [x for x in X.df if x not in set_aside or x == target]
        sample = X.df.sample(min([len(X.df), 10000]), random_state=0, replace=True)[variables]
        sample = pd.concat((
            sample.select_dtypes(('category', 'object')),
            sample.select_dtypes('number').apply(
                lambda x: pd.qcut(x, q=10, duplicates='drop') if x.nunique() &amp;gt; 10 else x)
        ), axis=1).apply(lambda column: np.unique(column.astype(str).fillna('&amp;lt;m&amp;gt;'), return_inverse=True)[1])
        logging.debug('Sample created for correlation matrix')
        
        # Calculate cramers V in between features and features vs target
        corr_matrix = sample.corr(method=calculate_cramersv)
        if target is not None:
            corr_matrix.drop(target, inplace=True)
            corr_target = corr_matrix.pop(target)
            features_sorted = corr_target.sort_values(ascending=False).index
        else: features_sorted = sample.columns
        
        # Loop through candidates and potentialy append or replace list of kept vars
        kept_vars = []
        for candidate in features_sorted:
            to_keep = True
            for i, kept_var in enumerate(kept_vars):
                if corr_matrix.loc[candidate, kept_var] &amp;gt; threshold:
                    logging.debug(f'Candidate {candidate} correlates too much with kept var {kept_var}.')
                    if target is not None and corr_target[candidate] &amp;gt; corr_target[kept_var]:
                        if not kept_var.startswith('in_'):
                            logging.debug(f'Candidate {candidate} correlates more with target, so replacing {kept_var}.')
                            kept_vars[i] = candidate
                    to_keep = False
                    break
            if to_keep: 
                logging.debug(f'Candidate {candidate} added to kept variables.')
                kept_vars.append(candidate)
        self.columns = kept_vars + set_aside
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">BiSelector.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#BiSelectorapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="BiSelectorapplymod" tabindex="-1" role="dialog" aria-labelledby="BiSelectorapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">BiSelectorapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        data.df = data.df[[c for c in self.columns if c in X.df]]
        return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Expandertab" role="tabpanel" aria-labelledby="Expandertab" tabindex="0">
<p><h3>
<span class="function">Expander</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Expandermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Expandermod" tabindex="-1" role="dialog" aria-labelledby="ExpanderLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Expander</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Expander(Transformer):

    def __init__(self):
        super().__init__('expander')
        self.expand_behaviour = {'interactions': False, 'log': False}
        self.itx_pairs = []
    
    def learn(self, X, interactions=True, log=False, set_aside=None):
        
        super().learn(X)
        self.params = dict(interactions=interactions, log=log)

        self.expand_behaviour['interactions'] = interactions
        self.expand_behaviour['log'] = log
        
        if self.expand_behaviour['interactions']:
            self.itx_pairs = []
            con_vars = [x for x in X.df.select_dtypes('number').columns if x not in set_aside]
            cat_vars = []
            for col in X.df.select_dtypes('category').columns:
                if col not in set_aside and np.all([x.isdigit() for x in X.df[col].cat.categories]).all():
                    cat_vars.append(col)
            columns = con_vars+cat_vars
            base_vars = pd.Series(columns).str.split('__').apply(lambda c: c[0]).unique()
            base_pairs = [x for x in combinations(base_vars, 2)]

            for base_var1, base_var2 in base_pairs:
                features1 = X.df.columns[X.df.columns.str.startswith(base_var1)][:5]
                features2 = X.df.columns[X.df.columns.str.startswith(base_var2)][:5]
                feature_pairs = [[f1, f2] for f1 in features1 for f2 in features2]
                self.itx_pairs += feature_pairs
        return self
    
    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        
        if self.expand_behaviour['interactions']:
            features = np.unique(np.array([list(x) for x in self.itx_pairs]).flatten())
            temp = data.df[features].astype(float)                        
            logging.info(f'Number of interactions to calculate: {len(self.itx_pairs)}')
            for i, (feature1, feature2) in enumerate(self.itx_pairs):
                itx = temp[feature1].mul(temp[feature2]).astype('category')
                itx.cat.set_categories(itx.cat.categories.astype(str))
                data.df[f'ITX_{feature1}_x_{feature2}'] = itx
                if i!=0 and (i+1)%1000==0: logging.info(f'Interactions calculated: {i+1}')
            
        return data    
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Expander.learn</span><span class="signature">(self, X, interactions=True, log=False, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Expanderlearnmod"></i></span>
</h3>
<p>This function learns how to add extra features to a dataset.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on <br>
<span class="argument"><b>interactions</b></span>: <span class="datatype"><i>Bool</i></span> Whether to include interactions, i.e. the multiplication of all pairwise features. Can be helpful for regression models to include effects of variables together. <br>
<span class="argument"><b>log</b></span>: <span class="datatype"><i>Bool, NOT YET IMPLEMENTED</i></span> Whether to include logs of continuous variables. Can be helpful for typically linear models to introduce non-linearity in the features. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="Expanderlearnmod" tabindex="-1" role="dialog" aria-labelledby="ExpanderlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Expanderlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, interactions=True, log=False, set_aside=None):
        
        super().learn(X)
        self.params = dict(interactions=interactions, log=log)

        self.expand_behaviour['interactions'] = interactions
        self.expand_behaviour['log'] = log
        
        if self.expand_behaviour['interactions']:
            self.itx_pairs = []
            con_vars = [x for x in X.df.select_dtypes('number').columns if x not in set_aside]
            cat_vars = []
            for col in X.df.select_dtypes('category').columns:
                if col not in set_aside and np.all([x.isdigit() for x in X.df[col].cat.categories]).all():
                    cat_vars.append(col)
            columns = con_vars+cat_vars
            base_vars = pd.Series(columns).str.split('__').apply(lambda c: c[0]).unique()
            base_pairs = [x for x in combinations(base_vars, 2)]

            for base_var1, base_var2 in base_pairs:
                features1 = X.df.columns[X.df.columns.str.startswith(base_var1)][:5]
                features2 = X.df.columns[X.df.columns.str.startswith(base_var2)][:5]
                feature_pairs = [[f1, f2] for f1 in features1 for f2 in features2]
                self.itx_pairs += feature_pairs
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Expander.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Expanderapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Expanderapplymod" tabindex="-1" role="dialog" aria-labelledby="ExpanderapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Expanderapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        
        if self.expand_behaviour['interactions']:
            features = np.unique(np.array([list(x) for x in self.itx_pairs]).flatten())
            temp = data.df[features].astype(float)                        
            logging.info(f'Number of interactions to calculate: {len(self.itx_pairs)}')
            for i, (feature1, feature2) in enumerate(self.itx_pairs):
                itx = temp[feature1].mul(temp[feature2]).astype('category')
                itx.cat.set_categories(itx.cat.categories.astype(str))
                data.df[f'ITX_{feature1}_x_{feature2}'] = itx
                if i!=0 and (i+1)%1000==0: logging.info(f'Interactions calculated: {i+1}')
            
        return data    
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Standardizertab" role="tabpanel" aria-labelledby="Standardizertab" tabindex="0">
<p><h3>
<span class="function">Standardizer</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Standardizermod"></i></span>
</h3><p>This class collects methods for transforming data.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Transformer'</i></span> Arbitrary name for the data object, that shows up in the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Transformer.name</b></span>: <span class="datatype"><i>String</i></span> Name of the transformer <br>
<span class="argument"><b>Transformer.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of parameters to learn the transformer. </p>


    <div class="modal fade bd-example-modal-lg" id="Standardizermod" tabindex="-1" role="dialog" aria-labelledby="StandardizerLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Standardizer</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Standardizer(Transformer):

    def __init__(self):
        super().__init__('standardizer')
        self.elements = {}
        
    def learn(self, X, standardize=True, set_aside=None):
        
        super().learn(X)
        self.params = dict(standardize=standardize)

        if not standardize: return self
        set_aside = [] if set_aside is None else set_aside

        # Only continuous variables will be selected to be standardized
        variables = [v for v in X.df.select_dtypes(['number']).columns if v not in set_aside]
        
        # Calculate the mean and standard deviation for each column
        self.elements = {v : {'mean': float(X.df[v].mean()), 'std': float(X.df[v].std())} for v in variables}
        return self
    
    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        
        for nv in self.elements:
            data.df[nv] = (data.df[nv] - self.elements[nv]['mean']) / self.elements[nv]['std'] 
        if not inplace: return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Standardizer.learn</span><span class="signature">(self, X, standardize=True, set_aside=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Standardizerlearnmod"></i></span>
</h3>
<p>This function learns which variables to standardize and which values to use.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to learn transformation on <br>
<span class="argument"><b>standardize</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to standardize numerical variables <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String], optional</i></span> List of column names that are excluded from the transformation. </p>


    <div class="modal fade bd-example-modal-lg" id="Standardizerlearnmod" tabindex="-1" role="dialog" aria-labelledby="StandardizerlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Standardizerlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, X, standardize=True, set_aside=None):
        
        super().learn(X)
        self.params = dict(standardize=standardize)

        if not standardize: return self
        set_aside = [] if set_aside is None else set_aside

        # Only continuous variables will be selected to be standardized
        variables = [v for v in X.df.select_dtypes(['number']).columns if v not in set_aside]
        
        # Calculate the mean and standard deviation for each column
        self.elements = {v : {'mean': float(X.df[v].mean()), 'std': float(X.df[v].std())} for v in variables}
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Standardizer.apply</span><span class="signature">(self, X, inplace=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Standardizerapplymod"></i></span>
</h3>
<p>Apply a transformer on a data object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>X</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to apply the transformer on. </p>


    <div class="modal fade bd-example-modal-lg" id="Standardizerapplymod" tabindex="-1" role="dialog" aria-labelledby="StandardizerapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Standardizerapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, X, inplace=False):
        super().apply(X)
        data = X if inplace else X.copy()
        
        for nv in self.elements:
            data.df[nv] = (data.df[nv] - self.elements[nv]['mean']) / self.elements[nv]['std'] 
        if not inplace: return data
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Modeltab" role="tabpanel" aria-labelledby="Modeltab" tabindex="0">
<p><h3>
<span class="function">Model</span><span class="signature">(name='Model') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelmod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelmod" tabindex="-1" role="dialog" aria-labelledby="ModelLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Model</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Model:
        
    def __init__(self, name='Model'):
        self.name: str = name
        self.params: None
        self.clf = None
        self.features: None
        self.target: str = None
        self.categories: np.array[str] = None
        self.mode: str = None
        self.feature_imp: pd.Series = None
        self.predictions: Data = None
        self.confusion: pd.DataFrame = None
        self.metrics: pd.DataFrame = None
        self.shapvalues: pd.DataFrame = None

    def learn(self, data, target, mode, hyper_params, set_aside=None, seed=0):
        
        logging.info(f'{data.df.shape} - {data.name} - learning {self.name}')
        self.params = hyper_params
        np.random.seed(seed)
        assert mode in ('linear', 'binaryclass', 'multiclass', 'multilabel', 
            'clustering', 'dimensionreduction', 'anomalydetection'), \
            "Mode should be one of ('linear', 'binaryclass', 'multiclass', \
                'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection')"
        self.mode = mode

        # Store features to train on
        set_aside = [] if set_aside is None else set_aside
        self.features = [c for c in data.df.columns if c not in set_aside and c!=target]
        self.target = target

    def _predict_scores(self):
        
        pass
        
    def apply(self, data, include_preds=True, store=False, cutoff_params=None):
        
        logging.info(f'{data.df.shape} - {data.name} - applying {self.name}')

        # Intitialize a predictions df, add target and scores
        preds = pd.DataFrame(index=data.df.index)
        if self.target in data.df: preds['target'] = data.df[self.target]
                
        # In case of binary classification
        if self.mode=='binaryclass':
            preds['scores'] = pd.Series(self._predict_scores(data), index=data.df.index)
            if include_preds:
                # Include manual cutoffs, and cutoffs infered by fix recalls, flags and beta.
                if cutoff_params is None: cutoff_params = dict()
                cutoffs = cutoff_params.get('cutoffs')
                if cutoffs is not None and len(cutoffs)&amp;gt;1:
                    for cutoff in cutoffs:
                        preds[f'predictions_{cutoff}'] = (preds.scores&amp;gt;=cutoff).astype(int)
                beta = cutoff_params.get('beta', 1)
                if beta and self.target in data.df:
                    _, cutoff = get_best_cutoff(data.df[self.target], preds.scores, beta)
                    preds[f'predictions_best'] = (preds.scores&amp;gt;=cutoff).astype(int)
                fix_recalls = cutoff_params.get('fix_recalls')
                if fix_recalls and self.target in data.df:
                    for dr in fix_recalls:
                        cutoff = preds.scores[data.df[self.target]==1].quantile(1-dr)
                        preds[f'predictions_rec{dr}'] = (preds.scores&amp;gt;cutoff).astype(int)
                fix_flags = cutoff_params.get('fix_flags')
                if fix_flags:
                    for df in fix_flags:
                        cutoff = preds.scores.quantile(1-df)
                        preds[f'predictions_fla{df}'] = (preds.scores&amp;gt;cutoff).astype(int)

        # In case of linear regression
        elif self.mode=='linear':
            preds['scores'] = pd.Series(self._predict_scores(data), index=data.df.index)
            if include_preds and self.target in data.df:
                preds['target_bins'] = preds.target
                preds['predictions'] = preds.scores
                if preds.scores.nunique()&amp;gt;10:
                    self.confusion_cuts = pd.qcut(data.df[self.target], q=5, retbins=True, duplicates='drop')[1]
                    labels = [f'bin{c+1}' for c in np.arange(len(self.confusion_cuts[:-1]))]
                    # Apply learned cuttoffs on whole dataset
                    preds['target_bins'] = pd.cut(preds['target'], bins=self.confusion_cuts, labels=labels,
                                            duplicates='drop', include_lowest=True)
                    preds['predictions'] = pd.cut(preds.scores, bins=self.confusion_cuts, labels=labels,
                                                duplicates='drop', include_lowest=True)
                    preds['predictions'] = preds['predictions'].cat.add_categories('missing')
                    preds['predictions'].fillna('missing', inplace=True)

        # In case of multiclass classification
        elif self.mode=='multiclass':
            scores = pd.DataFrame(self._predict_scores(data), index=data.df.index)
            scores.columns = [f'scores_{c}' for c in self.categories]
            preds = preds.join(scores)
            if self.target in data.df:
                preds['scores'] = preds.apply(lambda row: row[f'scores_{row.target}'], axis=1)
            if include_preds:
                preds['predictions'] = self.categories[scores.to_numpy().argmax(axis=1)]

        elif self.mode=='clustering':
            scores = pd.DataFrame(self._predict_scores(data), index=data.df.index)
            clusters = np.arange(scores.shape[1])
            scores.columns = [f'scores_{c}' for c in clusters]
            preds = preds.join(scores)
            if include_preds:
                preds['predictions'] = clusters[scores.to_numpy().argmax(axis=1)]
            
        preds = Data(preds, 'Preds')
        if store: self.predictions = preds
        return preds
    
    def evaluate(self, predictions, broken_by='dataset'):
        
        logging.info(f'{predictions.df.shape} - {predictions.name} - evaluating {self.name}')
        pred_cols = [c for c in predictions.columns if 'predictions' in c]
        if 'target' not in predictions.df or len(pred_cols) == 0: return None, None

        # 1. Build confusion table
        confusion = pd.DataFrame()
        target = 'target' if self.mode != 'linear' else 'target_bins'

        # Groupby given broken_by, targets and predictions
        if broken_by not in predictions.index.names: predictions.add_index(broken_by, 'All')
        values = predictions.index.get_level_values(broken_by)
        confusion = pd.concat([predictions.df.groupby([values, target, pred]).size() \
            for pred in pred_cols], axis=1, keys=pred_cols).unstack().fillna(0).astype(int)
        
        # These lines make sure all confusion conbinations are present
        # E.g. in the case where none of the actuals or predictions are 1
        confusion = confusion.reindex(pd.MultiIndex.from_product(
            confusion.index.levels), axis=0, fill_value=0)
        confusion = confusion.reindex(pd.MultiIndex.from_product(
            confusion.columns.levels), axis=1, fill_value=0)
    
        # 2. Create metric tables
        metrics = pd.DataFrame(
            index=pd.MultiIndex.from_product([predictions.index.levels[0]]),
            columns=pd.MultiIndex.from_tuples([(p, m) for p in pred_cols for m in ['accuracy']]))

        from itertools import product
        combinations = list(product(predictions.index.levels[0], pred_cols))
        preds = predictions.df
        # Linear metrics
        if self.mode=='linear':
            from scipy.stats import pearsonr, spearmanr
            for b, p in combinations:
                rmse = lambda p, t: np.sqrt(np.square(p-t).mean())
                pr, ta = preds.loc[b, 'scores'], preds.loc[b, 'target']
                metrics.loc[b, (p,'rmse')] = rmse(pr, ta)
                metrics.loc[b, (p,'pearsonr')] = pearsonr(pr, ta)[0]
                metrics.loc[b, (p,'spearmanr')] = spearmanr(pr, ta)[0]

        # Binary metrics
        elif self.mode=='binaryclass':
            from sklearn.metrics import roc_curve, auc
            bins = pd.qcut(preds.scores, 50, duplicates='drop')
            for b, p in combinations:
                metrics.loc[b, (p,'precision')] = confusion.loc[(b, 1),(p, 1)] / confusion.loc[b, (p,1)].sum()
                metrics.loc[b, (p,'recall')] = confusion.loc[(b, 1),(p, 1)] / confusion.loc[(b, 1),p].sum()
                metrics.loc[b, (p,'flags')] = confusion.loc[b, (p, 1)].sum() / confusion.loc[b, p].sum().sum()
                metrics.loc[b, (p,'f1')] = f1(metrics.loc[b, (p,'precision')], metrics.loc[b, (p,'recall')], 1)
                fpr, tpr, _ = roc_curve(preds.loc[b, 'target'], preds.loc[b, 'scores'])
                metrics.loc[b, (p,'auc')] = auc(fpr, tpr)
                metrics.loc[b, (p,'lift')] = preds.loc[b].groupby(bins.loc[b]).target.mean().iloc[-1] / preds.loc[b].target.mean()

        # Multiclass metrics
        elif self.mode=='multiclass': pass
        
        # Mode agnostic metrics
        for b, p in combinations:  # For any mode
            metrics.loc[b, (p,'accuracy')] = np.diag(confusion.loc[b, p]).sum() / confusion.loc[b, p].sum().sum()
            metrics.loc[b, (p,'c_index')] = c_index(preds.loc[b], 'target', 'scores')
        metrics = metrics.round(3)

        self.confusion = confusion
        self.metrics = metrics
        return self.confusion, self.metrics

    def explain(self, data):
        
        logging.info(f'{data.df.shape} - {data.name} - explaining {self.name}')

    def save(self, directory=None, name=None, slim=False, as_pickle=False):
        
        logging.info(f'Saving model {self.name}')
        self.name = name if name else self.name
        if directory is None or self.name is None:
            logging.warning('Pipeline not saved. No directory or name was provided.')
            return
            
        # Save as pickle
        if as_pickle:
            with open(os.path.join(directory, f'{self.name}.pkl'), 'wb') as f:
                pickle.dump(self, f)
            return

        # Reset path
        path = os.path.join(directory, self.name)
        if os.path.isdir(path): shutil.rmtree(path)
        os.mkdir(path)

        if not slim and self.predictions is not None:
            preds = self.predictions.df.drop('bins', axis=1) if 'bins' in self.predictions.df else self.predictions.df
            preds.to_parquet(os.path.join(path, 'predictions.parquet'))
        if not slim and self.shapvalues is not None:
            self.shapvalues.to_parquet(os.path.join(path, 'shapvalues.parquet'))
        if self.feature_imp is not None:
            self.feature_imp.to_csv(os.path.join(path, 'features.csv'))
        if self.metrics is not None:
            self.metrics.to_csv(os.path.join(path, 'metrics.csv'))
        if self.confusion is not None:
            self.confusion.to_csv(os.path.join(path, 'confusion.csv'))
        with open(os.path.join(path, 'model.json'), 'w') as f:
            json.dump({'features': self.features, 'target': self.target, 'mode': self.mode, 
                       'algorithm':self.__class__.__name__.lower(), 'params': self.params}, f, indent=4)
        with open(os.path.join(path, 'model.pickle'), 'wb') as f:
            pickle.dump(self.clf, f)

    def load(self, path=None, slim=False):
        
        logging.info('Loading model')
        paths = path.split('/')
        storage = '/'.join(paths[:-1])

        # Load pickle file
        if paths[-1].endswith('.pkl'):
            name = paths[-1][:-4]
            with open(os.path.join(storage, f'{name}.pkl'), 'rb') as f:
                self = pickle.load(f)
            self.name = paths[-1][:-4]
            return self
        # Load files
        self.name = paths[-1]
        path = os.path.join(storage, self.name)

        files = os.listdir(path)
        self.feature_imp, self.metrics, self.confusion = None, None, None
        if 'features.csv' in files:
            self.feature_imp = pd.read_csv(os.path.join(path, 'features.csv'), index_col=0).squeeze('columns')
        if 'metrics.csv' in files:
            self.metrics = pd.read_csv(os.path.join(path, 'metrics.csv'), index_col=0, header=[0, 1])
        if 'confusion.csv' in files:
            self.confusion = pd.read_csv(os.path.join(path, 'confusion.csv'), index_col=[0, 1], header=[0, 1])
        if not slim and 'predictions.parquet' in files:
            self.predictions = Data(pd.read_parquet(os.path.join(path, 'predictions.parquet')), 'Preds')
        if not slim and 'shapvalues.parquet' in files:
            self.shapvalues = pd.read_parquet(os.path.join(path, 'shapvalues.parquet'))
        with open(os.path.join(path, 'model.json'), 'r') as f:
            data = json.load(f)
            self.features, self.target, self.mode, self.params = \
                data['features'], data['target'], data['mode'], data['params']
        with open(os.path.join(path, 'model.pickle'), 'rb') as f:
            self.clf = pickle.load(f)
        return self

    def _summary(self):
        
        return pd.Series(dict(
            Name = self.name,
            Algorithm = self.__class__.__name__.lower(),
            Type = self.clf.__class__.__name__,
            Features = len(self.features),
            Target = self.target if self.target else 'None',
            Mode = self.mode,
            Parameters = ", ".join([f'{k}: {v}' for k, v in self.params.items()]),
        ))

    def __repr__(self):
        string = 'This is a MODEL object.\n'
        string += tabulate(self._summary().to_frame(), tablefmt='simple_outline')
        string += '\n\nAttributes: clf, algorithm, mode, params, features, target, predictions, confusion, metrics, shapvalues.\n'
        string += 'Methods: learn, apply, evaluate, explain, save, load.\n'
        return string

    # def __getstate__(self):
    #     state = self.__dict__.copy()
    #     for a in ['predictions', 'shapvalues']:
    #         state[a] = None
    #     return state

    # def __setstate__(self, state):
    #     self.__dict__.update(state)
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Model.learn</span><span class="signature">(self, data, target, mode, hyper_params, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modellearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="Modellearnmod" tabindex="-1" role="dialog" aria-labelledby="ModellearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modellearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode, hyper_params, set_aside=None, seed=0):
        
        logging.info(f'{data.df.shape} - {data.name} - learning {self.name}')
        self.params = hyper_params
        np.random.seed(seed)
        assert mode in ('linear', 'binaryclass', 'multiclass', 'multilabel', 
            'clustering', 'dimensionreduction', 'anomalydetection'), \
            "Mode should be one of ('linear', 'binaryclass', 'multiclass', \
                'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection')"
        self.mode = mode

        # Store features to train on
        set_aside = [] if set_aside is None else set_aside
        self.features = [c for c in data.df.columns if c not in set_aside and c!=target]
        self.target = target
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Model.apply</span><span class="signature">(self, data, include_preds=True, store=False, cutoff_params=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelapplymod"></i></span>
</h3>
<p>Apply a model on a data object, i.e. make scores and predictions for it.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for apply the model on. <br>
<span class="argument"><b>include_preds</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to include predictions aside from the model scores. E.g. binary 1/0's based on scores and a cutoff. <br>
<span class="argument"><b>store</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to store the predictions as an attribute in the object. <br>
<span class="argument"><b>cutoff_params</b></span>: <span class="datatype"><i>Dict[String: List[Float]]</i></span> Parameters to decide on possible multiple cutoffs used for binary classification. Format is dict(cutoffs=[0.3, 0.5], fix_recalls=[0.6], fix_flags=[0.1, 0.2], beta=1) Any of these is optional. 1. Cutoffs is a manual list of cutoffs for which to include the predictions. 2. Fix_recalls infers cutoffs to reach the desired recall. 3. Fix_flags infers cutoffs to reach a desired number of flags. 4. Beta is a coefficient to decide a cutoff to optimize f1 which is the harmonic mean of precision and recall. Beta = 1 favours both equally, beta &amp;gt; 1 favours recall, beta &amp;lt; 1 favours precision. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelapplymod" tabindex="-1" role="dialog" aria-labelledby="ModelapplyLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modelapply</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def apply(self, data, include_preds=True, store=False, cutoff_params=None):
        
        logging.info(f'{data.df.shape} - {data.name} - applying {self.name}')

        # Intitialize a predictions df, add target and scores
        preds = pd.DataFrame(index=data.df.index)
        if self.target in data.df: preds['target'] = data.df[self.target]
                
        # In case of binary classification
        if self.mode=='binaryclass':
            preds['scores'] = pd.Series(self._predict_scores(data), index=data.df.index)
            if include_preds:
                # Include manual cutoffs, and cutoffs infered by fix recalls, flags and beta.
                if cutoff_params is None: cutoff_params = dict()
                cutoffs = cutoff_params.get('cutoffs')
                if cutoffs is not None and len(cutoffs)&amp;gt;1:
                    for cutoff in cutoffs:
                        preds[f'predictions_{cutoff}'] = (preds.scores&amp;gt;=cutoff).astype(int)
                beta = cutoff_params.get('beta', 1)
                if beta and self.target in data.df:
                    _, cutoff = get_best_cutoff(data.df[self.target], preds.scores, beta)
                    preds[f'predictions_best'] = (preds.scores&amp;gt;=cutoff).astype(int)
                fix_recalls = cutoff_params.get('fix_recalls')
                if fix_recalls and self.target in data.df:
                    for dr in fix_recalls:
                        cutoff = preds.scores[data.df[self.target]==1].quantile(1-dr)
                        preds[f'predictions_rec{dr}'] = (preds.scores&amp;gt;cutoff).astype(int)
                fix_flags = cutoff_params.get('fix_flags')
                if fix_flags:
                    for df in fix_flags:
                        cutoff = preds.scores.quantile(1-df)
                        preds[f'predictions_fla{df}'] = (preds.scores&amp;gt;cutoff).astype(int)

        # In case of linear regression
        elif self.mode=='linear':
            preds['scores'] = pd.Series(self._predict_scores(data), index=data.df.index)
            if include_preds and self.target in data.df:
                preds['target_bins'] = preds.target
                preds['predictions'] = preds.scores
                if preds.scores.nunique()&amp;gt;10:
                    self.confusion_cuts = pd.qcut(data.df[self.target], q=5, retbins=True, duplicates='drop')[1]
                    labels = [f'bin{c+1}' for c in np.arange(len(self.confusion_cuts[:-1]))]
                    # Apply learned cuttoffs on whole dataset
                    preds['target_bins'] = pd.cut(preds['target'], bins=self.confusion_cuts, labels=labels,
                                            duplicates='drop', include_lowest=True)
                    preds['predictions'] = pd.cut(preds.scores, bins=self.confusion_cuts, labels=labels,
                                                duplicates='drop', include_lowest=True)
                    preds['predictions'] = preds['predictions'].cat.add_categories('missing')
                    preds['predictions'].fillna('missing', inplace=True)

        # In case of multiclass classification
        elif self.mode=='multiclass':
            scores = pd.DataFrame(self._predict_scores(data), index=data.df.index)
            scores.columns = [f'scores_{c}' for c in self.categories]
            preds = preds.join(scores)
            if self.target in data.df:
                preds['scores'] = preds.apply(lambda row: row[f'scores_{row.target}'], axis=1)
            if include_preds:
                preds['predictions'] = self.categories[scores.to_numpy().argmax(axis=1)]

        elif self.mode=='clustering':
            scores = pd.DataFrame(self._predict_scores(data), index=data.df.index)
            clusters = np.arange(scores.shape[1])
            scores.columns = [f'scores_{c}' for c in clusters]
            preds = preds.join(scores)
            if include_preds:
                preds['predictions'] = clusters[scores.to_numpy().argmax(axis=1)]
            
        preds = Data(preds, 'Preds')
        if store: self.predictions = preds
        return preds
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Model.evaluate</span><span class="signature">(self, predictions, broken_by='dataset') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelevaluatemod"></i></span>
</h3>
<p>Evaluate a mode on any data object. Outputs a confusion matrix and model metrics.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object as return by the apply function Contains scores and/r predictions to evaluate. <br>
<span class="argument"><b>broken_by</b></span>: <span class="datatype"><i>String, default 'dataset'</i></span> Shoud be in index levels if given. The metrics and confusion matrices are broken by its values. E.g. the confusion and model metrics for each data split. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelevaluatemod" tabindex="-1" role="dialog" aria-labelledby="ModelevaluateLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modelevaluate</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def evaluate(self, predictions, broken_by='dataset'):
        
        logging.info(f'{predictions.df.shape} - {predictions.name} - evaluating {self.name}')
        pred_cols = [c for c in predictions.columns if 'predictions' in c]
        if 'target' not in predictions.df or len(pred_cols) == 0: return None, None

        # 1. Build confusion table
        confusion = pd.DataFrame()
        target = 'target' if self.mode != 'linear' else 'target_bins'

        # Groupby given broken_by, targets and predictions
        if broken_by not in predictions.index.names: predictions.add_index(broken_by, 'All')
        values = predictions.index.get_level_values(broken_by)
        confusion = pd.concat([predictions.df.groupby([values, target, pred]).size() \
            for pred in pred_cols], axis=1, keys=pred_cols).unstack().fillna(0).astype(int)
        
        # These lines make sure all confusion conbinations are present
        # E.g. in the case where none of the actuals or predictions are 1
        confusion = confusion.reindex(pd.MultiIndex.from_product(
            confusion.index.levels), axis=0, fill_value=0)
        confusion = confusion.reindex(pd.MultiIndex.from_product(
            confusion.columns.levels), axis=1, fill_value=0)
    
        # 2. Create metric tables
        metrics = pd.DataFrame(
            index=pd.MultiIndex.from_product([predictions.index.levels[0]]),
            columns=pd.MultiIndex.from_tuples([(p, m) for p in pred_cols for m in ['accuracy']]))

        from itertools import product
        combinations = list(product(predictions.index.levels[0], pred_cols))
        preds = predictions.df
        # Linear metrics
        if self.mode=='linear':
            from scipy.stats import pearsonr, spearmanr
            for b, p in combinations:
                rmse = lambda p, t: np.sqrt(np.square(p-t).mean())
                pr, ta = preds.loc[b, 'scores'], preds.loc[b, 'target']
                metrics.loc[b, (p,'rmse')] = rmse(pr, ta)
                metrics.loc[b, (p,'pearsonr')] = pearsonr(pr, ta)[0]
                metrics.loc[b, (p,'spearmanr')] = spearmanr(pr, ta)[0]

        # Binary metrics
        elif self.mode=='binaryclass':
            from sklearn.metrics import roc_curve, auc
            bins = pd.qcut(preds.scores, 50, duplicates='drop')
            for b, p in combinations:
                metrics.loc[b, (p,'precision')] = confusion.loc[(b, 1),(p, 1)] / confusion.loc[b, (p,1)].sum()
                metrics.loc[b, (p,'recall')] = confusion.loc[(b, 1),(p, 1)] / confusion.loc[(b, 1),p].sum()
                metrics.loc[b, (p,'flags')] = confusion.loc[b, (p, 1)].sum() / confusion.loc[b, p].sum().sum()
                metrics.loc[b, (p,'f1')] = f1(metrics.loc[b, (p,'precision')], metrics.loc[b, (p,'recall')], 1)
                fpr, tpr, _ = roc_curve(preds.loc[b, 'target'], preds.loc[b, 'scores'])
                metrics.loc[b, (p,'auc')] = auc(fpr, tpr)
                metrics.loc[b, (p,'lift')] = preds.loc[b].groupby(bins.loc[b]).target.mean().iloc[-1] / preds.loc[b].target.mean()

        # Multiclass metrics
        elif self.mode=='multiclass': pass
        
        # Mode agnostic metrics
        for b, p in combinations:  # For any mode
            metrics.loc[b, (p,'accuracy')] = np.diag(confusion.loc[b, p]).sum() / confusion.loc[b, p].sum().sum()
            metrics.loc[b, (p,'c_index')] = c_index(preds.loc[b], 'target', 'scores')
        metrics = metrics.round(3)

        self.confusion = confusion
        self.metrics = metrics
        return self.confusion, self.metrics
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Model.explain</span><span class="signature">(self, data) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelexplainmod"></i></span>
</h3>
<p>Explain the model with a data object, either globally (regression coefficients) or 
locally (shap values).</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to use for explainability. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelexplainmod" tabindex="-1" role="dialog" aria-labelledby="ModelexplainLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modelexplain</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def explain(self, data):
        
        logging.info(f'{data.df.shape} - {data.name} - explaining {self.name}')
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Model.save</span><span class="signature">(self, directory=None, name=None, slim=False, as_pickle=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelsavemod"></i></span>
</h3>
<p>Save model.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>directory</b></span>: <span class="datatype"><i>String, optional</i></span> Directory where the model should be saved. <br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, optional</i></span> Name the folder or file will have in the directory. If not given, name attribute will be used. If given, name attribute will be overwritten. <br>
<span class="argument"><b>slim</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to store also predictions, data and shapvalues. Generally not needed for prediction, but useful for inspection. <br>
<span class="argument"><b>as_pickle</b></span>: <span class="datatype"><i>Bool, default False</i></span> Whether to save to a pickle file. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelsavemod" tabindex="-1" role="dialog" aria-labelledby="ModelsaveLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modelsave</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def save(self, directory=None, name=None, slim=False, as_pickle=False):
        
        logging.info(f'Saving model {self.name}')
        self.name = name if name else self.name
        if directory is None or self.name is None:
            logging.warning('Pipeline not saved. No directory or name was provided.')
            return
            
        # Save as pickle
        if as_pickle:
            with open(os.path.join(directory, f'{self.name}.pkl'), 'wb') as f:
                pickle.dump(self, f)
            return

        # Reset path
        path = os.path.join(directory, self.name)
        if os.path.isdir(path): shutil.rmtree(path)
        os.mkdir(path)

        if not slim and self.predictions is not None:
            preds = self.predictions.df.drop('bins', axis=1) if 'bins' in self.predictions.df else self.predictions.df
            preds.to_parquet(os.path.join(path, 'predictions.parquet'))
        if not slim and self.shapvalues is not None:
            self.shapvalues.to_parquet(os.path.join(path, 'shapvalues.parquet'))
        if self.feature_imp is not None:
            self.feature_imp.to_csv(os.path.join(path, 'features.csv'))
        if self.metrics is not None:
            self.metrics.to_csv(os.path.join(path, 'metrics.csv'))
        if self.confusion is not None:
            self.confusion.to_csv(os.path.join(path, 'confusion.csv'))
        with open(os.path.join(path, 'model.json'), 'w') as f:
            json.dump({'features': self.features, 'target': self.target, 'mode': self.mode, 
                       'algorithm':self.__class__.__name__.lower(), 'params': self.params}, f, indent=4)
        with open(os.path.join(path, 'model.pickle'), 'wb') as f:
            pickle.dump(self.clf, f)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Model.load</span><span class="signature">(self, path=None, slim=False) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Modelloadmod"></i></span>
</h3>
<p>Load model.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>path</b></span>: <span class="datatype"><i>String, optional</i></span> Path where the model should be loaded from. Can be a path to a pipeline directory or pipeline pickle file. <br>
<span class="argument"><b>slim</b></span>: <span class="datatype"><i>Bool, default False</i></span> If True, will not load predictions and shapvalues. Generally not needed for prediction, but useful for inspection. </p>


    <div class="modal fade bd-example-modal-lg" id="Modelloadmod" tabindex="-1" role="dialog" aria-labelledby="ModelloadLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Modelload</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def load(self, path=None, slim=False):
        
        logging.info('Loading model')
        paths = path.split('/')
        storage = '/'.join(paths[:-1])

        # Load pickle file
        if paths[-1].endswith('.pkl'):
            name = paths[-1][:-4]
            with open(os.path.join(storage, f'{name}.pkl'), 'rb') as f:
                self = pickle.load(f)
            self.name = paths[-1][:-4]
            return self
        # Load files
        self.name = paths[-1]
        path = os.path.join(storage, self.name)

        files = os.listdir(path)
        self.feature_imp, self.metrics, self.confusion = None, None, None
        if 'features.csv' in files:
            self.feature_imp = pd.read_csv(os.path.join(path, 'features.csv'), index_col=0).squeeze('columns')
        if 'metrics.csv' in files:
            self.metrics = pd.read_csv(os.path.join(path, 'metrics.csv'), index_col=0, header=[0, 1])
        if 'confusion.csv' in files:
            self.confusion = pd.read_csv(os.path.join(path, 'confusion.csv'), index_col=[0, 1], header=[0, 1])
        if not slim and 'predictions.parquet' in files:
            self.predictions = Data(pd.read_parquet(os.path.join(path, 'predictions.parquet')), 'Preds')
        if not slim and 'shapvalues.parquet' in files:
            self.shapvalues = pd.read_parquet(os.path.join(path, 'shapvalues.parquet'))
        with open(os.path.join(path, 'model.json'), 'r') as f:
            data = json.load(f)
            self.features, self.target, self.mode, self.params = \
                data['features'], data['target'], data['mode'], data['params']
        with open(os.path.join(path, 'model.pickle'), 'rb') as f:
            self.clf = pickle.load(f)
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Regressiontab" role="tabpanel" aria-labelledby="Regressiontab" tabindex="0">
<p><h3>
<span class="function">Regression</span><span class="signature">(name='Regression') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Regressionmod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Regressionmod" tabindex="-1" role="dialog" aria-labelledby="RegressionLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Regression</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Regression(Model):
    
    def __init__(self, name='Regression'):
        super().__init__(name=name)
        
    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        # Initialize a classifier
        hyper_params['l1_ratio'] = hyper_params.get('hyper_params', 0)
        if self.mode in ('binaryclass', 'multiclass'):
            from sklearn.linear_model import LogisticRegression
            self.clf = LogisticRegression(penalty='elasticnet', solver='saga', 
                                          random_state=seed, **hyper_params)
        elif self.mode=='linear':   
            from sklearn.linear_model import ElasticNet 
            self.clf = ElasticNet(random_state=seed, **hyper_params)
        self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        coef = self.clf.coef_[0] if len(self.clf.coef_.shape)==2 else self.clf.coef_
        self.feature_imp = pd.Series(coef, index=self.features).sort_values(ascending=False).rename('importance')
        return self
    
    def _predict_scores(self, data):
        super()._predict_scores()
        if self.mode=='binaryclass':
            scores = self.clf.predict_proba(data.df[self.features].astype(float))[:, 1]
        elif self.mode=='multiclass':    
            scores = self.clf.predict_proba(data.df[self.features].astype(float))
        elif self.mode=='linear':    
            scores = self.clf.predict(data.df[self.features].astype(float))
        return scores
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Regression.learn</span><span class="signature">(self, data, target, mode, hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Regressionlearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="Regressionlearnmod" tabindex="-1" role="dialog" aria-labelledby="RegressionlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Regressionlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        # Initialize a classifier
        hyper_params['l1_ratio'] = hyper_params.get('hyper_params', 0)
        if self.mode in ('binaryclass', 'multiclass'):
            from sklearn.linear_model import LogisticRegression
            self.clf = LogisticRegression(penalty='elasticnet', solver='saga', 
                                          random_state=seed, **hyper_params)
        elif self.mode=='linear':   
            from sklearn.linear_model import ElasticNet 
            self.clf = ElasticNet(random_state=seed, **hyper_params)
        self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        coef = self.clf.coef_[0] if len(self.clf.coef_.shape)==2 else self.clf.coef_
        self.feature_imp = pd.Series(coef, index=self.features).sort_values(ascending=False).rename('importance')
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Xgboosttab" role="tabpanel" aria-labelledby="Xgboosttab" tabindex="0">
<p><h3>
<span class="function">Xgboost</span><span class="signature">(name='Xgboost') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Xgboostmod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Xgboostmod" tabindex="-1" role="dialog" aria-labelledby="XgboostLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Xgboost</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Xgboost(Model): 
    
    def __init__(self, name='Xgboost'):
        super().__init__(name=name)
        
    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        # Make sure hyper params are integers where needed
        for h in ['n_estimators', 'gamma', 'early_stopping_rounds']:
            if hyper_params.get(h): hyper_params[h] = int(hyper_params[h])
        
        # Initialize and train a classifier
        if self.mode in ('binaryclass', 'multiclass'):
            from xgboost import XGBClassifier
            self.clf = XGBClassifier(random_state=seed, **hyper_params)
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target], eval_metric='logloss')
            if self.mode=='multiclass': self.categories = self.clf.classes_
        elif self.mode=='linear':
            from xgboost import XGBRegressor
            self.clf = XGBRegressor(random_state=seed, **hyper_params) 
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        self.feature_imp = pd.Series(
            self.clf.feature_importances_, index=self.features).sort_values(ascending=False).rename('importance')
        return self
    
    def _predict_scores(self, data):
        super()._predict_scores()
        if self.mode=='binaryclass':
            scores = self.clf.predict_proba(data.df[self.features].astype(float))[:, 1]
        elif self.mode=='multiclass':
            scores = self.clf.predict_proba(data.df[self.features].astype(float))
        elif self.mode=='linear':    
            scores = self.clf.predict(data.df[self.features].astype(float))
        return scores
    
    def explain(self, data):
        super().explain(data)
        import shap
        X = data.df[self.features].astype(float)
        explainer = shap.Explainer(self.clf, feature_names=self.features)
        self.shapvalues = explainer.shap_values(X, check_additivity=True)
        if len(np.array(self.shapvalues).shape)&amp;gt;2: self.shapvalues = self.shapvalues[0]

        self.shapvalues = pd.DataFrame(self.shapvalues, columns=self.features, index=X.index)
        #self.shap_expected = float(explainer.expected_value)

        # Sort columns of shap values based on global importance
        self.shapvalues = self.shapvalues[
            self.shapvalues.abs().sum().sort_values(ascending=False).index]
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Xgboost.learn</span><span class="signature">(self, data, target, mode, hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Xgboostlearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="Xgboostlearnmod" tabindex="-1" role="dialog" aria-labelledby="XgboostlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Xgboostlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        # Make sure hyper params are integers where needed
        for h in ['n_estimators', 'gamma', 'early_stopping_rounds']:
            if hyper_params.get(h): hyper_params[h] = int(hyper_params[h])
        
        # Initialize and train a classifier
        if self.mode in ('binaryclass', 'multiclass'):
            from xgboost import XGBClassifier
            self.clf = XGBClassifier(random_state=seed, **hyper_params)
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target], eval_metric='logloss')
            if self.mode=='multiclass': self.categories = self.clf.classes_
        elif self.mode=='linear':
            from xgboost import XGBRegressor
            self.clf = XGBRegressor(random_state=seed, **hyper_params) 
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        self.feature_imp = pd.Series(
            self.clf.feature_importances_, index=self.features).sort_values(ascending=False).rename('importance')
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Xgboost.explain</span><span class="signature">(self, data) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Xgboostexplainmod"></i></span>
</h3>
<p>Explain the model with a data object, either globally (regression coefficients) or 
locally (shap values).</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to use for explainability. </p>


    <div class="modal fade bd-example-modal-lg" id="Xgboostexplainmod" tabindex="-1" role="dialog" aria-labelledby="XgboostexplainLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Xgboostexplain</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def explain(self, data):
        super().explain(data)
        import shap
        X = data.df[self.features].astype(float)
        explainer = shap.Explainer(self.clf, feature_names=self.features)
        self.shapvalues = explainer.shap_values(X, check_additivity=True)
        if len(np.array(self.shapvalues).shape)&amp;gt;2: self.shapvalues = self.shapvalues[0]

        self.shapvalues = pd.DataFrame(self.shapvalues, columns=self.features, index=X.index)
        #self.shap_expected = float(explainer.expected_value)

        # Sort columns of shap values based on global importance
        self.shapvalues = self.shapvalues[
            self.shapvalues.abs().sum().sort_values(ascending=False).index]
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="NeuralNettab" role="tabpanel" aria-labelledby="NeuralNettab" tabindex="0">
<p><h3>
<span class="function">NeuralNet</span><span class="signature">(name='neuralnet') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#NeuralNetmod"></i></span>
</h3><p>This class collects methods for training and utilising an Xgboost model.</p>

    <div class="modal fade bd-example-modal-lg" id="NeuralNetmod" tabindex="-1" role="dialog" aria-labelledby="NeuralNetLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">NeuralNet</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class NeuralNet(Model):
        
    
    def __init__(self, name='neuralnet'):
        super().__init__(name=name)
        self._name = name

    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        
        logging.info(f'{data.df.shape} - {data.name} - training {self.name} with parameters {hyper_params}')
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        from tensorflow.keras.regularizers import l1_l2
        from tensorflow.keras.optimizers import Adam
        from tensorflow.keras.models import Model as KerasModel
        from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, MaxPooling2D, Flatten, Concatenate, BatchNormalization, Activation

        np.random.seed(seed)
        assert mode in ('linear', 'binaryclass', 'multiclass', 'multilabel'), \
            "Mode should be one of ('linear', 'binaryclass', 'multiclass', 'multilabel')"
        set_aside = [] if set_aside is None else set_aside
        self.features = [c for c in data.df.columns if c not in set_aside and c!=target]
        self.target = target
        self.mode = mode
        if 'activation' not in hyper_params.keys(): hyper_params['activation'] = 'tanh'
        if 'regularization' not in hyper_params.keys(): hyper_params['regularization'] = None
        if 'epochs' not in hyper_params.keys(): hyper_params['epochs'] = 10
        if 'batch_size' not in hyper_params.keys(): hyper_params['batch_size'] = 16

        # Store features to train on
        act = hyper_params['activation']
        reg = l1_l2(hyper_params['regularization'], hyper_params['regularization'])
        outputs_n = 1 if self.mode in ('linear', 'binaryclass') else data.df[target].nunique()
        output_act = 'sigmoid' if self.mode=='binaryclass' \
            else 'linear' if self.mode=='linear' \
            else 'softmax' if self.mode=='multiclass' \
            else 'NOT_IMPLEMENTED'

        if data.type=='visual' and hyper_params['transfer_learning']:

            # Retrieve and set pretrained model
            input_layer = Input(shape=data.dimensions)
            import tensorflow_hub as hub
            x = hub.KerasLayer(hyper_params['transfer_learning'], output_shape=None, trainable=False)(input_layer)
            x = Dropout(0.5)(x)
            x = Dense(512, activation=act)(x)
            x = Dropout(0.5)(x)
            if len(self.features) &amp;gt; 0:
                input_layer2 = Input(shape=len(self.features))
                input_layer = [input_layer, input_layer2]
                x = Concatenate()([x, input_layer2])

        # Build network architecture
        elif data.type=='visual' and not hyper_params['transfer_learning']:
            input_layer = x = Input(shape=data.dimensions)
            counter = 1
            while x.shape[1] &amp;gt; 2:
                x = Conv2D(data.dimensions[-1]*2**counter, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=act)(x)
                x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
                counter += 1
            if len(self.features) &amp;gt; 0:
                input_layer2 = Input(shape=len(self.features))
                input_layer = [input_layer, input_layer2]
                x = Concatenate()([x, input_layer2])
            x = Dropout(0.5)(x)
            x = Flatten()(x)
            layers = calculate_layers(x.shape[1], outputs_n)

            for layer in layers:
                x = Dense(layer, act, kernel_regularizer=reg)(x)
            x = Dropout(0.5)(x)

        elif data.type == 'tabular':
            input_layer = x = Input(shape=len(self.features))
            layers = calculate_layers(x.shape[1], outputs_n)
            for layer in layers:
                x = Dense(layer, act, kernel_regularizer=reg)(x)
            x = Dropout(0.5)(x)
            
        output_layer = Dense(outputs_n, activation=output_act)(x)
        self.clf = KerasModel(inputs=input_layer, outputs=output_layer)
        self.clf.summary()

        # Compile, with mean_squared_error or binary_crossentropy loss
        loss = 'mean_squared_error' if self.mode=='linear' \
            else 'binary_crossentropy' if self.mode=='binaryclass'\
            else 'categorical_crossentropy' if self.mode=='multiclass'\
            else 'NOT_IMPLEMENTED'
        metrics = ['accuracy'] if self.mode in ('binaryclass', 'multiclass') else []
        self.clf.compile(Adam(lr=hyper_params['learning_rate']), loss=loss, metrics=metrics)
        
        # Train
        from tensorflow.keras.callbacks import EarlyStopping
        callback = EarlyStopping(monitor='loss', mode='min', patience=5, restore_best_weights=True, verbose=1)
        if data.type=='visual':
            history = self.clf.fit(data.get_generator(self.mode, train=True, batch_size=hyper_params['batch_size']), 
                epochs=hyper_params['epochs'], use_multiprocessing=True, workers=5, callbacks=[callback])

        elif data.type=='tabular':
            if self.mode=='binaryclass': target = data.df[self.target].cat.codes
            elif self.mode=='multiclass': 
                target = pd.get_dummies(data.df[self.target])
                self.categories = target.columns.values
            elif self.mode=='linear': target = data.df[self.target]
            history = self.clf.fit(data.df[self.features].astype(float), target, callbacks=[callback],
                                epochs=hyper_params['epochs'], use_multiprocessing=True,
                                batch_size=hyper_params['batch_size'])#, verbose=0)
        # Show feature importance
        self.feature_imp = pd.Series()  # Todo: implement
        return self

    def _predict_scores(self, data):
        super()._predict_scores()
        if data.type == 'visual':
            X = data.get_generator(self.mode, train=False)
        elif data.type=='tabular':
            X = data.df[self.features].astype(float)
        if self.mode in ('binaryclass', 'linear'):
            scores = self.clf.predict(X).flatten()
        elif self.mode=='multiclass':
            scores = self.clf.predict(X)
        return scores
    
    def explain(self, data, split=2):
        super().explain(data)
        assert(split in data.df.index.levels[0], "Split is not present in data")
        # TODO: implement
        pass
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">NeuralNet.learn</span><span class="signature">(self, data, target, mode, hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#NeuralNetlearnmod"></i></span>
</h3>
<p>This function trains a model.</p>

    <div class="modal fade bd-example-modal-lg" id="NeuralNetlearnmod" tabindex="-1" role="dialog" aria-labelledby="NeuralNetlearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">NeuralNetlearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        
        logging.info(f'{data.df.shape} - {data.name} - training {self.name} with parameters {hyper_params}')
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        from tensorflow.keras.regularizers import l1_l2
        from tensorflow.keras.optimizers import Adam
        from tensorflow.keras.models import Model as KerasModel
        from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, MaxPooling2D, Flatten, Concatenate, BatchNormalization, Activation

        np.random.seed(seed)
        assert mode in ('linear', 'binaryclass', 'multiclass', 'multilabel'), \
            "Mode should be one of ('linear', 'binaryclass', 'multiclass', 'multilabel')"
        set_aside = [] if set_aside is None else set_aside
        self.features = [c for c in data.df.columns if c not in set_aside and c!=target]
        self.target = target
        self.mode = mode
        if 'activation' not in hyper_params.keys(): hyper_params['activation'] = 'tanh'
        if 'regularization' not in hyper_params.keys(): hyper_params['regularization'] = None
        if 'epochs' not in hyper_params.keys(): hyper_params['epochs'] = 10
        if 'batch_size' not in hyper_params.keys(): hyper_params['batch_size'] = 16

        # Store features to train on
        act = hyper_params['activation']
        reg = l1_l2(hyper_params['regularization'], hyper_params['regularization'])
        outputs_n = 1 if self.mode in ('linear', 'binaryclass') else data.df[target].nunique()
        output_act = 'sigmoid' if self.mode=='binaryclass' \
            else 'linear' if self.mode=='linear' \
            else 'softmax' if self.mode=='multiclass' \
            else 'NOT_IMPLEMENTED'

        if data.type=='visual' and hyper_params['transfer_learning']:

            # Retrieve and set pretrained model
            input_layer = Input(shape=data.dimensions)
            import tensorflow_hub as hub
            x = hub.KerasLayer(hyper_params['transfer_learning'], output_shape=None, trainable=False)(input_layer)
            x = Dropout(0.5)(x)
            x = Dense(512, activation=act)(x)
            x = Dropout(0.5)(x)
            if len(self.features) &amp;gt; 0:
                input_layer2 = Input(shape=len(self.features))
                input_layer = [input_layer, input_layer2]
                x = Concatenate()([x, input_layer2])

        # Build network architecture
        elif data.type=='visual' and not hyper_params['transfer_learning']:
            input_layer = x = Input(shape=data.dimensions)
            counter = 1
            while x.shape[1] &amp;gt; 2:
                x = Conv2D(data.dimensions[-1]*2**counter, kernel_size=(4, 4), strides=(2, 2), padding='same', activation=act)(x)
                x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)
                counter += 1
            if len(self.features) &amp;gt; 0:
                input_layer2 = Input(shape=len(self.features))
                input_layer = [input_layer, input_layer2]
                x = Concatenate()([x, input_layer2])
            x = Dropout(0.5)(x)
            x = Flatten()(x)
            layers = calculate_layers(x.shape[1], outputs_n)

            for layer in layers:
                x = Dense(layer, act, kernel_regularizer=reg)(x)
            x = Dropout(0.5)(x)

        elif data.type == 'tabular':
            input_layer = x = Input(shape=len(self.features))
            layers = calculate_layers(x.shape[1], outputs_n)
            for layer in layers:
                x = Dense(layer, act, kernel_regularizer=reg)(x)
            x = Dropout(0.5)(x)
            
        output_layer = Dense(outputs_n, activation=output_act)(x)
        self.clf = KerasModel(inputs=input_layer, outputs=output_layer)
        self.clf.summary()

        # Compile, with mean_squared_error or binary_crossentropy loss
        loss = 'mean_squared_error' if self.mode=='linear' \
            else 'binary_crossentropy' if self.mode=='binaryclass'\
            else 'categorical_crossentropy' if self.mode=='multiclass'\
            else 'NOT_IMPLEMENTED'
        metrics = ['accuracy'] if self.mode in ('binaryclass', 'multiclass') else []
        self.clf.compile(Adam(lr=hyper_params['learning_rate']), loss=loss, metrics=metrics)
        
        # Train
        from tensorflow.keras.callbacks import EarlyStopping
        callback = EarlyStopping(monitor='loss', mode='min', patience=5, restore_best_weights=True, verbose=1)
        if data.type=='visual':
            history = self.clf.fit(data.get_generator(self.mode, train=True, batch_size=hyper_params['batch_size']), 
                epochs=hyper_params['epochs'], use_multiprocessing=True, workers=5, callbacks=[callback])

        elif data.type=='tabular':
            if self.mode=='binaryclass': target = data.df[self.target].cat.codes
            elif self.mode=='multiclass': 
                target = pd.get_dummies(data.df[self.target])
                self.categories = target.columns.values
            elif self.mode=='linear': target = data.df[self.target]
            history = self.clf.fit(data.df[self.features].astype(float), target, callbacks=[callback],
                                epochs=hyper_params['epochs'], use_multiprocessing=True,
                                batch_size=hyper_params['batch_size'])#, verbose=0)
        # Show feature importance
        self.feature_imp = pd.Series()  # Todo: implement
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">NeuralNet.explain</span><span class="signature">(self, data, split=2) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#NeuralNetexplainmod"></i></span>
</h3>
<p>Explain the model with a data object, either globally (regression coefficients) or 
locally (shap values).</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object to use for explainability. </p>


    <div class="modal fade bd-example-modal-lg" id="NeuralNetexplainmod" tabindex="-1" role="dialog" aria-labelledby="NeuralNetexplainLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">NeuralNetexplain</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def explain(self, data, split=2):
        super().explain(data)
        assert(split in data.df.index.levels[0], "Split is not present in data")
        # TODO: implement
        pass
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="DecisionTreetab" role="tabpanel" aria-labelledby="DecisionTreetab" tabindex="0">
<p><h3>
<span class="function">DecisionTree</span><span class="signature">(name='Decisiontree') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#DecisionTreemod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="DecisionTreemod" tabindex="-1" role="dialog" aria-labelledby="DecisionTreeLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">DecisionTree</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class DecisionTree(Model):
    
    def __init__(self, name='Decisiontree'):
        super().__init__(name=name)

    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        
        # Initialize a classifier
        if self.mode in ('binaryclass', 'multiclass'):
            from sklearn.tree import DecisionTreeClassifier
            self.clf = DecisionTreeClassifier(random_state=seed, **hyper_params)
        elif self.mode=='linear':
            from sklearn.tree import DecisionTreeRegressor
            self.clf = DecisionTreeRegressor(random_state=seed, **hyper_params)
        self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        self.feature_imp = None
        return self
    
    def _predict_scores(self, data):
        super()._predict_scores()
        if self.mode=='binaryclass':
            scores = self.clf.predict_proba(data.df[self.features].astype(float))[:, 1]
        elif self.mode=='multiclass':    
            scores = self.clf.predict_proba(data.df[self.features].astype(float))
        elif self.mode=='linear':    
            scores = self.clf.predict(data.df[self.features].astype(float))
        return scores
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">DecisionTree.learn</span><span class="signature">(self, data, target, mode, hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#DecisionTreelearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="DecisionTreelearnmod" tabindex="-1" role="dialog" aria-labelledby="DecisionTreelearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">DecisionTreelearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        
        # Initialize a classifier
        if self.mode in ('binaryclass', 'multiclass'):
            from sklearn.tree import DecisionTreeClassifier
            self.clf = DecisionTreeClassifier(random_state=seed, **hyper_params)
        elif self.mode=='linear':
            from sklearn.tree import DecisionTreeRegressor
            self.clf = DecisionTreeRegressor(random_state=seed, **hyper_params)
        self.clf.fit(data.df[self.features].astype(float), data.df[self.target])

        # Show feature importance
        self.feature_imp = None
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Isotonictab" role="tabpanel" aria-labelledby="Isotonictab" tabindex="0">
<p><h3>
<span class="function">Isotonic</span><span class="signature">(name='Isotonic') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Isotonicmod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="Isotonicmod" tabindex="-1" role="dialog" aria-labelledby="IsotonicLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Isotonic</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Isotonic(Model):

    def __init__(self, name='Isotonic'):
        super().__init__(name=name)
        
    def learn(self, data, target, mode=None, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        assert len(self.features)==1, f'Can only use mapping on 1 features, but {len(self.features)} were given.'
        method = hyper_params.get('method', 'quantile')
        
        if method == 'quantile':
            n_quantiles = 1000

            # Clf is a mapping table with quantiles on the scores and the target. This acts as the 'model'
            self.clf = pd.DataFrame(dict(
                scores = data.df[self.features[0]], target = data.df[self.target]
            )).quantile(np.arange(0, 1, 1/n_quantiles))
            self.clf.index = pd.Series(self.clf.index).apply(lambda x: round(x, len(str(n_quantiles))-1)) # Rounding issue

            # This line provides an upper cap so we always find a mapping
            self.clf.loc[2.00] = dict(scores = 1e10, target = self.clf.iloc[-1].target)  
            self.clf.target = self.clf.target.astype(data.df[self.target].dtype)
        
        elif method == 'regression':
            del hyper_params['method']
            from sklearn.isotonic import IsotonicRegression
            self.clf = IsotonicRegression(**hyper_params)
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target])
        return self
    
    def _predict_scores(self, data):
        super()._predict_scores()
        scores = data.df[self.features[0]].astype(float)
        if isinstance(self.clf, pd.DataFrame):
            # Quantile method: look up first row in quantile table with a higher score, and take that target quentile
            new_scores = self.clf.target.iloc[pd.Series(np.searchsorted(self.clf.scores, scores))].values
        else:
            # Regression method: predict with classifier
            new_scores = self.clf.predict(scores)
        return new_scores
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Isotonic.learn</span><span class="signature">(self, data, target, mode=None, hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Isotoniclearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="Isotoniclearnmod" tabindex="-1" role="dialog" aria-labelledby="IsotoniclearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Isotoniclearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target, mode=None, hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)

        assert len(self.features)==1, f'Can only use mapping on 1 features, but {len(self.features)} were given.'
        method = hyper_params.get('method', 'quantile')
        
        if method == 'quantile':
            n_quantiles = 1000

            # Clf is a mapping table with quantiles on the scores and the target. This acts as the 'model'
            self.clf = pd.DataFrame(dict(
                scores = data.df[self.features[0]], target = data.df[self.target]
            )).quantile(np.arange(0, 1, 1/n_quantiles))
            self.clf.index = pd.Series(self.clf.index).apply(lambda x: round(x, len(str(n_quantiles))-1)) # Rounding issue

            # This line provides an upper cap so we always find a mapping
            self.clf.loc[2.00] = dict(scores = 1e10, target = self.clf.iloc[-1].target)  
            self.clf.target = self.clf.target.astype(data.df[self.target].dtype)
        
        elif method == 'regression':
            del hyper_params['method']
            from sklearn.isotonic import IsotonicRegression
            self.clf = IsotonicRegression(**hyper_params)
            self.clf.fit(data.df[self.features].astype(float), data.df[self.target])
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="GaussianMixturetab" role="tabpanel" aria-labelledby="GaussianMixturetab" tabindex="0">
<p><h3>
<span class="function">GaussianMixture</span><span class="signature">(name='GM') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#GaussianMixturemod"></i></span>
</h3><p>This class collects methods for learning, applying, evaluating and explaining a model.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>name</b></span>: <span class="datatype"><i>String, default 'Model'</i></span> Arbitrary name for the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Model.name</b></span>: <span class="datatype"><i>String</i></span> Name of the model object, that shows up in many of the LFD output, such as metrics, confusions, dashboards, etc. <br>
<span class="argument"><b>Model.params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyperparameters used in the underlying algorithm. <br>
<span class="argument"><b>Model.clf</b></span>: <span class="datatype"><i>Any</i></span> Underlying modelling object that is different per subclass. E.g. sklearn.linear_model.LogisticRegression <br>
<span class="argument"><b>Model.features</b></span>: <span class="datatype"><i>List[String]</i></span> List of features used in the learning or applying of the model. <br>
<span class="argument"><b>Model.target</b></span>: <span class="datatype"><i>String</i></span> In case of supervised learning, what variable to use as  a target to train on. <br>
<span class="argument"><b>Model.categories</b></span>: <span class="datatype"><i>np.array[String]</i></span> In case of multiclass learning, what are the categories of the target. <br>
<span class="argument"><b>Model.mode</b></span>: <span class="datatype"><i>String</i></span> Type of model. One of ('linear', 'binaryclass', 'multiclass', 'multilabel', 'clustering', 'dimensionreduction', 'anomalydetection') <br>
<span class="argument"><b>Model.feature_imp</b></span>: <span class="datatype"><i>pandas.Series</i></span> Series of model specific features with importance. Not the same as SHAP. <br>
<span class="argument"><b>Model.predictions</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data object that centralizes scores and predictions for all observations, as a result of Model.apply(). <br>
<span class="argument"><b>Model.confusion</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Confusion matrix, broken into data split, as a result from Model.evaluate(). <br>
<span class="argument"><b>Model.confusion_cuts</b></span>: <span class="datatype"><i>List[Float]</i></span> In case of linear outputs, the cutoff thresholds used to bin in favour of a confusion matrix. <br>
<span class="argument"><b>Model.metrics</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Metrics table centralizing metrics, as a result of Model.evaluate(). <br>
<span class="argument"><b>Model.shapvalues</b></span>: <span class="datatype"><i>pd.DataFrame</i></span> Shap value table, as a result of Model.explain(). Has same dimensions as data object. </p>


    <div class="modal fade bd-example-modal-lg" id="GaussianMixturemod" tabindex="-1" role="dialog" aria-labelledby="GaussianMixtureLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">GaussianMixture</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class GaussianMixture(Model):

    def __init__(self, name='GM'):
        super().__init__(name=name)
        
    def learn(self, data, target=None, mode='clustering', hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        
        # Initialize and train a classifier
        from sklearn.mixture import GaussianMixture as GM
        self.clf = GM(**hyper_params, random_state=seed)
        scores = self.clf.fit_predict(data.df[self.features].astype(float))
        self.feature_imp = calculate_cluster_drivers(data.df[self.features], scores)
        return self
    
    def _predict_scores(self, data):
        super()._predict_scores()
        scores = self.clf.predict_proba(data.df[self.features])
        return scores
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">GaussianMixture.learn</span><span class="signature">(self, data, target=None, mode='clustering', hyper_params={}, set_aside=None, seed=0) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#GaussianMixturelearnmod"></i></span>
</h3>
<p>Learn a model on a data (training) object.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>data</b></span>: <span class="datatype"><i>lfd.Data</i></span> Data used for training the model. <br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable for supervised learning. <br>
<span class="argument"><b>hyper_params</b></span>: <span class="datatype"><i>Dict</i></span> Dictionary of hyper parameters which is passed on to the underlying algorithm. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List[String]</i></span> List of column names which are not included as features in training. <br>
<span class="argument"><b>seed</b></span>: <span class="datatype"><i>Integer, default 0</i></span> Defining the seed for reproducibility when training. </p>


    <div class="modal fade bd-example-modal-lg" id="GaussianMixturelearnmod" tabindex="-1" role="dialog" aria-labelledby="GaussianMixturelearnLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">GaussianMixturelearn</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def learn(self, data, target=None, mode='clustering', hyper_params={}, set_aside=None, seed=0):
        super().learn(data, target, mode, hyper_params, set_aside, seed)
        
        # Initialize and train a classifier
        from sklearn.mixture import GaussianMixture as GM
        self.clf = GM(**hyper_params, random_state=seed)
        scores = self.clf.fit_predict(data.df[self.features].astype(float))
        self.feature_imp = calculate_cluster_drivers(data.df[self.features], scores)
        return self
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="Plottertab" role="tabpanel" aria-labelledby="Plottertab" tabindex="0">
<p><h3>
<span class="function">Plotter</span><span class="signature">(colors=None, theme='light') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plottermod"></i></span>
</h3><p>This class collects methods for visualization.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>colors</b></span>: <span class="datatype"><i>String, default 'belfius'</i></span> Defines which color scheme to use accross al charts. Should be one of ('belfius', 'google', 'amazon', 'facebook') <br>
<span class="argument"><b>theme</b></span>: <span class="datatype"><i>String, default 'light'</i></span> Whether to run all visualizations in light or dark mode. Should be in ('light', 'dark'). <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Plotter.colors</b></span>: <span class="datatype"><i>List[String]</i></span> List of color hexacodes to use throughout the visualizations. <br>
<span class="argument"><b>Plotter.theme</b></span>: <span class="datatype"><i>String</i></span> Whether all visualizations run in light or dark mode. Either 'light' or 'dark'. </p>


    <div class="modal fade bd-example-modal-lg" id="Plottermod" tabindex="-1" role="dialog" aria-labelledby="PlotterLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotter</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class Plotter:
    
    def __init__(self, colors=None, theme='light'):
        color_dict = {
            "google": ["#4285f4", "#34a853", "#fbbc05", "#ea4335"]*10,
            "amazon": ["#ff9900", "#146eb4", "#232f3e"]*10,
            "facebook": ["#3b5998", "#8b9dc3", "#dfe3ee"]*10,
            "ngdata": ["#3E9539", "#3244C9", "#252827"]*10,
            "belfius": ['#CD5C5C', '#8e8e8e', '#ffaa00', '#00a4f7', '#029900']*10
        }
        self.colors = color_dict['belfius'] if colors is None else color_dict[colors]
        self.theme = 'plotly_dark' if theme=='dark' else 'plotly_white'
        self._plotcolor = "#fff" if self.theme=='plotly_white' else "#333"
        self._kwargs = dict(template=self.theme, paper_bgcolor=self._plotcolor, plot_bgcolor=self._plotcolor)

    def heatmap(self, x=None, y=None, z=None, data=None, aggfunc=None, bins=5, bins2=None, normalize=False, 
                cumulative=False, switch=False, bin_mode='quantile', bin_cats=None, bin_cats2=None):
        
        if data is not None: conf = data
        else:
            x_numeric = x.dtype.kind in 'iufc'
            y_numeric = y.dtype.kind in 'iufc'

            x, y = x.reset_index(drop=True), y.reset_index(drop=True)
            if not x_numeric and not y_numeric and (bin_cats2 or bin_cats): 
                bin_cats, bin_cats2 = bin_cats2, bin_cats
            if bin_cats and not x_numeric:
                mask = x.astype(str).isin(bin_cats)
                x, y = (x[mask], y[mask])
            if bin_cats2 and not y_numeric:
                mask = y.astype(str).isin(bin_cats2)
                x, y = (x[mask], y[mask])
            if switch: (x, y) = (y, x)
            bins2 = bins2 if bins2 else bins
            cut = pd.qcut if bin_mode=='quantile' else pd.cut
            bins, bins2 = min(bins, 20), min(bins2, 20)

            # Group x and y
            assert (x is not None and y is not None), 'Either give a Dataframe, or x - y Series to heatmap.'
            x_togroup = bins &amp;lt; x.nunique()
            if x_numeric and x_togroup: x = cut(x, bins, duplicates='drop')
            elif not x_numeric and x_togroup:
                x = x.astype(str)
                x[x.isin(x.value_counts().index[bins-1:])] = '&amp;lt;Other&amp;gt;'
            y_togroup = bins2 &amp;lt; y.nunique()
            if y_numeric and y_togroup: y = cut(y, bins2, duplicates='drop')
            elif not y_numeric and y_togroup:
                y = y.astype(str)
                y[y.isin(y.value_counts().index[bins2-1:])] = '&amp;lt;Other&amp;gt;'

            # Build crosstab
            conf = pd.crosstab(x, y, z, aggfunc=aggfunc, normalize=0 if normalize else False).round(3)
            if not x_numeric: conf = conf.loc[x.value_counts().index[:bins][::-1]]
            if not y_numeric: conf = conf.loc[:, y.value_counts().index[:bins2]]
            if cumulative: conf = conf.cumsum(axis=1)
            if x_numeric and x_togroup:
                conf.index = conf.index.to_series().apply(lambda x: f'{x.left.round(3)}+')
            else: conf.index = conf.index.astype(str)+'_'
            if y_numeric and y_togroup:
                conf.columns = conf.columns.to_series().apply(lambda x: f'{x.left.round(3)}+')
            else: conf.columns = conf.columns.astype(str)+'_'
            conf['All'] = conf.sum(axis=1).round(2) if not cumulative else conf.iloc[:, -1]
            conf.index.name, conf.columns.name = x.name, y.name

        # Build figure
        fig = make_subplots(rows=1, cols=1)
        fig.add_trace(go.Heatmap(x=conf.columns, y=conf.index, z=conf.assign(All=0).values, 
            hoverinfo='skip', showscale=False, xaxis="x", yaxis="y", zmin=conf.iloc[:, :-1].min().min(),
            zmax=conf.iloc[:, :-1].max().max(), colorscale=[[0, self._plotcolor], [1, self.colors[0]]]
        ), col=1, row=1)

        # Add value annotations on heatmaps
        if normalize: conf = conf.round(2)
        annotations = [dict(text=str(conf.loc[n, m]), showarrow=False, x=m, y=n,
                            xref="x", yref="y") for m in conf.columns for n in conf.index]
        # Update layout
        height = min(490, conf.shape[0]*40+180)
        fig.update_layout(
            annotations=annotations, yaxis=dict(title=conf.index.name), xaxis=dict(title=conf.columns.name), 
            autosize=True, height=height, margin=dict(l=80, r=20, b=20, t=40), **self._kwargs)
        return fig

    def line_chart(self, preds):
        
        binscores = get_binscores(preds, bins=50)
        x = binscores.target
        y = binscores.scores.drop('Total')
        counts = binscores['count'].drop('Total')

        variables = y.columns
        lin_max = max(y.max().max(), x.max().max())
        lin_min = min(y.min().min(), x.min().min())
        linspace = np.linspace(lin_max, lin_min, num=500)

        fig = go.Figure()
        for v, variable in enumerate(variables):
            fig.add_trace(go.Scatter(
                x=x[variable], y=y[variable], marker=dict(color=self.colors[v], size=4), name=variable, 
                opacity=0.8, text=counts[variable], textposition='middle center', mode='lines+markers', line_shape='spline'))
        fig.add_trace(go.Scatter(
            x=linspace, y=linspace, mode='lines',name='Ideal Prevalence', hoverinfo='skip',
            marker=dict(color='rgba(200,200,200,.5)', size=1), showlegend=False))

        fig.update_xaxes(title_text="Score")
        fig.update_yaxes(title_text="Prevalence", ticks="")
        fig.update_layout(legend=dict(x=.75, y=0.1), autosize=True, height=490, 
            margin=dict(l=40, r=10, b=50, t=20, pad=4), **self._kwargs)
        return fig

    def boxplots(self, x, y, bins=10, bin_mode='quantile', sort='value', reverse=False, switch=False, bin_cats=None):
        
        # Assert at least 1 continuous variable, put categorical one on x-axis if present
        assert x.dtype.kind in 'iufc' or y.dtype.kind in 'iufc', "At least x or y must be continuous."
        if x.dtype.kind in 'iufc' and y.dtype.kind not in 'iufc': x, y = (y, x)
        elif x.dtype.kind in 'iufc' and y.dtype.kind in 'iufc' and switch: x, y = (y, x)
        if bin_cats: 
            mask = x.isin(bin_cats)
            x, y = x[mask], y[mask]
        reverse = True if reverse else False

        # Group x variable, be it continuous or categorical
        cut = pd.qcut if bin_mode=='quantile' else pd.cut
        x_numeric = x.dtype.kind in 'iufc'
        x_togroup = bins &amp;lt; x.nunique()
        if x_numeric and x_togroup: x = cut(x, bins, duplicates='drop')
        elif not x_numeric and x_togroup:
            x = x.astype(str)
            to_show = x.value_counts().index if sort=='count' \
                else pd.Series(x.unique()).sort_values() if sort=='name' \
                else y.groupby(x).median().sort_values().dropna().index
            to_show = to_show[-bins+1:] if reverse else to_show[:bins-1]
            x[~x.isin(to_show)] = '&amp;lt;Other&amp;gt;'

        # Create boxplot
        boxplot = pd.concat((
            y.groupby(x).quantile([0.01, 0.25, 0.5, 0.75, 0.99]), 
            y.groupby(x).agg(['count', 'mean']).stack())).unstack(-1)
        boxplot.columns = boxplot.columns.astype(str)
        if x_numeric: boxplot = boxplot.sort_index()
        else: boxplot = boxplot.sort_index(ascending=not reverse) if sort=='name' else \
            boxplot.sort_values('count', ascending=reverse) if sort=='count' else \
            boxplot.sort_values('0.5', ascending=not reverse)
        if x_numeric and x_togroup: boxplot.index = boxplot.index.to_series().apply(
            lambda x: f'{x.left.round(3)}+' if type(x)!=float else x).astype(str)

        # Build figure
        fig = go.Figure()
        for i, cat in enumerate(boxplot.index):
            d = boxplot.loc[cat]
            c = 0 if np.isnan(d["count"]) else int(d["count"])
            fig.add_trace(
                go.Box(x=[f"{cat} (n={c})"], q1=[d['0.25']], q3=[d['0.75']], median=[d['0.5']], 
                upperfence=[d['0.99']], lowerfence=[d['0.01']], marker_color=self.colors[i%2], line=dict(width=1.5)))
        fig.update_layout(showlegend=False, yaxis=dict(title=y.name), autosize=True, height=490, 
            margin=dict(l=40, r=10, b=50, t=20, pad=4), xaxis=dict(title=x.name), **self._kwargs)
        return fig

    def plot_barchart(self, x, title):
        
        max_letters = min(x.index.to_series().apply(len).max(), 25)
        trace = go.Bar(x=x, y=x.index.str.slice(0, 25), orientation='h',
            marker=dict(color=x, colorscale=[[0.0, "#888"], [1.0, self.colors[0]]]))
        layout = go.Layout(showlegend=False, yaxis=dict(autorange="reversed", dtick=1), 
            xaxis=dict(title=title), height=len(x)*25+60, 
            margin=dict(t=30, l=max_letters*7, r=0, b=10, pad=10), **self._kwargs)
        fig = go.Figure([trace], layout)
        return fig

    def histogram(self, x, y=None, z=None, bins=20, normalize=False, cumulative=False, switch=False, bin_cats=None):
        
        df = pd.concat([series for series in [x, y, z] if series is not None], axis=1)
        if df.columns.duplicated().any(): df.columns = [f"{c}{i}" for i, c in enumerate(df, 1)]
        if bin_cats: df = df[x.isin(bin_cats)]

        # Group variable(s)
        is_numeric = x.dtype.kind in 'iufc'
        to_group = is_numeric and bins &amp;lt; df.nunique().max()
        if to_group:
            bins = np.linspace(df.min().min(), df.max().max(), bins+1).round(3)
            for c in df: df[c] = pd.cut(df[c], bins=bins, include_lowest=True)
        df = pd.concat([df[c].value_counts(normalize=normalize) for c in df], axis=1, keys=df.columns)
        if is_numeric: df.sort_index(inplace=True) 
        if not is_numeric: df = pd.concat(
            (df.iloc[:bins-1], df.iloc[bins-1:].sum(axis=0).rename('Other').to_frame().T), axis=0)
        if cumulative: df = pd.concat([df[c].cumsum() for c in df], axis=1)
        if to_group: df.index = df.index.to_series().apply(
            lambda x: f'{x.left.round(3)}+' if type(x)!=float else x).astype(str)

        # Build figure
        if switch: traces = [go.Bar(y=df.index.astype(str), x=df[c], marker=dict(
            color=self.colors[i]), name=c, orientation='h') for i, c in enumerate(df)]
        else: traces = [go.Bar(x=df.index.astype(str), y=df[c], marker=dict(
            color=self.colors[i]), name=c) for i, c in enumerate(df)]
        layout = go.Layout(autosize=True, height=490, margin=dict(t=20, r=20, b=50, l=20), 
            barmode='group', yaxis=dict(autorange="reversed") if switch else dict(), **self._kwargs)
        fig = go.Figure(traces, layout)
        return fig

    def scatter(self, x, y, z=None, identifier=None, switch=False, height=490):
        
        if switch: x, y = (y, x)
        if len(x) &amp;gt; 2000:
            np.random.seed(0)
            indices = np.random.choice(np.arange(len(x)), size=2000, replace=False)
            x, y, z = x.iloc[indices], y.iloc[indices], (z.iloc[indices] if z is not None else z)

        # Add some jitter on discrete values
        if x.nunique()&amp;lt;20: 
            x = x.astype(float)
            minmaxrange = (x.max()-x.min())/x.nunique()*0.6
            x += (np.random.uniform(size=len(x))-0.5)*minmaxrange
        if y.nunique()&amp;lt;20:
            y = y.astype(float)
            minmaxrange = (y.max()-y.min())/y.nunique()*0.6
            y += (np.random.uniform(size=len(y))-0.5)*minmaxrange

        # Set color params according to z
        if z is not None:
            if z.nunique()&amp;gt; 5: colorscale=[[0.0, self.colors[1]], [1.0, self.colors[0]]]
            else: colorscale=[[c, self.colors[i]] for i, c in enumerate(np.linspace(0, 1, z.nunique()))]
        else: colorscale = None
        
        # Build gigure
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(x=x, y=y, name=y.name, mode='markers', hoverinfo='text', hovertext=x.index,
                marker=dict(color=z if z is not None else self.colors[0], opacity=0.5, size=6, colorscale=colorscale))),
        if identifier is not None and identifier in x.index:
            fig.add_trace(go.Scatter(x=[x.loc[identifier]], y=[y.loc[identifier]], mode='markers', 
                hoverinfo='text', hovertext=identifier, marker=dict(color='#888', opacity=.8, size=20))),
        fig.update_layout(autosize=True, showlegend=z is not None, height=height, xaxis=dict(title=x.name), 
            yaxis=dict(title=y.name), margin=dict(t=30, r=10, b=10, l=20), **self._kwargs)
        return fig

    def make_datatable(self, identifier, data, height='200px', page_size=20, left_align=None, **kwargs):
        
        if left_align:
            style_cell_conditional=[{'if': {'column_id': c}, 'textAlign': 'left', 'fontWeight': '600'} for c in left_align]
            kwargs.update(style_cell_conditional=style_cell_conditional)
        background_header = '#333' if self.theme=='plotly_dark' else '#ddd'
        if page_size is not None: kwargs.update(dict(page_size=page_size))
        color = '#eee' if self.theme=='plotly_dark' else '#555'
        table = dt.DataTable(
            id=identifier, 
            data=data.loc[:, data.columns[:100]].to_dict('records'),
            columns=[{"name": i, "id": i} for i in data.columns[:100]],
            style_header={'font-family':'sans-serif', 'backgroundColor': background_header, 'color': color, 'fontWeight': 'bold'},
            style_data={'font-family':'sans-serif', 'backgroundColor': self._plotcolor, 'color': color},
            style_table={'height': height, 'overflowX': 'auto'},
            style_as_list_view=True,
            sort_action="native",
            **kwargs
        )
        return table

    def spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), xaxis=dict(showticklabels=False), 
            autosize=True, height=490, margin=dict(l=40, r=10, b=50, t=20, pad=4), **self._kwargs)
        return (fig)
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">Plotter.heatmap</span><span class="signature">(self, x=None, y=None, z=None, data=None, aggfunc=None, bins=5, bins2=None, normalize=False, cumulative=False, switch=False, bin_mode='quantile', bin_cats=None, bin_cats2=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterheatmapmod"></i></span>
</h3>
<p>Plots a heatmap. Either 3 pandas Series are given (x, y, and z=color) and the function 
aggregates them, or the data to heatmap is given straightaway.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterheatmapmod" tabindex="-1" role="dialog" aria-labelledby="PlotterheatmapLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterheatmap</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def heatmap(self, x=None, y=None, z=None, data=None, aggfunc=None, bins=5, bins2=None, normalize=False, 
                cumulative=False, switch=False, bin_mode='quantile', bin_cats=None, bin_cats2=None):
        
        if data is not None: conf = data
        else:
            x_numeric = x.dtype.kind in 'iufc'
            y_numeric = y.dtype.kind in 'iufc'

            x, y = x.reset_index(drop=True), y.reset_index(drop=True)
            if not x_numeric and not y_numeric and (bin_cats2 or bin_cats): 
                bin_cats, bin_cats2 = bin_cats2, bin_cats
            if bin_cats and not x_numeric:
                mask = x.astype(str).isin(bin_cats)
                x, y = (x[mask], y[mask])
            if bin_cats2 and not y_numeric:
                mask = y.astype(str).isin(bin_cats2)
                x, y = (x[mask], y[mask])
            if switch: (x, y) = (y, x)
            bins2 = bins2 if bins2 else bins
            cut = pd.qcut if bin_mode=='quantile' else pd.cut
            bins, bins2 = min(bins, 20), min(bins2, 20)

            # Group x and y
            assert (x is not None and y is not None), 'Either give a Dataframe, or x - y Series to heatmap.'
            x_togroup = bins &amp;lt; x.nunique()
            if x_numeric and x_togroup: x = cut(x, bins, duplicates='drop')
            elif not x_numeric and x_togroup:
                x = x.astype(str)
                x[x.isin(x.value_counts().index[bins-1:])] = '&amp;lt;Other&amp;gt;'
            y_togroup = bins2 &amp;lt; y.nunique()
            if y_numeric and y_togroup: y = cut(y, bins2, duplicates='drop')
            elif not y_numeric and y_togroup:
                y = y.astype(str)
                y[y.isin(y.value_counts().index[bins2-1:])] = '&amp;lt;Other&amp;gt;'

            # Build crosstab
            conf = pd.crosstab(x, y, z, aggfunc=aggfunc, normalize=0 if normalize else False).round(3)
            if not x_numeric: conf = conf.loc[x.value_counts().index[:bins][::-1]]
            if not y_numeric: conf = conf.loc[:, y.value_counts().index[:bins2]]
            if cumulative: conf = conf.cumsum(axis=1)
            if x_numeric and x_togroup:
                conf.index = conf.index.to_series().apply(lambda x: f'{x.left.round(3)}+')
            else: conf.index = conf.index.astype(str)+'_'
            if y_numeric and y_togroup:
                conf.columns = conf.columns.to_series().apply(lambda x: f'{x.left.round(3)}+')
            else: conf.columns = conf.columns.astype(str)+'_'
            conf['All'] = conf.sum(axis=1).round(2) if not cumulative else conf.iloc[:, -1]
            conf.index.name, conf.columns.name = x.name, y.name

        # Build figure
        fig = make_subplots(rows=1, cols=1)
        fig.add_trace(go.Heatmap(x=conf.columns, y=conf.index, z=conf.assign(All=0).values, 
            hoverinfo='skip', showscale=False, xaxis="x", yaxis="y", zmin=conf.iloc[:, :-1].min().min(),
            zmax=conf.iloc[:, :-1].max().max(), colorscale=[[0, self._plotcolor], [1, self.colors[0]]]
        ), col=1, row=1)

        # Add value annotations on heatmaps
        if normalize: conf = conf.round(2)
        annotations = [dict(text=str(conf.loc[n, m]), showarrow=False, x=m, y=n,
                            xref="x", yref="y") for m in conf.columns for n in conf.index]
        # Update layout
        height = min(490, conf.shape[0]*40+180)
        fig.update_layout(
            annotations=annotations, yaxis=dict(title=conf.index.name), xaxis=dict(title=conf.columns.name), 
            autosize=True, height=height, margin=dict(l=80, r=20, b=20, t=40), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.line_chart</span><span class="signature">(self, preds) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterline_chartmod"></i></span>
</h3>
<p>Plots a linechart.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterline_chartmod" tabindex="-1" role="dialog" aria-labelledby="Plotterline_chartLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterline_chart</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def line_chart(self, preds):
        
        binscores = get_binscores(preds, bins=50)
        x = binscores.target
        y = binscores.scores.drop('Total')
        counts = binscores['count'].drop('Total')

        variables = y.columns
        lin_max = max(y.max().max(), x.max().max())
        lin_min = min(y.min().min(), x.min().min())
        linspace = np.linspace(lin_max, lin_min, num=500)

        fig = go.Figure()
        for v, variable in enumerate(variables):
            fig.add_trace(go.Scatter(
                x=x[variable], y=y[variable], marker=dict(color=self.colors[v], size=4), name=variable, 
                opacity=0.8, text=counts[variable], textposition='middle center', mode='lines+markers', line_shape='spline'))
        fig.add_trace(go.Scatter(
            x=linspace, y=linspace, mode='lines',name='Ideal Prevalence', hoverinfo='skip',
            marker=dict(color='rgba(200,200,200,.5)', size=1), showlegend=False))

        fig.update_xaxes(title_text="Score")
        fig.update_yaxes(title_text="Prevalence", ticks="")
        fig.update_layout(legend=dict(x=.75, y=0.1), autosize=True, height=490, 
            margin=dict(l=40, r=10, b=50, t=20, pad=4), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.boxplots</span><span class="signature">(self, x, y, bins=10, bin_mode='quantile', sort='value', reverse=False, switch=False, bin_cats=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterboxplotsmod"></i></span>
</h3>
<p>Plots boxplots. Needs one categorical and one numerical variable.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterboxplotsmod" tabindex="-1" role="dialog" aria-labelledby="PlotterboxplotsLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterboxplots</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def boxplots(self, x, y, bins=10, bin_mode='quantile', sort='value', reverse=False, switch=False, bin_cats=None):
        
        # Assert at least 1 continuous variable, put categorical one on x-axis if present
        assert x.dtype.kind in 'iufc' or y.dtype.kind in 'iufc', "At least x or y must be continuous."
        if x.dtype.kind in 'iufc' and y.dtype.kind not in 'iufc': x, y = (y, x)
        elif x.dtype.kind in 'iufc' and y.dtype.kind in 'iufc' and switch: x, y = (y, x)
        if bin_cats: 
            mask = x.isin(bin_cats)
            x, y = x[mask], y[mask]
        reverse = True if reverse else False

        # Group x variable, be it continuous or categorical
        cut = pd.qcut if bin_mode=='quantile' else pd.cut
        x_numeric = x.dtype.kind in 'iufc'
        x_togroup = bins &amp;lt; x.nunique()
        if x_numeric and x_togroup: x = cut(x, bins, duplicates='drop')
        elif not x_numeric and x_togroup:
            x = x.astype(str)
            to_show = x.value_counts().index if sort=='count' \
                else pd.Series(x.unique()).sort_values() if sort=='name' \
                else y.groupby(x).median().sort_values().dropna().index
            to_show = to_show[-bins+1:] if reverse else to_show[:bins-1]
            x[~x.isin(to_show)] = '&amp;lt;Other&amp;gt;'

        # Create boxplot
        boxplot = pd.concat((
            y.groupby(x).quantile([0.01, 0.25, 0.5, 0.75, 0.99]), 
            y.groupby(x).agg(['count', 'mean']).stack())).unstack(-1)
        boxplot.columns = boxplot.columns.astype(str)
        if x_numeric: boxplot = boxplot.sort_index()
        else: boxplot = boxplot.sort_index(ascending=not reverse) if sort=='name' else \
            boxplot.sort_values('count', ascending=reverse) if sort=='count' else \
            boxplot.sort_values('0.5', ascending=not reverse)
        if x_numeric and x_togroup: boxplot.index = boxplot.index.to_series().apply(
            lambda x: f'{x.left.round(3)}+' if type(x)!=float else x).astype(str)

        # Build figure
        fig = go.Figure()
        for i, cat in enumerate(boxplot.index):
            d = boxplot.loc[cat]
            c = 0 if np.isnan(d["count"]) else int(d["count"])
            fig.add_trace(
                go.Box(x=[f"{cat} (n={c})"], q1=[d['0.25']], q3=[d['0.75']], median=[d['0.5']], 
                upperfence=[d['0.99']], lowerfence=[d['0.01']], marker_color=self.colors[i%2], line=dict(width=1.5)))
        fig.update_layout(showlegend=False, yaxis=dict(title=y.name), autosize=True, height=490, 
            margin=dict(l=40, r=10, b=50, t=20, pad=4), xaxis=dict(title=x.name), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.plot_barchart</span><span class="signature">(self, x, title) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterplot_barchartmod"></i></span>
</h3>
<p>Plots a barchart.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterplot_barchartmod" tabindex="-1" role="dialog" aria-labelledby="Plotterplot_barchartLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterplot_barchart</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def plot_barchart(self, x, title):
        
        max_letters = min(x.index.to_series().apply(len).max(), 25)
        trace = go.Bar(x=x, y=x.index.str.slice(0, 25), orientation='h',
            marker=dict(color=x, colorscale=[[0.0, "#888"], [1.0, self.colors[0]]]))
        layout = go.Layout(showlegend=False, yaxis=dict(autorange="reversed", dtick=1), 
            xaxis=dict(title=title), height=len(x)*25+60, 
            margin=dict(t=30, l=max_letters*7, r=0, b=10, pad=10), **self._kwargs)
        fig = go.Figure([trace], layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.histogram</span><span class="signature">(self, x, y=None, z=None, bins=20, normalize=False, cumulative=False, switch=False, bin_cats=None) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterhistogrammod"></i></span>
</h3>
<p>Plots a histogram.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterhistogrammod" tabindex="-1" role="dialog" aria-labelledby="PlotterhistogramLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterhistogram</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def histogram(self, x, y=None, z=None, bins=20, normalize=False, cumulative=False, switch=False, bin_cats=None):
        
        df = pd.concat([series for series in [x, y, z] if series is not None], axis=1)
        if df.columns.duplicated().any(): df.columns = [f"{c}{i}" for i, c in enumerate(df, 1)]
        if bin_cats: df = df[x.isin(bin_cats)]

        # Group variable(s)
        is_numeric = x.dtype.kind in 'iufc'
        to_group = is_numeric and bins &amp;lt; df.nunique().max()
        if to_group:
            bins = np.linspace(df.min().min(), df.max().max(), bins+1).round(3)
            for c in df: df[c] = pd.cut(df[c], bins=bins, include_lowest=True)
        df = pd.concat([df[c].value_counts(normalize=normalize) for c in df], axis=1, keys=df.columns)
        if is_numeric: df.sort_index(inplace=True) 
        if not is_numeric: df = pd.concat(
            (df.iloc[:bins-1], df.iloc[bins-1:].sum(axis=0).rename('Other').to_frame().T), axis=0)
        if cumulative: df = pd.concat([df[c].cumsum() for c in df], axis=1)
        if to_group: df.index = df.index.to_series().apply(
            lambda x: f'{x.left.round(3)}+' if type(x)!=float else x).astype(str)

        # Build figure
        if switch: traces = [go.Bar(y=df.index.astype(str), x=df[c], marker=dict(
            color=self.colors[i]), name=c, orientation='h') for i, c in enumerate(df)]
        else: traces = [go.Bar(x=df.index.astype(str), y=df[c], marker=dict(
            color=self.colors[i]), name=c) for i, c in enumerate(df)]
        layout = go.Layout(autosize=True, height=490, margin=dict(t=20, r=20, b=50, l=20), 
            barmode='group', yaxis=dict(autorange="reversed") if switch else dict(), **self._kwargs)
        fig = go.Figure(traces, layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.scatter</span><span class="signature">(self, x, y, z=None, identifier=None, switch=False, height=490) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterscattermod"></i></span>
</h3>
<p>Plots a scatter chart.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterscattermod" tabindex="-1" role="dialog" aria-labelledby="PlotterscatterLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterscatter</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def scatter(self, x, y, z=None, identifier=None, switch=False, height=490):
        
        if switch: x, y = (y, x)
        if len(x) &amp;gt; 2000:
            np.random.seed(0)
            indices = np.random.choice(np.arange(len(x)), size=2000, replace=False)
            x, y, z = x.iloc[indices], y.iloc[indices], (z.iloc[indices] if z is not None else z)

        # Add some jitter on discrete values
        if x.nunique()&amp;lt;20: 
            x = x.astype(float)
            minmaxrange = (x.max()-x.min())/x.nunique()*0.6
            x += (np.random.uniform(size=len(x))-0.5)*minmaxrange
        if y.nunique()&amp;lt;20:
            y = y.astype(float)
            minmaxrange = (y.max()-y.min())/y.nunique()*0.6
            y += (np.random.uniform(size=len(y))-0.5)*minmaxrange

        # Set color params according to z
        if z is not None:
            if z.nunique()&amp;gt; 5: colorscale=[[0.0, self.colors[1]], [1.0, self.colors[0]]]
            else: colorscale=[[c, self.colors[i]] for i, c in enumerate(np.linspace(0, 1, z.nunique()))]
        else: colorscale = None
        
        # Build gigure
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(x=x, y=y, name=y.name, mode='markers', hoverinfo='text', hovertext=x.index,
                marker=dict(color=z if z is not None else self.colors[0], opacity=0.5, size=6, colorscale=colorscale))),
        if identifier is not None and identifier in x.index:
            fig.add_trace(go.Scatter(x=[x.loc[identifier]], y=[y.loc[identifier]], mode='markers', 
                hoverinfo='text', hovertext=identifier, marker=dict(color='#888', opacity=.8, size=20))),
        fig.update_layout(autosize=True, showlegend=z is not None, height=height, xaxis=dict(title=x.name), 
            yaxis=dict(title=y.name), margin=dict(t=30, r=10, b=10, l=20), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.make_datatable</span><span class="signature">(self, identifier, data, height='200px', page_size=20, left_align=None, **kwargs) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plottermake_datatablemod"></i></span>
</h3>
<p>Plots a data table.</p>

    <div class="modal fade bd-example-modal-lg" id="Plottermake_datatablemod" tabindex="-1" role="dialog" aria-labelledby="Plottermake_datatableLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plottermake_datatable</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def make_datatable(self, identifier, data, height='200px', page_size=20, left_align=None, **kwargs):
        
        if left_align:
            style_cell_conditional=[{'if': {'column_id': c}, 'textAlign': 'left', 'fontWeight': '600'} for c in left_align]
            kwargs.update(style_cell_conditional=style_cell_conditional)
        background_header = '#333' if self.theme=='plotly_dark' else '#ddd'
        if page_size is not None: kwargs.update(dict(page_size=page_size))
        color = '#eee' if self.theme=='plotly_dark' else '#555'
        table = dt.DataTable(
            id=identifier, 
            data=data.loc[:, data.columns[:100]].to_dict('records'),
            columns=[{"name": i, "id": i} for i in data.columns[:100]],
            style_header={'font-family':'sans-serif', 'backgroundColor': background_header, 'color': color, 'fontWeight': 'bold'},
            style_data={'font-family':'sans-serif', 'backgroundColor': self._plotcolor, 'color': color},
            style_table={'height': height, 'overflowX': 'auto'},
            style_as_list_view=True,
            sort_action="native",
            **kwargs
        )
        return table
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">Plotter.spaceholder</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#Plotterspaceholdermod"></i></span>
</h3>
<p>Plots a spaceholder.</p>

    <div class="modal fade bd-example-modal-lg" id="Plotterspaceholdermod" tabindex="-1" role="dialog" aria-labelledby="PlotterspaceholderLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">Plotterspaceholder</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), xaxis=dict(showticklabels=False), 
            autosize=True, height=490, margin=dict(l=40, r=10, b=50, t=20, pad=4), **self._kwargs)
        return (fig)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="PlotterModeltab" role="tabpanel" aria-labelledby="PlotterModeltab" tabindex="0">
<p><h3>
<span class="function">PlotterModel</span><span class="signature">(colors='belfius', theme='light') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterModelmod"></i></span>
</h3><p>This class collects methods for visualization.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>colors</b></span>: <span class="datatype"><i>String, default 'belfius'</i></span> Defines which color scheme to use accross al charts. Should be one of ('belfius', 'google', 'amazon', 'facebook') <br>
<span class="argument"><b>theme</b></span>: <span class="datatype"><i>String, default 'light'</i></span> Whether to run all visualizations in light or dark mode. Should be in ('light', 'dark'). <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Plotter.colors</b></span>: <span class="datatype"><i>List[String]</i></span> List of color hexacodes to use throughout the visualizations. <br>
<span class="argument"><b>Plotter.theme</b></span>: <span class="datatype"><i>String</i></span> Whether all visualizations run in light or dark mode. Either 'light' or 'dark'. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterModelmod" tabindex="-1" role="dialog" aria-labelledby="PlotterModelLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterModel</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class PlotterModel(Plotter):

    def __init__(self, colors='belfius', theme='light'):
        super().__init__(colors=colors, theme=theme)

    def run_app(self, directory='.', host="0.0.0.0", port=9063, debug=True):
        
        run_app(directory, host, port, debug)

    def confusion_heatmaps(self, confusion):
        
        pred_name = confusion.columns.levels[0][0]
        confusion = confusion.sort_index()[pred_name]
        low_bins = confusion.shape[1] &amp;lt; 10

        datasets = list(confusion.index.levels[0])
        datasets.reverse()
        n_data = len(datasets)
        fig = make_subplots(rows=len(datasets), cols=1)
        annotations = []
        for d, dataset in enumerate(datasets):
            conf = confusion.loc[dataset].copy()
            conf.columns = [f'P{c}' if type(c)!=str else c for c in conf.columns]
            conf.index = [f'L{i}' if type(i)!=str else i for i in conf.index]
            conf.loc['Total'] = 0
            conf['Total'] = 0

            # Heatmap traces
            fig.add_trace(go.Heatmap(
                x=conf.columns, y=conf.index, z=conf.values, hoverinfo='skip' if low_bins else None,
                showscale=False, xaxis=f"x{d+1}", yaxis=f"y{d+1}", zmin=0,
                zmax=conf.max(axis=1).max(),
                colorscale=[[0, self._plotcolor], [1, self.colors[0]]]), col=1, row=d+1)
            conf.loc['Total'] = conf.sum()
            conf['Total'] = conf.sum(axis=1)

            if low_bins:
                # Add counts as annotations on heatmaps
                for n in conf.index:
                    for m in conf.columns:
                        annotations.append(dict(text=str(conf.loc[n, m]), showarrow=False,
                                                x=m, y=n, xref=f"x{d+1}", yref=f"y{d+1}"))
            # Update layout locations
            fig.update_layout({f'xaxis{d+1}': dict(title=dataset, dtick=1 if low_bins else None, side='top')})
            fig.update_layout({f'yaxis{d+1}': dict(title='Actual', dtick=1 if low_bins else None, anchor=f"x{d+1}", 
                autorange='reversed', domain=[d * 1/n_data, (d+1)*1/n_data-0.2/n_data])})
        width = min(conf.shape[1]*40+130, 620)
        height = min(conf.shape[0]*40+120, 540)
        fig.update_layout(annotations=annotations, width=width, height=height*len(datasets),
            margin=dict(l=80, r=10, b=20, t=10), **self._kwargs)
        return fig

    def lift_curve(self, preds, dataset='Test', bins=50):
        
        binscores = get_binscores(preds, bins)
        targets = binscores.target
        preds = binscores.scores.drop('Total')
        counts = binscores['count'].drop('Total')
        totals = targets[[dataset]]
        targets.drop('Total', inplace=True)
        
        fig = make_subplots(rows=1, cols=1, subplot_titles=None, specs=[[{"secondary_y": True}]])
        if len(dataset)&amp;gt;0:
            d = dataset
            fig.add_trace(go.Scatter(
                x=targets.index, y=targets[d], marker=dict(color=self.colors[0]), name=d+' Actual'))
            fig.add_trace(go.Scatter(
                x=preds.index, y=preds[d], marker=dict(color=self.colors[1]), name=d+' Predictions'))
            fig.add_trace(go.Bar(hoverinfo='name+y',
                x=counts.index, y=counts[d], marker=dict(color="#bbb"), name=d+' Count', opacity=0.3), secondary_y=True)
            fig.update_layout(yaxis2=dict(title="Count", showgrid=False, range=[0, counts[d].max()*4]),)
                
        fig.update_layout(autosize=True, height=541, showlegend=True, 
                        margin=dict(t=30, r=40, b=50, l=20), yaxis=dict(title="Prevalence"),
                        legend=dict(x=0.05, y=0.9), xaxis=dict(title="Prediction Bins", dtick=1), **self._kwargs)
        return fig

    def shap_observation(self, shapsample, datasample):
        
        max_letters = min(25, shapsample.index.to_series().apply(len).max())
        trace = go.Bar(x=shapsample, y=shapsample.index.str.slice(0, 25), orientation='h', 
                    hoverinfo='x+y+text', hovertext=datasample, text=datasample, 
                    textposition='auto', textangle=0,
                    marker=dict(color=(shapsample&amp;gt;0).astype(float), colorscale=[[0.0, self.colors[1]], [1.0, self.colors[0]]]))
        layout = go.Layout(autosize=True, showlegend=False, yaxis=dict(autorange="reversed", dtick=1),
                        xaxis=dict(title="Impact on Prediction"), height=len(shapsample)*25+60,
                        margin=dict(t=30, l=max_letters*7, r=30, b=10, pad=10), **self._kwargs)
        fig = go.Figure([trace], layout)
        fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">PlotterModel.run_app</span><span class="signature">(self, directory='.', host='0.0.0.0', port=9063, debug=True) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterModelrun_appmod"></i></span>
</h3>
<p>Run Dash dashboard that visualizes experiments made with lfd.
If running from a notebook, kill the kernal to close the connection.
If running in the background, it can be closed in a terminal by 
running "netstat -ltnp | grep &amp;lt;port&amp;gt;" and "kill -9 &amp;lt;PID number&amp;gt;".</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>directory</b></span>: <span class="datatype"><i>String, default './'</i></span> Path to the directory where experiments are stored. <br>
<span class="argument"><b>host</b></span>: <span class="datatype"><i>String, default '0.0.0.0'</i></span> Host where the app is served. Defaults to loacal host. <br>
<span class="argument"><b>port</b></span>: <span class="datatype"><i>Integer, default '9063'</i></span> Port where the app is served. <br>
<span class="argument"><b>debug</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to run the app in debug mode. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterModelrun_appmod" tabindex="-1" role="dialog" aria-labelledby="PlotterModelrun_appLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterModelrun_app</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def run_app(self, directory='.', host="0.0.0.0", port=9063, debug=True):
        
        run_app(directory, host, port, debug)
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">PlotterModel.confusion_heatmaps</span><span class="signature">(self, confusion) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterModelconfusion_heatmapsmod"></i></span>
</h3>
<p>Displays a modelling tailored confusion heatmap.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>confusion</b></span>: <span class="datatype"><i>pandas.DataFrame</i></span> Confusion matrix in same format of Model.confusion. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterModelconfusion_heatmapsmod" tabindex="-1" role="dialog" aria-labelledby="PlotterModelconfusion_heatmapsLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterModelconfusion_heatmaps</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def confusion_heatmaps(self, confusion):
        
        pred_name = confusion.columns.levels[0][0]
        confusion = confusion.sort_index()[pred_name]
        low_bins = confusion.shape[1] &amp;lt; 10

        datasets = list(confusion.index.levels[0])
        datasets.reverse()
        n_data = len(datasets)
        fig = make_subplots(rows=len(datasets), cols=1)
        annotations = []
        for d, dataset in enumerate(datasets):
            conf = confusion.loc[dataset].copy()
            conf.columns = [f'P{c}' if type(c)!=str else c for c in conf.columns]
            conf.index = [f'L{i}' if type(i)!=str else i for i in conf.index]
            conf.loc['Total'] = 0
            conf['Total'] = 0

            # Heatmap traces
            fig.add_trace(go.Heatmap(
                x=conf.columns, y=conf.index, z=conf.values, hoverinfo='skip' if low_bins else None,
                showscale=False, xaxis=f"x{d+1}", yaxis=f"y{d+1}", zmin=0,
                zmax=conf.max(axis=1).max(),
                colorscale=[[0, self._plotcolor], [1, self.colors[0]]]), col=1, row=d+1)
            conf.loc['Total'] = conf.sum()
            conf['Total'] = conf.sum(axis=1)

            if low_bins:
                # Add counts as annotations on heatmaps
                for n in conf.index:
                    for m in conf.columns:
                        annotations.append(dict(text=str(conf.loc[n, m]), showarrow=False,
                                                x=m, y=n, xref=f"x{d+1}", yref=f"y{d+1}"))
            # Update layout locations
            fig.update_layout({f'xaxis{d+1}': dict(title=dataset, dtick=1 if low_bins else None, side='top')})
            fig.update_layout({f'yaxis{d+1}': dict(title='Actual', dtick=1 if low_bins else None, anchor=f"x{d+1}", 
                autorange='reversed', domain=[d * 1/n_data, (d+1)*1/n_data-0.2/n_data])})
        width = min(conf.shape[1]*40+130, 620)
        height = min(conf.shape[0]*40+120, 540)
        fig.update_layout(annotations=annotations, width=width, height=height*len(datasets),
            margin=dict(l=80, r=10, b=20, t=10), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">PlotterModel.lift_curve</span><span class="signature">(self, preds, dataset='Test', bins=50) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterModellift_curvemod"></i></span>
</h3>
<p>Displays a modelling tailored lift curve.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>preds</b></span>: <span class="datatype"><i>pandas.DataFrame</i></span> Prediction dataframe in same format of Model.predictions.df. Contains targets and predictions to calculate lift curve on the fly. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterModellift_curvemod" tabindex="-1" role="dialog" aria-labelledby="PlotterModellift_curveLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterModellift_curve</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def lift_curve(self, preds, dataset='Test', bins=50):
        
        binscores = get_binscores(preds, bins)
        targets = binscores.target
        preds = binscores.scores.drop('Total')
        counts = binscores['count'].drop('Total')
        totals = targets[[dataset]]
        targets.drop('Total', inplace=True)
        
        fig = make_subplots(rows=1, cols=1, subplot_titles=None, specs=[[{"secondary_y": True}]])
        if len(dataset)&amp;gt;0:
            d = dataset
            fig.add_trace(go.Scatter(
                x=targets.index, y=targets[d], marker=dict(color=self.colors[0]), name=d+' Actual'))
            fig.add_trace(go.Scatter(
                x=preds.index, y=preds[d], marker=dict(color=self.colors[1]), name=d+' Predictions'))
            fig.add_trace(go.Bar(hoverinfo='name+y',
                x=counts.index, y=counts[d], marker=dict(color="#bbb"), name=d+' Count', opacity=0.3), secondary_y=True)
            fig.update_layout(yaxis2=dict(title="Count", showgrid=False, range=[0, counts[d].max()*4]),)
                
        fig.update_layout(autosize=True, height=541, showlegend=True, 
                        margin=dict(t=30, r=40, b=50, l=20), yaxis=dict(title="Prevalence"),
                        legend=dict(x=0.05, y=0.9), xaxis=dict(title="Prediction Bins", dtick=1), **self._kwargs)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">PlotterModel.shap_observation</span><span class="signature">(self, shapsample, datasample) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterModelshap_observationmod"></i></span>
</h3>
<p>Displays a modelling tailored shap observation chart.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>shapsample</b></span>: <span class="datatype"><i>pandas.DataFrame</i></span> Shapvalues dataframe in same format of Model.shapvalues.df. Ideally use a sample for quick rendering. <br>
<span class="argument"><b>datasample</b></span>: <span class="datatype"><i>pandas.DataFrame</i></span> Input dataframe in same format of Model.data.df. Ideally use a sample for quick rendering. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterModelshap_observationmod" tabindex="-1" role="dialog" aria-labelledby="PlotterModelshap_observationLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterModelshap_observation</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def shap_observation(self, shapsample, datasample):
        
        max_letters = min(25, shapsample.index.to_series().apply(len).max())
        trace = go.Bar(x=shapsample, y=shapsample.index.str.slice(0, 25), orientation='h', 
                    hoverinfo='x+y+text', hovertext=datasample, text=datasample, 
                    textposition='auto', textangle=0,
                    marker=dict(color=(shapsample&amp;gt;0).astype(float), colorscale=[[0.0, self.colors[1]], [1.0, self.colors[0]]]))
        layout = go.Layout(autosize=True, showlegend=False, yaxis=dict(autorange="reversed", dtick=1),
                        xaxis=dict(title="Impact on Prediction"), height=len(shapsample)*25+60,
                        margin=dict(t=30, l=max_letters*7, r=30, b=10, pad=10), **self._kwargs)
        fig = go.Figure([trace], layout)
        fig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="PlotterVisualtab" role="tabpanel" aria-labelledby="PlotterVisualtab" tabindex="0">
<p><h3>
<span class="function">PlotterVisual</span><span class="signature">(colors=None, theme='dark') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterVisualmod"></i></span>
</h3><p>This class collects methods for visualization.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>colors</b></span>: <span class="datatype"><i>String, default 'belfius'</i></span> Defines which color scheme to use accross al charts. Should be one of ('belfius', 'google', 'amazon', 'facebook') <br>
<span class="argument"><b>theme</b></span>: <span class="datatype"><i>String, default 'light'</i></span> Whether to run all visualizations in light or dark mode. Should be in ('light', 'dark'). <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Plotter.colors</b></span>: <span class="datatype"><i>List[String]</i></span> List of color hexacodes to use throughout the visualizations. <br>
<span class="argument"><b>Plotter.theme</b></span>: <span class="datatype"><i>String</i></span> Whether all visualizations run in light or dark mode. Either 'light' or 'dark'. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterVisualmod" tabindex="-1" role="dialog" aria-labelledby="PlotterVisualLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterVisual</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class PlotterVisual(Plotter):

    def __init__(self, colors=None, theme='dark'):
        super().__init__(colors=colors, theme=theme)
        self.layout = dict(margin = dict(pad=0, t=50, r=0, l=0, b=0), #font = dict(family='Palatino'), 
            template=self.theme, paper_bgcolor=self._plotcolor, plot_bgcolor=self._plotcolor, autosize=True, height=550)

    def plot_images(self, visual, indices):
        
        nx, ny = 5, 2
        titles = [f"{i} - {visual.df.label[i]}" for i in indices]
        fig = make_subplots(ny, nx, horizontal_spacing=0.015, vertical_spacing=0.10, subplot_titles=titles)
        for i, img in enumerate(visual.tensor):
            fig.add_trace(go.Image(z=img), i//nx+1, i%nx+1)
        fig.update_xaxes(showticklabels=False)
        fig.update_yaxes(showticklabels=False)
        fig.update_layout(**self.layout)
        fig.update_layout(height=600)
        fig.update_annotations(font=dict(size=11))
        return fig

    def plot_spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), 
                        xaxis=dict(showticklabels=False), **self.layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">PlotterVisual.plot_images</span><span class="signature">(self, visual, indices) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterVisualplot_imagesmod"></i></span>
</h3>
<p>Plots images for a visual dataset.</p>

    <div class="modal fade bd-example-modal-lg" id="PlotterVisualplot_imagesmod" tabindex="-1" role="dialog" aria-labelledby="PlotterVisualplot_imagesLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterVisualplot_images</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def plot_images(self, visual, indices):
        
        nx, ny = 5, 2
        titles = [f"{i} - {visual.df.label[i]}" for i in indices]
        fig = make_subplots(ny, nx, horizontal_spacing=0.015, vertical_spacing=0.10, subplot_titles=titles)
        for i, img in enumerate(visual.tensor):
            fig.add_trace(go.Image(z=img), i//nx+1, i%nx+1)
        fig.update_xaxes(showticklabels=False)
        fig.update_yaxes(showticklabels=False)
        fig.update_layout(**self.layout)
        fig.update_layout(height=600)
        fig.update_annotations(font=dict(size=11))
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">PlotterVisual.plot_spaceholder</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterVisualplot_spaceholdermod"></i></span>
</h3>
<p>Plots a spaceholder.</p>

    <div class="modal fade bd-example-modal-lg" id="PlotterVisualplot_spaceholdermod" tabindex="-1" role="dialog" aria-labelledby="PlotterVisualplot_spaceholderLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterVisualplot_spaceholder</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def plot_spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), 
                        xaxis=dict(showticklabels=False), **self.layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="PlotterGraphtab" role="tabpanel" aria-labelledby="PlotterGraphtab" tabindex="0">
<p><h3>
<span class="function">PlotterGraph</span><span class="signature">(colors=None, theme='dark') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterGraphmod"></i></span>
</h3><p>This class collects methods for visualization.</p><p><span class="attributes">Arguments</span><br>
<span class="argument"><b>colors</b></span>: <span class="datatype"><i>String, default 'belfius'</i></span> Defines which color scheme to use accross al charts. Should be one of ('belfius', 'google', 'amazon', 'facebook') <br>
<span class="argument"><b>theme</b></span>: <span class="datatype"><i>String, default 'light'</i></span> Whether to run all visualizations in light or dark mode. Should be in ('light', 'dark'). <br><br><span class="attributes">Attributes</span><br>
<span class="argument"><b>Plotter.colors</b></span>: <span class="datatype"><i>List[String]</i></span> List of color hexacodes to use throughout the visualizations. <br>
<span class="argument"><b>Plotter.theme</b></span>: <span class="datatype"><i>String</i></span> Whether all visualizations run in light or dark mode. Either 'light' or 'dark'. </p>


    <div class="modal fade bd-example-modal-lg" id="PlotterGraphmod" tabindex="-1" role="dialog" aria-labelledby="PlotterGraphLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterGraph</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">class PlotterGraph(Plotter):

    def __init__(self, colors=None, theme='dark'):
        super().__init__(colors=colors, theme=theme)
        self.layout = dict(margin = dict(pad=0, t=0, r=0, l=0, b=0), #font = dict(family='Palatino'), 
            template=self.theme, paper_bgcolor=self._plotcolor, plot_bgcolor=self._plotcolor, autosize=True, height=700)

    def plot_graph(self, graph, mode='mesh', showgrid=False, opacity=1, size=1, color=None, ambient=0.2, diffuse=0.8, fresnel= .1, specular= 1, roughness= .1):
        
        m = np.ceil(np.abs(graph.vertices).max().max())
        color = '#fff' if color is None else color
        
        if mode == 'point':
            data = go.Scatter3d(opacity=opacity, 
                x = graph.vertices.x, y = graph.vertices.y, z = graph.vertices.z,
                #colorscale=[[0, '#C30045'], [0.5, '#51626F'], [0.7, 'silver'], [1, '#252827']],
                mode = 'markers', marker = dict(color=color, opacity=opacity, size=size)
            )
        elif mode == 'mesh':
            data = go.Mesh3d(opacity=opacity, 
                x = graph.vertices.x, y = graph.vertices.y, z = graph.vertices.z,
                i = graph.faces.i, j = graph.faces.j, k = graph.faces.k,
                #colorscale=[[0, '#C30045'], [0.5, '#51626F'], [0.7, 'silver'], [1, '#252827']],
                lighting=dict(ambient=ambient, diffuse=diffuse, fresnel=fresnel, specular=specular, roughness=roughness),
                lightposition=dict(x=100, y=200, z=150), color=color,
            )
        
        axes = dict(
            range=[-m, m], showgrid=True, zeroline=True,
            gridcolor='#888', gridwidth=2,
            zerolinecolor='#969696', zerolinewidth=4,
            linecolor='#999999', linewidth=3,
            backgroundcolor=self._plotcolor
        ) if showgrid else dict(
            range=[-m,m], showgrid=False, zeroline=False,
            showticklabels=False, title='',
            backgroundcolor=self._plotcolor
        )        
            
        fig = go.Figure(data=[data])
        fig.update_layout(scene=dict(
                bgcolor=self._plotcolor,
                aspectratio=dict(x=1, y=1, z=1),
                xaxis=axes, yaxis=axes, zaxis=axes,
                camera = dict(eye=dict(x=.4, y=.4, z=.4))
            ), **self.layout
        )
        return fig

    def plot_spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), 
                        xaxis=dict(showticklabels=False), **self.layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div><br></p>
<h3>
<span class="function">PlotterGraph.plot_graph</span><span class="signature">(self, graph, mode='mesh', showgrid=False, opacity=1, size=1, color=None, ambient=0.2, diffuse=0.8, fresnel=0.1, specular=1, roughness=0.1) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterGraphplot_graphmod"></i></span>
</h3>
<p>Create a 3D space object.
This object can be plotted, saved, projected, generated to HTML/JS, etc.

Parameters:
data (dataframe): dataframe with coordinates x, y, z and graphs i, j, k
showgrid (boolean): whether to add axes to the space object

Returns:
Plotly figure: 3D space object</p>

    <div class="modal fade bd-example-modal-lg" id="PlotterGraphplot_graphmod" tabindex="-1" role="dialog" aria-labelledby="PlotterGraphplot_graphLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterGraphplot_graph</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def plot_graph(self, graph, mode='mesh', showgrid=False, opacity=1, size=1, color=None, ambient=0.2, diffuse=0.8, fresnel= .1, specular= 1, roughness= .1):
        
        m = np.ceil(np.abs(graph.vertices).max().max())
        color = '#fff' if color is None else color
        
        if mode == 'point':
            data = go.Scatter3d(opacity=opacity, 
                x = graph.vertices.x, y = graph.vertices.y, z = graph.vertices.z,
                #colorscale=[[0, '#C30045'], [0.5, '#51626F'], [0.7, 'silver'], [1, '#252827']],
                mode = 'markers', marker = dict(color=color, opacity=opacity, size=size)
            )
        elif mode == 'mesh':
            data = go.Mesh3d(opacity=opacity, 
                x = graph.vertices.x, y = graph.vertices.y, z = graph.vertices.z,
                i = graph.faces.i, j = graph.faces.j, k = graph.faces.k,
                #colorscale=[[0, '#C30045'], [0.5, '#51626F'], [0.7, 'silver'], [1, '#252827']],
                lighting=dict(ambient=ambient, diffuse=diffuse, fresnel=fresnel, specular=specular, roughness=roughness),
                lightposition=dict(x=100, y=200, z=150), color=color,
            )
        
        axes = dict(
            range=[-m, m], showgrid=True, zeroline=True,
            gridcolor='#888', gridwidth=2,
            zerolinecolor='#969696', zerolinewidth=4,
            linecolor='#999999', linewidth=3,
            backgroundcolor=self._plotcolor
        ) if showgrid else dict(
            range=[-m,m], showgrid=False, zeroline=False,
            showticklabels=False, title='',
            backgroundcolor=self._plotcolor
        )        
            
        fig = go.Figure(data=[data])
        fig.update_layout(scene=dict(
                bgcolor=self._plotcolor,
                aspectratio=dict(x=1, y=1, z=1),
                xaxis=axes, yaxis=axes, zaxis=axes,
                camera = dict(eye=dict(x=.4, y=.4, z=.4))
            ), **self.layout
        )
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">PlotterGraph.plot_spaceholder</span><span class="signature">(self) <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#PlotterGraphplot_spaceholdermod"></i></span>
</h3>
<p>Plots a spaceholder.</p>

    <div class="modal fade bd-example-modal-lg" id="PlotterGraphplot_spaceholdermod" tabindex="-1" role="dialog" aria-labelledby="PlotterGraphplot_spaceholderLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">PlotterGraphplot_spaceholder</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">    def plot_spaceholder(self):
        
        fig = go.Figure()
        fig.update_layout(showlegend=False, yaxis=dict(showticklabels=False), 
                        xaxis=dict(showticklabels=False), **self.layout)
        return fig
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<div class="tab-pane" id="configtab" role="tabpanel" aria-labelledby="configtab" tabindex="0">
<p></p>
<h3>
<span class="function">get_params</span><span class="signature">(target=None, set_aside=None, mode='binaryclass') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#get_paramsmod"></i></span>
</h3>
<p>This function provides a parameter dictionary for the pipe.learn() function.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>target</b></span>: <span class="datatype"><i>String</i></span> Target variable used in target encoding, biselection, and modelling. <br>
<span class="argument"><b>set_aside</b></span>: <span class="datatype"><i>List(String)</i></span> List of variables not to be included in any transformer or as feature for modelling. <br>
<span class="argument"><b>mode</b></span>: <span class="datatype"><i>String, in ('linear', 'binaryclass', 'multiclass')</i></span> What kind of model to build. </p>


    <div class="modal fade bd-example-modal-lg" id="get_paramsmod" tabindex="-1" role="dialog" aria-labelledby="get_paramsLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">get_params</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">def get_params(target=None, set_aside=None, mode='binaryclass'):
    
    params = dict(
        set_aside = set_aside,
        data = dict(
            add_noise = dict(seed=0),
            test_split = dict(test_size=0.2, stratify_col=None, seed=0),
        ),
        transform = dict(
            uniselector = dict(min_occ=0.01, max_occ=0.99),
            imputer = dict(default_cat='MISSING', default_cont='median'),
            encoder = dict(min_occ=0.01, method='onehot' if target is None else 'target', target=target),
            biselector = dict(threshold=0.8, target=target),
        ),
        model = dict(
            target=target, mode=mode, seed_train=0,
            base0 = dict(algorithm='xgboost', name='Xgboost', hyper_params=dict(
                n_estimators=100, max_depth=6
            )),
            calibrate = dict(algorithm='isotonic', hyper_params=dict(method='quantile')) \
                if mode=='linear' else dict(algorithm='regression', hyper_params=dict()),
        ),
    )
    return params
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">set_logging</span><span class="signature">(stdout=True, stdout_level='INFO', log_dir=None, log_level='DEBUG') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#set_loggingmod"></i></span>
</h3>
<p>Configure logging, to standard output and/or a log file for any use of lfd.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>stdout</b></span>: <span class="datatype"><i>Bool, default True</i></span> Whether to log to standard output. <br>
<span class="argument"><b>stdout_level</b></span>: <span class="datatype"><i>String, default 'INFO'</i></span> Should be in (in 'CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG'). What level should be logged to standard output. Level and above is logged. <br>
<span class="argument"><b>log_dir</b></span>: <span class="datatype"><i>String, default None</i></span> Path to logfile. If given, all logging is written to this file. If parent directory doesn't exist, it is created. <br>
<span class="argument"><b>log_level</b></span>: <span class="datatype"><i>String, default 'DEBUG'</i></span> Should be in (in 'CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG'). What level should be logged to the logfile. Level and above is logged. </p>


    <div class="modal fade bd-example-modal-lg" id="set_loggingmod" tabindex="-1" role="dialog" aria-labelledby="set_loggingLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">set_logging</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">def set_logging(stdout=True, stdout_level='INFO', log_dir=None, log_level='DEBUG'):
    
    log_path = os.path.join(log_dir, 'logs.log') if log_dir else None
    if log_dir and not os.path.exists(log_dir): os.mkdir(log_dir)
    logging.config.dictConfig(_get_logging(stdout, stdout_level, log_path, log_level))
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">generate_doc</span><span class="signature">(path='doc.html') <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#generate_docmod"></i></span>
</h3>
<p>Get HTML documentation on the LFD package.</p>
<p><span class="attributes">Arguments</span><br>
<span class="argument"><b>path</b></span>: <span class="datatype"><i>String, default 'doc.html'</i></span> Path where the output documentation should be written. Should have an .html extension. </p>


    <div class="modal fade bd-example-modal-lg" id="generate_docmod" tabindex="-1" role="dialog" aria-labelledby="generate_docLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">generate_doc</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">def generate_doc(path='doc.html'):
    
    # Read from base HTML file
    with open(os.path.join(os.path.dirname(__file__), 'doc_base.html'), "r") as f: page = f.read()
    tree = ET.fromstring(page, parser=ET.HTMLParser())
    intro = tree.find(".//span[@id='intro']")
    content = tree.find(".//span[@id='content']")
    sidebar = tree.find(".//span[@id='sidebar']")
    
    # Title
    lfd_doc = h(f'Learnfromdata {span("v"+lfd.__version__, "small attributes")}', 1) + br()
    intro.addprevious(ET.XML(div(lfd_doc)))

    # Introduction tab
    sidebar.addprevious(ET.XML(pill('About', space=False, active=True)))
    content.addprevious(ET.XML(tab('Abouttab', inspect.getdoc(lfd), active=True)))

    # Collect objects to build a page for 
    transformers = [e.value for e in lfd.TransformEnum]
    models = [e.value for e in lfd.ModelEnum]
    plotters = [e.value for e in lfd.PlotterEnum]
    things = [lfd.Pipeline, lfd.Bootstrap, lfd.Data]
    things += transformers + models + plotters + [lfd.config]

    for thing in things:
        # Tab page
        class_intro = doc_function(thing)
        name = re.sub('lfd\.', '', thing.__name__)
        functions = get_functions(thing)
        doc = p(class_intro)
        doc += ''.join([doc_function(func) for func in functions])
        content.addprevious(ET.XML(tab(f'{name}tab', doc)))

        # Sidebar
        sub = thing in transformers[1:] + models[1:] + plotters[1:]
        sidebar.addprevious(ET.XML(pill(name, sub)))

    # Write to html file
    ET.ElementTree(tree).write(path, pretty_print=True, method="html")
    path = path if path.startswith('/') else os.path.join(os.path.abspath(os.getcwd()), path)
    logging.info(f'Doc available at {path}')
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br><h3>
<span class="function">get_lfd_doc</span><span class="signature">() <i type="button" class="bi bi-code-slash" data-bs-toggle="modal" data-bs-target="#get_lfd_docmod"></i></span>
</h3>
<p>Get docstring for LFD module.</p>

    <div class="modal fade bd-example-modal-lg" id="get_lfd_docmod" tabindex="-1" role="dialog" aria-labelledby="get_lfd_docLabel" aria-hidden="true">
        <div class="modal-dialog modal-xl" role="document">
            <div class="modal-content">
                <div class="modal-header">
                    <h5 class="modal-title">get_lfd_doc</h5>
                    <button type="button" class="btn-close" data-dismiss="modal" aria-label="Close"></button>
                </div>
                <div class="modal-body">
                    <pre><code class="python">def get_lfd_doc():
    
    doc = ''
    path = os.path.dirname(__file__)
    with open(os.path.join(path, 'doc_lfd.html'), "r") as f: 
        doc += f.read()
    return doc
</code><br></pre>
                </div>
            </div>
        </div>
    </div>
<br>
</div>
<span id="content"></span>         
                </main>
            </div>
        </div>
        <br><br>
        <!-- <div class="row">
          <div class="col-xl-8 offset-xl-2">
            <footer class="pt-5 py-3 my-5 text-muted border-top mt-auto footer">
              Created by Data & Analytics, Belfius Insurance &#183; &#169; 2022
            </footer>
          </div>
        </div>
      -->
    </div>
  </body>
</html>
