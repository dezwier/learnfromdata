{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Houses'\n",
    "TARGET = 'SalePrice'\n",
    "SET_ASIDE = [TARGET]\n",
    "MODE = 'linear'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = lfd.Data(f'../../learnfromdata_new/datasets/tabular/{DATASET.lower()}')\n",
    "data.set_dtypes()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.analyse(broken_by='SalePrice', bins=5, to_excel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    set_aside = SET_ASIDE,\n",
    "    data = dict(\n",
    "        add_noise = None,#dict(seed=0),\n",
    "        test_split = dict(test_size=0.2, stratify_col=None, seed=0),\n",
    "        #valid_split = dict(test_size=0.2, stratify_col=None, seed=0),\n",
    "    ),\n",
    "    transform = dict(\n",
    "        uniselector = dict(min_occ=0.01, max_occ=0.99),\n",
    "        encoder = dict(min_occ=0.01, method='onehot', target=TARGET),\n",
    "        biselector = dict(threshold=0.8, target=TARGET),\n",
    "    ),\n",
    "    model = dict(\n",
    "        target=TARGET, mode=MODE, seed_train=0,\n",
    "        base0 = dict(algorithm='xgboost', name='Xgboost1', hyper_params=dict(\n",
    "            n_estimators=20, max_depth=3\n",
    "        )),\n",
    "        base1 = dict(algorithm='xgboost', name='Xgboost2', hyper_params=dict(\n",
    "            n_estimators=50, max_depth=6\n",
    "        )),\n",
    "        calibrate = dict(algorithm='isotonic', hyper_params=dict(method='quantile')),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = lfd.Pipeline(name=f'{DATASET}_{TARGET}').learn(\n",
    "    params, data=data.copy(), evaluate=True, explain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.save('../../experiments', slim=False, as_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = lfd.Pipeline().load(f'../../experiments/{DATASET}_{TARGET}', slim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2.apply(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipe.cal_models['Xgboost1']\n",
    "shapvalues = pipe.models['Xgboost1'].shapvalues.abs().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = lfd.PlotterModel(theme='dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.confusion_heatmaps(model.confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.confusion_cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_barchart(shapvalues.head(20), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.lift_curve(model.predictions.df, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.histogram(\n",
    "    pipe.models['Xgboost1'].predictions.df.loc['Test'].scores, \n",
    "    model.predictions.df.loc['Test'].scores, \n",
    "    model.predictions.df.loc['Test'].target,\n",
    "    bins=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cdcf78662290a5d38caa095ea8726f573c25613098cce55fbf78c21b4d772aa4"
  },
  "kernelspec": {
   "display_name": "Python [conda env:conda-sinatra]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d3b036bd79e85f84cae0ba01a2da779369df343e5207183dc018dee967c7d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
